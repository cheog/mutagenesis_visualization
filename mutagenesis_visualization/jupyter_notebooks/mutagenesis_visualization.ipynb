{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.409948Z",
     "start_time": "2020-09-13T01:44:55.948942Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import copy\n",
    "from scipy import stats\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from adjustText import adjust_text\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.PDB import PDBParser\n",
    "from collections import defaultdict, OrderedDict, Counter\n",
    "import freesasa\n",
    "from os import path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import shannon\n",
    "except ModuleNotFoundError:\n",
    "    print(\"\")\n",
    "    \n",
    "try:\n",
    "    import adjustText\n",
    "except ModuleNotFoundError:\n",
    "    print(\"\")\n",
    "    \n",
    "try:\n",
    "    import logomaker\n",
    "except ModuleNotFoundError:\n",
    "    print(\"\")\n",
    "\n",
    "try:\n",
    "    from ipymol import viewer as pymol\n",
    "except ModuleNotFoundError:\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Process Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process trimmed fastq file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.439520Z",
     "start_time": "2020-09-13T01:45:00.416558Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_reads(dna_sequence, codon_list='NNS', **kwargs):\n",
    "    '''\n",
    "    Process a trimmed fastq file containing DNA reads and returns the counts of \n",
    "    each DNA sequence specified by the user.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    dna_sequence : str, \n",
    "        Contains the DNA sequence of the allele of reference (usually wild-type).\n",
    "    \n",
    "    codon_list : list or str, default 'NNS'\n",
    "        Input a list of the codons that were used to create point mutations. Example: [\"GCC\", \"GCG\", \"TGC\"].\n",
    "        If the library was built using NNS and NNK codons, it is enough to input 'NNS' or 'NNK' as a string. \n",
    "        It is important to know that the order of the codon_list will determine the output order.\n",
    "    \n",
    "    inputfilepath : str, not optional kwarg\n",
    "        Path where the input fastq file is stored.\n",
    "    \n",
    "    inputfilename : str, not optional kwarg\n",
    "        Name of the fastq file (full name including \".fastq\").\n",
    "    \n",
    "    outputfilepath : str, optional kwarg\n",
    "        Path where the output files will be saved.\n",
    "    \n",
    "    outputfilename : str, optional kwarg\n",
    "        Name of the output files.\n",
    "    \n",
    "    savefile : boolean, default False. optional kwarg \n",
    "        If set to true, the function will export the two arrays to separate txt files using the\n",
    "        output filepath and output filename specified by the user.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    df_counts : dataframe \n",
    "        Dataframe with the counts for each point mutant.\n",
    "    \n",
    "    wt_counts : list\n",
    "        List of the counts for each for each DNA sequence that codes for the wild-type protein.\n",
    "    '''\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "\n",
    "    # Naming files\n",
    "    trimmedfile = temp_kwargs['inputfilepath']+temp_kwargs['inputfilename']\n",
    "\n",
    "    # Make upper case in case input was lower case\n",
    "    dna_sequence = dna_sequence.upper()\n",
    "    codon_list = [item.upper() for item in codon_list]\n",
    "    \n",
    "    # Create list with codons of sequence\n",
    "    wtSeqList = [dna_sequence[i:i+3] for i in range(0, len(dna_sequence), 3)]\n",
    "\n",
    "    # codon_list\n",
    "    if codon_list == 'NNS':\n",
    "        codon_list = [\"GCC\", \"GCG\", \"TGC\", \"GAC\", \"GAG\", \"TTC\", \"GGC\", \"GGG\", \"CAC\", \"ATC\", \"AAG\", \"CTC\", \"CTG\", \"TTG\", \"ATG\",\n",
    "                      \"AAC\", \"CCC\", \"CCG\", \"CAG\", \"CGC\", \"CGG\", \"AGG\", \"TCC\", \"TCG\", \"AGC\", \"ACC\", \"ACG\", \"GTC\", \"GTG\", \"TGG\", \"TAC\", \"TAG\"]\n",
    "    elif codon_list == 'NNK':\n",
    "        codon_list = ['GCG', 'GCT', 'TGT', 'GAT', 'GAG', 'TTT', 'GGG', 'GGT', 'CAT', 'ATT', 'AAG', 'CTG', 'CTT', 'TTG', 'ATG',\n",
    "                      'AAT', 'CCG', 'CCT', 'CAG', 'AGG', 'CGG', 'CGT', 'AGT', 'TCG', 'TCT', 'ACG', 'ACT', 'GTG', 'GTT', 'TGG', 'TAT', 'TAG']\n",
    "\n",
    "    # Enumerate variants\n",
    "    variants = OrderedDict()\n",
    "    isitthefirstwtseq = False\n",
    "    for position, codon in enumerate(wtSeqList):\n",
    "        for position2, codons in enumerate(codon_list):\n",
    "            variant = ''.join(wtSeqList[0:position]) + \\\n",
    "                ''.join(codons) + ''.join(wtSeqList[position+1:])\n",
    "            if (variant == dna_sequence):\n",
    "                if isitthefirstwtseq:\n",
    "                    variant = 'wtSeq' + str(position)\n",
    "                isitthefirstwtseq = True\n",
    "            variants[variant] = 0\n",
    "\n",
    "    # Translate nucleotide sequence and count variant frequency\n",
    "    totalreads = 0\n",
    "    for nuc in SeqIO.parse(trimmedfile, \"fastq\"):\n",
    "        totalreads += 1\n",
    "        nucleicsequence = str(nuc.seq)\n",
    "        if nucleicsequence in variants:\n",
    "            variants[nucleicsequence] += 1\n",
    "    usefulreads = np.nansum(list(variants.values()))\n",
    "\n",
    "    # Convert to df\n",
    "    wtProtein = Seq(dna_sequence).translate()\n",
    "    df = pd.DataFrame()\n",
    "    df['Position'] = np.ravel([[pos]*len(codon_list)\n",
    "                               for pos in np.arange(1, len(wtProtein)+1).astype(int)])\n",
    "    df['Codon'] = codon_list*len(wtProtein)\n",
    "    df['WTCodon'] = np.ravel([[codon]*len(codon_list) for codon in wtSeqList])\n",
    "    df['Aminoacid'] = np.ravel([[aa]*len(codon_list) for aa in wtProtein])\n",
    "    codontable = _codon_table()\n",
    "    df['SynWT'] = df.apply(lambda x: _are_syn(\n",
    "        x['Codon'], x['WTCodon'], codontable), axis=1)\n",
    "    df['Counts'] = list(variants.values())\n",
    "    df.loc[df['Codon'] == df['WTCodon'], 'Counts'] = variants[dna_sequence]\n",
    "\n",
    "    # Pivot table and reindex\n",
    "    df_counts = df.pivot_table(values='Counts', index='Codon',\n",
    "                                     columns=['Position'], dropna=False)\n",
    "    df_counts = df_counts.reindex(index=codon_list)\n",
    "\n",
    "    # Get WT counts\n",
    "    df_wt = df.loc[df['SynWT'] == True]\n",
    "    wt_counts = list(df_wt['Counts'])\n",
    "    wt_counts.insert(0, int([variants[dna_sequence]][0]))\n",
    "\n",
    "    # Export files\n",
    "    if temp_kwargs['savefile']:\n",
    "        # Generate file handles\n",
    "        outputfile_counts = temp_kwargs['outputfilepath'] + \\\n",
    "            temp_kwargs['outputfilename']+\"_counts.txt\"\n",
    "        outputfile_wtcounts = temp_kwargs['outputfilepath'] + \\\n",
    "            temp_kwargs['outputfilename']+\"_wtcounts.txt\"\n",
    "        # Save to txt files\n",
    "        np.savetxt(outputfile_counts, np.array(df_counts), fmt='%i', delimiter='\\t')\n",
    "        np.savetxt(outputfile_wtcounts, wt_counts, fmt='%i', delimiter='\\t')\n",
    "\n",
    "    # Print total reads\n",
    "    print('{}/{} useful reads ({}%)'.format(str(usefulreads),\n",
    "                                            str(totalreads), str(int(usefulreads/totalreads*100))))\n",
    "    return df_counts, wt_counts\n",
    "\n",
    "\n",
    "def _codon_table():\n",
    "    codontable = {'ATA': 'I', 'ATC': 'I', 'ATT': 'I', 'ATG': 'M',\n",
    "                  'ACA': 'T', 'ACC': 'T', 'ACG': 'T', 'ACT': 'T',\n",
    "                  'AAC': 'N', 'AAT': 'N', 'AAA': 'K', 'AAG': 'K',\n",
    "                  'AGC': 'S', 'AGT': 'S', 'AGA': 'R', 'AGG': 'R',\n",
    "                  'CTA': 'L', 'CTC': 'L', 'CTG': 'L', 'CTT': 'L',\n",
    "                  'CCA': 'P', 'CCC': 'P', 'CCG': 'P', 'CCT': 'P',\n",
    "                  'CAC': 'H', 'CAT': 'H', 'CAA': 'Q', 'CAG': 'Q',\n",
    "                  'CGA': 'R', 'CGC': 'R', 'CGG': 'R', 'CGT': 'R',\n",
    "                  'GTA': 'V', 'GTC': 'V', 'GTG': 'V', 'GTT': 'V',\n",
    "                  'GCA': 'A', 'GCC': 'A', 'GCG': 'A', 'GCT': 'A',\n",
    "                  'GAC': 'D', 'GAT': 'D', 'GAA': 'E', 'GAG': 'E',\n",
    "                  'GGA': 'G', 'GGC': 'G', 'GGG': 'G', 'GGT': 'G',\n",
    "                  'TCA': 'S', 'TCC': 'S', 'TCG': 'S', 'TCT': 'S',\n",
    "                  'TTC': 'F', 'TTT': 'F', 'TTA': 'L', 'TTG': 'L',\n",
    "                  'TAC': 'Y', 'TAT': 'Y', 'TAA': '*', 'TAG': '*',\n",
    "                  'TGC': 'C', 'TGT': 'C', 'TGA': '*', 'TGG': 'W'}\n",
    "    return codontable\n",
    "\n",
    "\n",
    "def _are_syn(codon1, codon2, codontable):\n",
    "    '''Determine if 2 codons are synonymous'''\n",
    "    if codon1 == codon2:\n",
    "        return False\n",
    "    if _translate(codon1, codontable) is not _translate(codon2, codontable):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def _translate(seq, codontable):\n",
    "    '''Translate DNA sequence to protein.'''\n",
    "    # I forgot why I made this custom function instead of using a biopython function\n",
    "    protein = ''\n",
    "    if len(seq) % 3 == 0:\n",
    "        for i in range(0, len(seq), 3):\n",
    "            codon = seq[i:i + 3]\n",
    "            protein += codontable[codon]\n",
    "    return protein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process count files and return enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.457484Z",
     "start_time": "2020-09-13T01:45:00.442591Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_enrichment(pre_lib, post_lib, pre_wt=None, post_wt=None, aminoacids=list('AACDEFGGHIKLLLMNPPQRRRSSSTTVVWY*'),\n",
    "                         zeroing='population', how='median', norm_std=True, stopcodon=False, min_counts=25,\n",
    "                         min_countswt=100, std_scale = 0.2, mpop=2, mwt=2, infinite=3, **kwargs):\n",
    "    '''\n",
    "    Determine the enrichment scores of a selection experiment, where there is a preselected population (input)\n",
    "    and a selected population (output).\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    pre_lib : str, pandas dataframe or np.array\n",
    "        Can be filepath and name of the exported txt file, dataframe or np.array.\n",
    "    \n",
    "    post_lib : str, pandas dataframe or np.array\n",
    "        Can be filepath and name of the exported txt file, dataframe or np.array. \n",
    "    \n",
    "    pre_wt : str, or np.array, optional \n",
    "        Str with filepath and name of the exported txt file or np.array.  \n",
    "    \n",
    "    post_wt : str, or np.array, optional \n",
    "        Str with filepath and name of the exported txt file or np.array.  \n",
    "    \n",
    "    aminoacids : list, default ('AACDEFGGHIKLLLMNPPQRRRSSSTTVVWY*')\n",
    "        Index of aminoacids (in order). Stop codon needs to be '*'.\n",
    "    \n",
    "    zeroing : str, default 'population'\n",
    "        Method to zero the data.\n",
    "        Can also use 'counts', wt' or 'kernel'.\n",
    "    \n",
    "    how : str, default 'median'\n",
    "        Metric to zero the data. Only works if zeroing='population' or 'wt'.\n",
    "        Can also be set to 'mean' or 'mode'.\n",
    "    \n",
    "    norm_std : boolean, default True\n",
    "        If norm_std is set to True, it will scale the data.\n",
    "        \n",
    "    stopcodon : boolean, default False\n",
    "        Use the enrichment score stop codons as a metric to determine the minimum enrichment score.\n",
    "    \n",
    "    min_counts : int, default 25\n",
    "        If mutant has less than the min_counts, it will be replaced by np.nan.\n",
    "    \n",
    "    min_countswt : int, default 100 \n",
    "        If synonymous wild-type mutant has less than the min_counts, it will be replaced by np.nan.\n",
    "    \n",
    "    std_scale : float, default 0.2\n",
    "        Factor by which the population is scaled. Only works if norm_std is set to True.\n",
    "    \n",
    "    mpop : int, default 2 \n",
    "        When using the median absolute deviation (MAD) filtering, mpop is the number of medians away\n",
    "        a data point must be to be discarded.\n",
    "        \n",
    "    mwt : int, default 2 \n",
    "        When MAD filtering, mpop is the number of medians away a data point must be to \n",
    "        be discarded. The difference with mpop is that mwt is only used when the population of wild-type \n",
    "        alleles is the reference for data zeroing.\n",
    "        \n",
    "    infinite : int, default 3\n",
    "        It will replace +infinite values with +3 and -infinite with -3.\n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "        savefile : boolean, default False. optional kwarg \n",
    "            If set to true, the function will export the enrichment scores to a txt file.\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    zeroed : ndarray\n",
    "        A np.array containing the enrichment scores. \n",
    "    '''\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "\n",
    "    # Convert to numpy if libraries are in dataframe format.\n",
    "    # If input is a filepath, then load the txt files\n",
    "    if type(pre_lib) is pd.DataFrame:\n",
    "        pre_lib = pre_lib.to_numpy()\n",
    "    elif type(pre_lib) is str:\n",
    "        pre_lib = np.loadtxt(pre_lib)\n",
    "    if type(post_lib) is pd.DataFrame:\n",
    "        post_lib = post_lib.to_numpy()\n",
    "    elif type(post_lib) is str:\n",
    "        post_lib = np.loadtxt(post_lib)\n",
    "    \n",
    "    # Same thing for wt allele files\n",
    "    if type(pre_wt) is str:\n",
    "        pre_wt = np.loadtxt(pre_wt)\n",
    "    if type(post_wt) is str:\n",
    "        post_wt = np.loadtxt(post_wt)\n",
    "        \n",
    "    # Convert to df\n",
    "    pre_lib = _array_to_df_enrichments(pre_lib, aminoacids)\n",
    "    post_lib = _array_to_df_enrichments(post_lib, aminoacids)\n",
    "    \n",
    "    # Locate stop codons\n",
    "    if stopcodon:\n",
    "        input_stopcodon = pre_lib.loc['*'].astype(float)\n",
    "        output_stopcodon = post_lib.loc['*'].astype(float)\n",
    "    else:\n",
    "        input_stopcodon = ''\n",
    "        output_stopcodon = ''\n",
    "\n",
    "    # Log10 of the counts for library and wt alleles\n",
    "    log10_counts = _get_enrichment(pre_lib, post_lib, input_stopcodon,\n",
    "                                   output_stopcodon, min_counts, stopcodon, infinite)\n",
    "    # Group by amino acid\n",
    "    df = pd.DataFrame(data=log10_counts)\n",
    "    log10_counts_grouped = _group_byaa(df, aminoacids)\n",
    "\n",
    "    # MAD filtering\n",
    "    log10_counts_mad = _MAD_filtering(np.ravel(np.array(log10_counts_grouped)), mpop)\n",
    "    mean_pop = np.nanmean(log10_counts_mad)\n",
    "    median_pop = np.nanmedian(log10_counts_mad)\n",
    "    std_pop = np.nanstd(log10_counts_mad)\n",
    "    mode_pop = _nanmode(log10_counts_mad)\n",
    "\n",
    "    # Wt counts\n",
    "    if pre_wt is not None:\n",
    "        log10_wtcounts = _get_enrichment(pre_wt, post_wt, input_stopcodon,\n",
    "                                         output_stopcodon, min_countswt, stopcodon, infinite)\n",
    "        # MAD filtering\n",
    "        # If set to m=1, if tosses out about 50% of the values. the mean barely changes though\n",
    "        log10_wtcounts = _MAD_filtering(log10_wtcounts, mwt)\n",
    "        mean_wt = np.nanmean(log10_wtcounts)\n",
    "        median_wt = np.nanmedian(log10_wtcounts)\n",
    "        std_wt = np.nanstd(log10_wtcounts)\n",
    "        mode_wt = _nanmode(log10_wtcounts)\n",
    "\n",
    "    # Zero data\n",
    "    if zeroing == 'wt':\n",
    "        if how == 'mean':\n",
    "            zeroed = log10_counts_grouped - mean_wt\n",
    "        elif how == 'median':\n",
    "            zeroed = log10_counts_grouped - median_wt\n",
    "        elif how == 'mode':\n",
    "            zeroed = log10_counts_grouped - mode_wt\n",
    "        if norm_std == True:\n",
    "            zeroed = zeroed*std_scale/2/std_wt\n",
    "    elif zeroing == 'population':\n",
    "        if how == 'mean':\n",
    "            zeroed = log10_counts_grouped - mean_pop\n",
    "        elif how == 'median':\n",
    "            zeroed = log10_counts_grouped - median_pop\n",
    "        elif how == 'mode':\n",
    "            zeroed = log10_counts_grouped - mode_pop\n",
    "        if norm_std == True:\n",
    "            zeroed = zeroed*std_scale/std_pop\n",
    "    elif zeroing == 'counts':\n",
    "        # Get the ratio of counts\n",
    "        ratio = np.log10(pre_lib.sum().sum()/post_lib.sum().sum())\n",
    "        zeroed = log10_counts_grouped + ratio\n",
    "        if norm_std == True:\n",
    "            zeroed = zeroed*std_scale/std_pop\n",
    "    elif zeroing == 'kernel':\n",
    "        zeroed_0, kernel_std = _kernel_correction(\n",
    "            log10_counts_grouped, aminoacids)\n",
    "        zeroed, kernel_std = _kernel_correction(zeroed_0, aminoacids, cutoff=1)\n",
    "        if norm_std is True:\n",
    "            zeroed = zeroed*std_scale/kernel_std\n",
    "\n",
    "    # Export files\n",
    "    if temp_kwargs['savefile']:\n",
    "        np.savetxt(temp_kwargs['outputfilepath']+temp_kwargs['outputfilename'],\n",
    "                   zeroed, fmt='%i', delimiter='\\t')\n",
    "\n",
    "    return zeroed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Aux functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.476837Z",
     "start_time": "2020-09-13T01:45:00.458953Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_enrichment(input_lib, output_lib, input_stopcodon, output_stopcodon,\n",
    "                    min_counts, stopcodon, infinite):\n",
    "    '''Calculate log10 enrichment scores from input and output counts'''\n",
    "    # Copy data and replace low counts by np.nan\n",
    "    input_lib = np.copy(input_lib.astype(float))\n",
    "    output_lib = np.copy(output_lib.astype(float))\n",
    "    input_lib[input_lib < min_counts] = np.nan\n",
    "\n",
    "    # Stop codon correction\n",
    "    if stopcodon:\n",
    "        output_lib = _stopcodon_correction(\n",
    "            input_lib, output_lib, input_stopcodon, output_stopcodon)\n",
    "\n",
    "    # log10 of library and replace infinite values\n",
    "    counts_log10_ratio = _replace_inf(np.log10(output_lib/input_lib), infinite)\n",
    "\n",
    "    return counts_log10_ratio\n",
    "\n",
    "\n",
    "def _stopcodon_correction(input_lib, output_lib, input_stopcodon, output_stopcodon):\n",
    "    '''This aux function will take as an input the counts for pre and post selection (and also for wT subset), \n",
    "    and will return the corrected output counts'''\n",
    "\n",
    "    # calculate stop codons frequencies\n",
    "    frequency_stopcodons = output_stopcodon/input_stopcodon\n",
    "\n",
    "    # MAD filtering\n",
    "    frequency_stopcodons_filtered = _MAD_filtering(frequency_stopcodons, m=2)\n",
    "    median_frequency = np.nanmedian(frequency_stopcodons_filtered)\n",
    "\n",
    "    # subtract to output counts\n",
    "    output_lib_corr = output_lib - input_lib*median_frequency\n",
    "\n",
    "    # eliminate negative values so they wont get turned into np.nan\n",
    "    output_lib_corr[output_lib_corr < 0] = 0\n",
    "\n",
    "    return output_lib_corr\n",
    "\n",
    "\n",
    "def _MAD_filtering(data, m=2):\n",
    "    '''This aux function will take a numpy array, calculate median and MAD, \n",
    "    and filter the data removing outliers'''\n",
    "\n",
    "    # turn data into df to do mad calculations\n",
    "    df = pd.DataFrame(np.array(data), columns=['Data'])\n",
    "    median = df['Data'].median(axis=0)\n",
    "    mad = df['Data'].mad(axis=0)\n",
    "    df['Abs_Dev'] = np.abs(data-median)/mad\n",
    "\n",
    "    # filter values m times away from median, by default m = 2\n",
    "    df['Abs_Dev'].mask(df['Abs_Dev'] > m, inplace=True)  # mask values\n",
    "    df.dropna(how='any', inplace=True)  # eliminte NANs\n",
    "\n",
    "    return df['Data'].to_numpy()\n",
    "\n",
    "\n",
    "def _replace_inf(array, infinite):\n",
    "    '''Replace values over a threshold with a min or max value'''\n",
    "    np.warnings.filterwarnings('ignore')\n",
    "    array[array == -np.inf] = -infinite\n",
    "    array[array < -infinite] = -infinite\n",
    "    array[array == +np.inf] = +infinite\n",
    "    array[array > +infinite] = +infinite\n",
    "    return array\n",
    "\n",
    "\n",
    "def _group_byaa(df, aminoacids):\n",
    "    '''Group different codons that are synonymous'''\n",
    "    # copy df\n",
    "    df = df.copy()\n",
    "\n",
    "    # Set up amino acid column\n",
    "    df['Aminoacid'] = aminoacids\n",
    "\n",
    "    # Group by mean\n",
    "    df = df.groupby(as_index=True, by='Aminoacid', sort= False).mean()\n",
    "    return df\n",
    "\n",
    "\n",
    "def _nanmode(data):\n",
    "    '''input is wt log enrichments, and return the mode of the histogram \n",
    "    (aka the x coordinate at which y is max)'''\n",
    "    \n",
    "    # Copy data\n",
    "    data = np.copy(data)\n",
    "    # Remove NaN values\n",
    "    data_corrected = data[np.invert(np.isnan(data))]\n",
    "    # Adjust kernel\n",
    "    kernel_processed_data = stats.gaussian_kde(data_corrected)\n",
    "    # Find mode\n",
    "    indexmax = np.where(kernel_processed_data(data_corrected)\n",
    "                        == kernel_processed_data(data_corrected).max())\n",
    "    # Return mean in case there are two x values with equal y-axis height\n",
    "    return data_corrected[indexmax].mean()\n",
    "\n",
    "\n",
    "# corrects the mutagenesis data and returns the height of the peak\n",
    "def _kernel_correction(data, aminoacids, cutoff=2):\n",
    "    '''input the library matrix, returns the corrected version. I set to 0 the max of the peak of the normal dist\n",
    "    ignores stop codons. Not used for dataframes, only numpy arrays'''\n",
    "\n",
    "    # Get data into right format\n",
    "    data_corrected, kernel_processed_data = _kernel_datapreparation(data, cutoff) \n",
    "                                                                    \n",
    "    # Find max of kernel peak\n",
    "    indexmax = np.where(kernel_processed_data(data_corrected) ==\n",
    "                        kernel_processed_data(data_corrected).max())\n",
    "\n",
    "    # Normalize the max of peak os it has an x = 0\n",
    "    data_final = data-data_corrected[indexmax].mean()\n",
    "\n",
    "    # find std of kernel. It uses the already max peak x=0 normalized data\n",
    "    data_final_flatten, data_final_kernel_processed_data = _kernel_datapreparation(\n",
    "        data_final, cutoff)\n",
    "    std = _kernel_std(data_final_flatten, data_final_kernel_processed_data)\n",
    "\n",
    "    return data_final, std\n",
    "\n",
    "\n",
    "def _kernel_datapreparation(data, cutoff):\n",
    "    '''this function will copy the data, eliminate stop codon, eliminate values lower than -1, \n",
    "    flatten and eliminate np.nan. Will return the data in that format + the adjusted kernel'''\n",
    "    # Eliminate stop codon\n",
    "    data_corrected = np.array(data.drop('*', errors = 'ignore').copy())\n",
    "    \n",
    "    # Eliminate values lower than -1\n",
    "    data_corrected = data_corrected[(\n",
    "        data_corrected >= -cutoff) & (data_corrected <= cutoff)]\n",
    "\n",
    "    # Get rid of np.nan values and convert matrix into 1d matrix\n",
    "    data_corrected = data_corrected[np.invert(np.isnan(data_corrected))]\n",
    "\n",
    "    # Adjust gaussian kernel\n",
    "    kernel_processed_data = stats.gaussian_kde(data_corrected)\n",
    "\n",
    "    return data_corrected, kernel_processed_data\n",
    "\n",
    "\n",
    "def _kernel_std(data, kernel):\n",
    "    '''input the library matrix (and wont count stop codon), and will return the std of the normal distribution.\n",
    "    To calculate the std, it will find the FWHM and divide by 2.355\n",
    "    https://en.wikipedia.org/wiki/Full_width_at_half_maximum\n",
    "    The algorithm will give back the min std between both sides of the peak'''\n",
    "\n",
    "    # find ymax and the x value of the max height\n",
    "    y_max = kernel(data).max()\n",
    "    index_y_max = np.where(kernel(data) == y_max)\n",
    "    x_ymax = data[index_y_max].mean()\n",
    "\n",
    "    # find the two x value of ymax/2. One at each side of the center. l of left and r of right\n",
    "    # so I can select only the positive side of the distribution\n",
    "    y_temp = kernel(data)\n",
    "\n",
    "    # left side\n",
    "    y_hw_l = (min(y_temp[data < 0], key=lambda x: abs(x-y_max/2)))\n",
    "    index_yhw_l = np.where(kernel(data) == y_hw_l)\n",
    "    x_yhw_l = data[index_yhw_l].mean()\n",
    "\n",
    "    # right side\n",
    "    y_hw_r = (min(y_temp[data > 0], key=lambda x: abs(x-y_max/2)))\n",
    "    index_yhw_r = np.where(kernel(data) == y_hw_r)\n",
    "    x_yhw_r = data[index_yhw_r].mean()\n",
    "\n",
    "    # calculate half width at half maximum\n",
    "    hwhm_l = abs(x_yhw_l - x_ymax)\n",
    "    hwhm_r = abs(x_yhw_r - x_ymax)\n",
    "\n",
    "    # calculate std from fwhm\n",
    "    std_l = hwhm_l/((2*np.log(2))**0.5)\n",
    "    std_r = hwhm_r/((2*np.log(2))**0.5)\n",
    "\n",
    "    return min(std_l, std_r)\n",
    "\n",
    "\n",
    "def _array_to_df_enrichments(lib, aminoacids):\n",
    "    '''aux function to transform array in df with index of amino acids'''\n",
    "    df = pd.DataFrame(index=aminoacids, data=lib)\n",
    "    return df.astype(float)\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble sublibraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.490638Z",
     "start_time": "2020-09-13T01:45:00.479031Z"
    }
   },
   "outputs": [],
   "source": [
    "def assemble_avengers(excel_path, sheet_pre, sheet_post, columns,\n",
    "                      nrows_pop, nrows_wt, columns_wt=None, skiprows=1,\n",
    "                      aminoacids=list('AACDEFGGHIKLLLMNPPQRRRSSSTTVVWY*'),\n",
    "                      zeroing='population', how='median', norm_std=True, \n",
    "                      stopcodon=False, min_counts=25, min_countswt=100, \n",
    "                      std_scale=0.2, mpop=2, mwt=2, infinite=3, **kwargs):\n",
    "    '''\n",
    "    Assembles different sublibraries into one. Uses calculate_enrichments. \n",
    "    Can only read from excel files that are in the same format as the example provided.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    excel_path : str\n",
    "        Location of the excel file to read.\n",
    "\n",
    "    sheet_pre : str\n",
    "        Name of the sheet with input (pre-selected) counts.\n",
    "\n",
    "    sheet_post : str\n",
    "        Name of the sheet with output (post-selected) counts.\n",
    "\n",
    "    columns : list\n",
    "        List of columns for each sublibrary to read from the excel file.\n",
    "\n",
    "    nrows_pop : int, \n",
    "        Number of rows to read from the excel.\n",
    "\n",
    "    nrows_wt : list, \n",
    "        Contains a list of integers, with the number of rows to read from each wt subset.\n",
    "\n",
    "    columns_wt : list,\n",
    "        Contains a list of strings, specifying the excel columns to read for each wt subset.\n",
    "    \n",
    "    skiprows : int, default 1\n",
    "        Parameter for pd.read_excel. Only works for the main columns, not for wt.\n",
    "    \n",
    "    aminoacids : list, default ('AACDEFGGHIKLLLMNPPQRRRSSSTTVVWY*')\n",
    "        Index of aminoacids (in order). Stop codon needs to be '*'.\n",
    "\n",
    "    zeroing : str, default 'population'\n",
    "        Method to zero the data.\n",
    "        Can also use 'counts', wt' or 'kernel'.\n",
    "\n",
    "    how : str, default 'median'\n",
    "        Metric to zero the data. Only works if zeroing='population' or 'wt'.\n",
    "        Can also be set to 'mean' or 'mode'.\n",
    "\n",
    "    norm_std : boolean, default True\n",
    "        If norm_std is set to True, it will scale the data.\n",
    "\n",
    "    stopcodon : boolean, default False\n",
    "        Use the enrichment score stop codons as a metric to determine the minimum enrichment score.\n",
    "\n",
    "    min_counts : int, default 25\n",
    "        If mutant has less than the min_counts, it will be replaced by np.nan.\n",
    "\n",
    "    min_countswt : int, default 100 \n",
    "        If synonymous wild-type mutant has less than the min_counts, it will be replaced by np.nan.\n",
    "\n",
    "    std_scale : float, default 0.2\n",
    "        Factor by which the population is scaled. Only works if norm_std is set to True.\n",
    "\n",
    "    mpop : int, default 2 \n",
    "        When using the median absolute deviation (MAD) filtering, mpop is the number of medians away\n",
    "        a data point must be to be discarded.\n",
    "\n",
    "    mwt : int, default 2 \n",
    "        When MAD filtering, mpop is the number of medians away a data point must be to \n",
    "        be discarded. The difference with mpop is that mwt is only used when the population of wild-type \n",
    "        alleles is the reference for data zeroing.\n",
    "\n",
    "    infinite : int, default 3\n",
    "        It will replace +infinite values with +3 and -infinite with -3.\n",
    "\n",
    "    **kwargs : other keyword arguments\n",
    "        savefile : boolean, default False. optional kwarg \n",
    "            If set to true, the function will export the enrichment scores to a txt file.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    df : Pandas dataframe\n",
    "        A dataframe that contains the enrichment scores of the assembled sublibraries.\n",
    "    '''\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    \n",
    "    # Read reads from excel\n",
    "    list_pre, list_sel, list_pre_wt, list_sel_wt = _read_counts(excel_path, sheet_pre, sheet_post, columns,\n",
    "                                                                nrows_pop, nrows_wt, columns_wt)\n",
    "\n",
    "    # Assemble sublibraries\n",
    "    df = _assemble_list(list_pre, list_sel, list_pre_wt, list_sel_wt,\n",
    "                        aminoacids, zeroing, how, norm_std, stopcodon, min_counts,\n",
    "                        min_countswt, std_scale, mpop, mwt, infinite, **kwargs)\n",
    "    \n",
    "        # Export files\n",
    "    if temp_kwargs['savefile']:\n",
    "        np.savetxt(temp_kwargs['outputfilepath']+temp_kwargs['outputfilename'],\n",
    "                   zeroed, fmt='%i', delimiter='\\t')\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def _read_counts(excel_path, sheet_pre, sheet_post, columns,\n",
    "                 nrows_pop, nrows_wt, columns_wt=None, skiprows=1):\n",
    "    '''Aux'''\n",
    "    # Create dictionary with data. Loading 3 replicates, each of them is divided into 3 pools\n",
    "    list_pre, list_sel, list_pre_wt, list_sel_wt = ([] for i in range(4))\n",
    "\n",
    "    # Read counts from excel\n",
    "    replicates = np.arange(0, len(sheet_pre))\n",
    "    for column, column_wt, nrow_wt, rep in zip(columns, columns_wt, nrows_wt, replicates):\n",
    "        # Pre counts\n",
    "        list_pre.append(pd.read_excel(excel_path, sheet_pre,\n",
    "                                      skiprows=skiprows, usecols=column, nrows=nrows_pop))\n",
    "        # Sel counts\n",
    "        list_sel.append(pd.read_excel(excel_path, sheet_post,\n",
    "                                      skiprows=skiprows, usecols=column, nrows=nrows_pop))\n",
    "        if columns_wt is None:\n",
    "            list_pre_wt.append(None)\n",
    "            list_sel_wt.append(None)\n",
    "        else:\n",
    "            # Pre counts wild-type alleles\n",
    "            list_pre_wt.append(pd.read_excel(\n",
    "                excel_path, sheet_pre, usecols=column_wt, nrows=nrow_wt))\n",
    "            # Sel counts wild-type alleles\n",
    "            list_sel_wt.append(pd.read_excel(\n",
    "                excel_path, sheet_post, usecols=column_wt, nrows=nrow_wt))\n",
    "    return list_pre, list_sel, list_pre_wt, list_sel_wt\n",
    "\n",
    "\n",
    "def _assemble_list(list_pre, list_sel, list_pre_wt, list_sel_wt, aminoacids, zeroing,\n",
    "                   how, norm_std, stopcodon, min_counts,\n",
    "                   min_countswt, std_scale, mpop, mwt, infinite, **kwargs):\n",
    "    '''gets the output from _read_counts and assembles the sublibraries'''\n",
    "    \n",
    "    enrichment_lib = []\n",
    "    \n",
    "    for pre, sel, pre_wt, sel_wt in zip(list_pre, list_sel, list_pre_wt, list_sel_wt):\n",
    "        # log 10\n",
    "        enrichment_log10 = calculate_enrichment(pre, sel, pre_wt, sel_wt, aminoacids, zeroing,\n",
    "                                                how, norm_std, stopcodon, min_counts,\n",
    "                                                min_countswt, std_scale, mpop, mwt, infinite, **kwargs)\n",
    "        # Store in list\n",
    "        enrichment_lib.append(enrichment_log10)\n",
    "\n",
    "    # Concatenate sublibraries\n",
    "    df = pd.concat(enrichment_lib, ignore_index=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge enrichment with MSA conservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.502953Z",
     "start_time": "2020-09-13T01:45:00.493037Z"
    }
   },
   "outputs": [],
   "source": [
    "def msa_enrichment(self, path, start_position, threshold=0.01):\n",
    "    '''\n",
    "    Generate a dataframe with the Shannon entropy by residue and the mean enrichment score, and\n",
    "    a second dataframe with the frequency of each substitution and the enrichment score\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    path : str\n",
    "        Path where is located the fasta MSA that will be parsed. That MSA needs to have removed \n",
    "        any insertions that are not present in the target sequence. For example, if a Ras ortholog has \n",
    "        an extra amino acid at position 123, that needs to be removed from the aligment. Otherwise, everything\n",
    "        will be shifted by 1 residue.\n",
    "    \n",
    "    start_position : int\n",
    "        This is the position in the protein sequence of the first position in the MSA\n",
    "    \n",
    "    threshold : float, default 0.01\n",
    "        The conservation frequency for each amino acid subsitution will be binarized, and a threshold between 0-1 \n",
    "        needs to be selected.\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    df_shannon: pandas dataframe\n",
    "        Shannon entropy by residue and mean enrichment score by residue. \n",
    "    \n",
    "    df_freq : pandas dataframe   \n",
    "        Frequency of each susbsitution merged to the enrichment score.\n",
    "    '''\n",
    "    # Read MSA\n",
    "    msa, seq_lengths, index = shannon.parseMSA(path,\"fasta\",0)\n",
    "\n",
    "    # Calculate Shannon entropy from alignment\n",
    "    shannon_entropy = shannon.shannon_entropy_list_msa(msa)\n",
    "    \n",
    "    # Merge enrichment scores and MSA conservation\n",
    "    df_freq = _merge_msa_enrichment(self,_msa_to_df(msa),start_position,threshold)\n",
    "    \n",
    "    # Merge shannon and mean enrichment score\n",
    "    df_shannon = _merge_shannon_enrichment(self,shannon_entropy,start_position)\n",
    "    \n",
    "    return  df_shannon, df_freq\n",
    "\n",
    "def _merge_shannon_enrichment(self,shannon_entropy,start_position):\n",
    "        \n",
    "    # Create df with shannon entropy by residue and average enrichment score by residue\n",
    "    df_shannon = pd.DataFrame()\n",
    "    df_shannon['Position'] = np.arange(start_position, len(shannon_entropy)+start_position)\n",
    "    df_shannon['Shannon'] = shannon_entropy\n",
    "    \n",
    "    # group by enrichment scores\n",
    "    df_enrichment = self.dataframe.groupby(by='Position', as_index=False).mean()\n",
    "    \n",
    "    # Merge Shannon with enrichment scores\n",
    "    df_shannon = df_shannon.merge(df_enrichment, how='inner', on=['Position'])\n",
    "    \n",
    "    return df_shannon\n",
    "\n",
    "def _flatten_msa(msa):\n",
    "    '''Flatten an msa so each sequence is in one string'''\n",
    "    msa_flattened = []\n",
    "    for sequence in msa:\n",
    "        msa_flattened.append(''.join(sequence))\n",
    "    return msa_flattened\n",
    "\n",
    "def _msa_to_df(msa,correctionfactor=1):\n",
    "    '''Convert a msa from a fasta file into a df ready to plot with logomaker. Returns frequency'''\n",
    "    # Flatten MSA\n",
    "    msa_flattened = _flatten_msa(msa)\n",
    "\n",
    "    # Make matrix\n",
    "    df = logomaker.alignment_to_matrix(msa_flattened)\n",
    "\n",
    "    # Reindex\n",
    "    df.index = np.arange(correctionfactor,len(df)+correctionfactor)\n",
    "    \n",
    "    # Return only common aa \n",
    "    aminoacids = list ('ACDEFGHIKLMNPQRSTVWY')\n",
    "    \n",
    "    # Normalize by the total number of counts\n",
    "    df_final = df[aminoacids].copy()\n",
    "    \n",
    "    return df_final/df_final.sum(axis=1).max()\n",
    "\n",
    "\n",
    "def _merge_msa_enrichment(self, df_msa, start_position, threshold):\n",
    "    '''merges msa conservation of each individual amino acid with the enrichment scores'''\n",
    "    \n",
    "    # make a dataframe\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Create column with position and aminoacid label\n",
    "    df['Position'] = np.ravel([[i]*len(df_msa.T) for i in range(start_position, len(df_msa)+start_position)])\n",
    "    df['Aminoacid'] = list(df_msa.columns) * len(df_msa)\n",
    "\n",
    "    # Add conservation from MSA\n",
    "    df['Conservation'] = list(df_msa.stack(dropna=False))\n",
    "\n",
    "    # Merge with enrichment scores\n",
    "    df_merged = self.dataframe.merge(df, how='inner', on=['Position', 'Aminoacid'])\n",
    "\n",
    "    # Copycat conservation\n",
    "    df_merged['Class'] = df_merged['Conservation']\n",
    "\n",
    "    # Binarize conservation scores. 0 means not conserved\n",
    "    df_merged.loc[df_merged['Conservation']>threshold, 'Class'] = 1\n",
    "    df_merged.loc[df_merged['Conservation']<=threshold, 'Class'] = 0\n",
    "    return df_merged\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T22:32:16.564477Z",
     "start_time": "2020-09-13T22:32:16.551596Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_kernel(self, kernel='gau', kernel_label='KDE', histogram=False,\n",
    "                fit=None, fit_label='_nolegend_', extra_dist=None,\n",
    "                extra_dist_label='_nolegend_',  **kwargs):\n",
    "    '''\n",
    "    Generate a kernel density plot. If specified it can also draw a histogram. Uses sns.distplot.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    kernel : str, default gau\n",
    "        options are ['biw','cos','epa','gau','tri','triw']\n",
    "    \n",
    "    kernel_label : str, default '_nolegend_'\n",
    "    \n",
    "    histogram : boolean, default False\n",
    "    \n",
    "    fit : boolean, optional\n",
    "        ask sns.distplot to fit a function\n",
    "    \n",
    "    fit_label : str, default '_nolegend_'\n",
    "    \n",
    "    extra_dist : [x,y], optional\n",
    "        fit any distribution you want. Input the x and y coordinates\n",
    "    \n",
    "    extra_dist_label : str, default '_nolegend_'\n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "    '''\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    temp_kwargs['figsize'] = kwargs.get('figsize', (2.5, 2))\n",
    "\n",
    "    # create figure\n",
    "    fig = plt.figure(figsize=temp_kwargs['figsize'])\n",
    "\n",
    "    # import parameters\n",
    "    _parameters()\n",
    "\n",
    "    # plot\n",
    "    ax = sns.distplot(self.dataframe['Score_NaN'], kde=True, hist=histogram, norm_hist=True,\n",
    "                      kde_kws={'kernel': kernel, 'color': temp_kwargs['color'], 'lw': 2, 'label': kernel_label}, fit=fit,\n",
    "                      fit_kws={'label': fit_label, 'linestyle': 'dotted', 'color': 'red'})\n",
    "\n",
    "    # plot extra distribution\n",
    "    if extra_dist is not None:\n",
    "        plt.plot(extra_dist[0], extra_dist[1], linewidth=2, linestyle='dotted',\n",
    "                 color='green', label=extra_dist_label)\n",
    "\n",
    "    # tune graph\n",
    "    plt.xlabel(r'$∆E^i_x$', fontsize=10,\n",
    "               fontname='Arial', color='k', labelpad=0)\n",
    "    plt.ylabel('Probability density', fontsize=10,\n",
    "               fontname='Arial', color='k', labelpad=3)\n",
    "    plt.title(temp_kwargs['title'], fontsize=12, fontname='Arial', color='k')\n",
    "    plt.xlim(temp_kwargs['xscale'])\n",
    "    plt.grid()\n",
    "    ax.legend(loc='best', frameon=False, fontsize=9,\n",
    "              handlelength=1, handletextpad=0.5)\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "\n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def _parameters():\n",
    "    # normal font\n",
    "    rcParams['font.family'] = 'sans-serif'\n",
    "    rcParams['font.sans-serif'] = ['Arial']\n",
    "\n",
    "    # math font\n",
    "    rcParams['mathtext.fontset'] = 'custom'\n",
    "    rcParams['mathtext.rm'] = 'Arial'\n",
    "    rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "    # add grid\n",
    "    rcParams['grid.color'] = 'silver'\n",
    "    rcParams['grid.linestyle'] = '--'\n",
    "    rcParams['grid.linewidth'] = 1\n",
    "    rcParams['lines.dashed_pattern'] = [5, 10]\n",
    "    rcParams['axes.axisbelow'] = True\n",
    "    # Parameters for all graphs\n",
    "    rcParams['xtick.labelsize'] = 9\n",
    "    rcParams['ytick.labelsize'] = 9\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Kernel plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.528641Z",
     "start_time": "2020-09-13T01:45:00.520085Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_multiplekernel(dict_entries, kernel='gau',\n",
    "                        colors=['k', 'crimson', 'dodgerblue', 'g', 'silver'], **kwargs):\n",
    "    '''\n",
    "    Generate a kernel density plot for multiple objects passed as a dictionary.\n",
    "    If specified it can also draw a histogram. Uses sns.distplot. Can manage either Screen objects\n",
    "    or dataframes out of the calculate_enrichments function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dict_entries : dictionary containing dataframes\n",
    "        Allows for either putting multiple objects as inputs or to use dataframes \n",
    "        that come out of the calculate_enrichments function. If you use an object, \n",
    "        you need to say object.dataframe.\n",
    "\n",
    "    kernel : str, default gau\n",
    "        options are ['biw','cos','epa','gau','tri','triw'].\n",
    "\n",
    "    colors : list, default ['k', 'crimson', 'dodgerblue', 'g', 'silver']\n",
    "        List of the colors (in order of arguments) that the kernels will have.\n",
    "\n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "    '''\n",
    "\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    temp_kwargs['figsize'] = kwargs.get('figsize', (3.5, 2))\n",
    "    temp_kwargs['xscale'] = kwargs.get('xscale', (-2, 2))\n",
    "\n",
    "    # hard copy of data\n",
    "    dict_copy = copy.deepcopy(dict_entries)\n",
    "\n",
    "    # create figure\n",
    "    fig = plt.figure(figsize=temp_kwargs['figsize'])\n",
    "\n",
    "    # import parameters\n",
    "    _parameters()\n",
    "\n",
    "    # plot (allows two types of data input)\n",
    "    for (label, dataset, color) in zip(dict_copy.keys(), dict_copy.values(), colors[0:len(dict_copy)]):\n",
    "        if 'Score' in dataset.columns:\n",
    "            # plot objects scores\n",
    "            sns.distplot(dataset['Score_NaN'], hist=False,\n",
    "                         kde_kws={\"color\": color, \"lw\": 2, \"label\": label})\n",
    "        else:\n",
    "            # get rid of stop codons\n",
    "            dataset.drop('*', errors='ignore', inplace=True)\n",
    "            dataset = dataset.stack()\n",
    "            # plot stacked matrix\n",
    "            sns.distplot(dataset[~numpy.isnan(dataset)], kde=True, hist=False, \n",
    "                         kde_kws={\"color\": color, \"lw\": 2, \"label\": label})\n",
    "\n",
    "    # tune graph\n",
    "    plt.xlabel(r'$∆E^i_x$', fontsize=10,\n",
    "               fontname='Arial', color='k', labelpad=0)\n",
    "    plt.ylabel('Probability density', fontsize=10,\n",
    "               fontname='Arial', color='k', labelpad=3)\n",
    "    plt.title(temp_kwargs['title'], fontsize=12, fontname='Arial', color='k')\n",
    "    plt.xlim(temp_kwargs['xscale'])\n",
    "    plt.grid()\n",
    "    plt.legend(dict_copy.keys(), loc='best', frameon=False, fontsize=9,\n",
    "               handlelength=1, handletextpad=0.5)\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "\n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.572763Z",
     "start_time": "2020-09-13T01:45:00.530989Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_heatmap(self, nancolor='lime', show_cartoon=False, show_snv = False, **kwargs):\n",
    "    '''\n",
    "    Generate a heatmap plot of the enrichment scores.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    nancolor : str, default 'lime'\n",
    "        Will color np.nan values with the specified color.\n",
    "    \n",
    "    show_carton : boolean, default False\n",
    "        If true, the plot will display a cartoon with the secondary structure. The user must have added the secondary structure to the object. \n",
    "    \n",
    "    show_snv : boolean, default False\n",
    "        If true, it will only display mutants that are a single nucleotide variant (SNV) of the wild-type\n",
    "        protein sequence. The algorithm does not take into account the wild-type DNA allele, so it \n",
    "        will include any possible mutant that is one base away.\n",
    "        \n",
    "    **kwargs : other keyword arguments\n",
    "        \n",
    "    Returns\n",
    "    ----------\n",
    "    None    \n",
    "    '''\n",
    "    # load font parameters\n",
    "    _font_parameters()\n",
    "\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "\n",
    "    # load labels\n",
    "    temp_kwargs['color_sequencelabels'] = _labels(self.start_position)[0]\n",
    "    temp_kwargs['number_sequencelabels'] = _labels(self.start_position)[1]\n",
    "\n",
    "    # sort data in specified order by user\n",
    "    df = _df_rearrange(_add_SNV_boolean(self.dataframe_stopcodons.copy()),\n",
    "                            temp_kwargs['neworder_aminoacids'], values='Score_NaN', show_snv = show_snv)\n",
    "\n",
    "    # declare figure and subplots\n",
    "    figwidth = 14*len(df.columns)/165\n",
    "\n",
    "    # Change parameters depending on whether cartoon is on or off\n",
    "    if show_cartoon:\n",
    "        figheight = 2.45\n",
    "        fig = plt.figure(figsize=(figwidth, figheight))\n",
    "        gs = gridspec.GridSpec(nrows=3, ncols=2, height_ratios=[\n",
    "                               len(df), 1, 5], width_ratios=[len(df.columns), 1])\n",
    "    else:\n",
    "        figheight = 2\n",
    "        fig = plt.figure(figsize=(figwidth, figheight))\n",
    "        gs = gridspec.GridSpec(nrows=2, ncols=2, height_ratios=[\n",
    "                               len(df), 1], width_ratios=[len(df.columns), 1])\n",
    "\n",
    "    ax = plt.subplot(gs[0, 0])\n",
    "    averageresidue = plt.subplot(gs[1, 0])\n",
    "    cbar1 = plt.subplot(gs[0, 1])\n",
    "    cbar2 = plt.subplot(gs[1, 1])\n",
    "\n",
    "    # Change color of values that are NaN\n",
    "    cmap = temp_kwargs['colormap']\n",
    "    cmap.set_bad(color=nancolor)\n",
    "\n",
    "    # main heatmap\n",
    "    heatmap = ax.pcolormesh(df, vmin=temp_kwargs['colorbar_scale'][0], vmax=temp_kwargs['colorbar_scale'][1],\n",
    "                            cmap=cmap, edgecolors='k', linewidths=0.2, antialiased=True, color='darkgrey')\n",
    "\n",
    "    # average of residues by positon\n",
    "    average = [_add_SNV_boolean(self.dataframe.copy()).groupby(by='Position').mean()['Score_NaN']]\n",
    "\n",
    "    # average by position\n",
    "    heatmapaverageresidues = averageresidue.pcolormesh(average, vmin=temp_kwargs['colorbar_scale'][0], vmax=temp_kwargs['colorbar_scale'][1],\n",
    "                        cmap=cmap, edgecolors='k', linewidths=0.2, antialiased=True, color='darkgrey')\n",
    "\n",
    "    # ____________axes manipulation____________________________________________\n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_xticks(np.arange(len(df.columns)) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(len(df)) + 0.5, minor=False)\n",
    "\n",
    "    # position of axis labels\n",
    "    ax.tick_params('x', direction='out', pad=-2.5)\n",
    "    ax.tick_params('y', direction='out', pad=0.4)\n",
    "\n",
    "    # make new axes\n",
    "    ax2 = ax.twiny()\n",
    "    ax3 = ax.twinx()\n",
    "\n",
    "    # tune the axes\n",
    "    ax2.set_xticks(np.arange(len(df.columns)) + 0.5, minor=False)\n",
    "    ax3.set_yticks(np.arange(len(df)) + 0.5, minor=False)\n",
    "    ax2.tick_params(direction='out', pad=4)\n",
    "    ax3.tick_params(direction='out', pad=0.4)\n",
    "    averageresidue.tick_params(direction='out', pad=-2)\n",
    "    averageresidue.set_xticks(np.arange(len(df.columns)) + 0.5, minor=False,)\n",
    "    averageresidue.set_yticks(np.arange(0.5)+0.5)\n",
    "\n",
    "    # Set the limits of the new axis from the original axis limits\n",
    "    ax2.set_xlim(ax.get_xlim())\n",
    "    ax3.set_ylim(ax.get_ylim())\n",
    "\n",
    "    # want a more natural, table-like display\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    "    ax3.invert_yaxis()\n",
    "\n",
    "    # remove ticks\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax2.yaxis.set_ticks_position('none')\n",
    "    ax2.xaxis.set_ticks_position('none')\n",
    "    ax3.yaxis.set_ticks_position('none')\n",
    "    averageresidue.xaxis.set_ticks_position('none')\n",
    "    averageresidue.yaxis.set_ticks_position('none')\n",
    "\n",
    "    # so labels of x and y do not show up and my labels show up instead\n",
    "    ax.set_xticklabels(list(self.sequence), fontsize=6.5,\n",
    "                       fontname=\"Arial\", color='k', minor=False)\n",
    "    ax.set_yticklabels(temp_kwargs['neworder_aminoacids'], fontsize=6,\n",
    "                       fontname=\"Arial\", color='k', minor=False)\n",
    "    ax2.set_xticklabels(temp_kwargs['number_sequencelabels'][0:len(df.columns)],\n",
    "                        fontsize=10, fontname=\"Arial\", color='k', minor=False)\n",
    "    ax3.set_yticklabels(temp_kwargs['neworder_aminoacids'],\n",
    "                        fontsize=6, fontname=\"Arial\", color='k', minor=False)\n",
    "    averageresidue.set_xticklabels(list(self.sequence), fontsize=6.5,\n",
    "                                   fontname=\"Arial\", color='k', minor=False)\n",
    "    rowaverage = ''\n",
    "    averageresidue.set_yticklabels(\n",
    "        rowaverage, fontsize=6, fontname=\"Arial\", color='k', minor=False)\n",
    "\n",
    "    # align the labels of the y axis\n",
    "    for ylabel in ax.get_yticklabels():\n",
    "        ylabel.set_horizontalalignment('center')\n",
    "    for ylabel in ax3.get_yticklabels():\n",
    "        ylabel.set_horizontalalignment('center')\n",
    "\n",
    "    # for coloring the residues that are 10,20...\n",
    "    for xtick, color in zip(ax.get_xticklabels(), temp_kwargs['color_sequencelabels']):\n",
    "        xtick.set_color(color)\n",
    "    for xtick, color in zip(averageresidue.get_xticklabels(), temp_kwargs['color_sequencelabels']):\n",
    "        xtick.set_color(color)\n",
    "    # _____________________________________________________________________________\n",
    "\n",
    "    # for color bar format\n",
    "    cbar1.axis('off')\n",
    "    cbar2.axis('off')\n",
    "    cb = plt.colorbar(heatmap, fraction=1, pad=0, ax=[cbar1], aspect=5, ticks=[temp_kwargs['colorbar_scale'][0], np.mean(\n",
    "        temp_kwargs['colorbar_scale']), temp_kwargs['colorbar_scale'][1]], orientation='vertical')\n",
    "    cb.ax.set_yticklabels(cb.ax.get_yticklabels(),\n",
    "                          fontsize=6, fontname=\"Arial\", color='k')\n",
    "    cb.update_ticks()\n",
    "    plt.text(1.2+10/len(df.columns), 0.7, r'$\\langle∆E^x_i\\rangle_x$', transform=cbar1.transAxes,\n",
    "             horizontalalignment='center', fontsize=7, fontname=\"Arial\", color='k')\n",
    "\n",
    "    gs.update(hspace=0.1, wspace=0.1/len(df.columns)*50)\n",
    "\n",
    "    # for putting title on graph\n",
    "    plt.title(temp_kwargs['title'], horizontalalignment='center',\n",
    "              fontname=\"Arial\", fontsize=12)\n",
    "\n",
    "    # Cartoon\n",
    "    if show_cartoon:\n",
    "        _generate_cartoon(self, gs, 2, temp_kwargs['cartoon_colors'], 0.025)\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def _labels(start_position=1):\n",
    "    # residue label and color\n",
    "    emptylist = [''] * 1000\n",
    "    number_sequencelabels = list(['b' if index in np.arange(\n",
    "        10-(start_position % 10), 1000, 10) else 'k' for index, x in enumerate(emptylist)])\n",
    "    color_sequencelabels = list([index+start_position if index in np.arange(10 -\n",
    "                                                                            (start_position % 10), 1000, 10) else '' for index, x in enumerate(emptylist)])\n",
    "    return number_sequencelabels, color_sequencelabels\n",
    "\n",
    "\n",
    "def _font_parameters():\n",
    "    # math font\n",
    "    rcParams['mathtext.fontset'] = 'custom'\n",
    "    rcParams['mathtext.rm'] = 'Arial'\n",
    "    rcParams['svg.fonttype'] = 'none'\n",
    "    return\n",
    "\n",
    "\n",
    "def generatecolormap():\n",
    "    cmap = LinearSegmentedColormap(\n",
    "        'BlueWhiteRed',\n",
    "        {\n",
    "            'red':  ((0.0, 0.0, 0.0),\n",
    "                     (0.15, 0.0, 0.0),\n",
    "                     (0.475, 1.0, 1), (0.525, 1.0, 1), (0.85, 1.0, 1.0), (1.0, .8, 1)),\n",
    "            'green': ((0.0, 0.0, .0),\n",
    "                      (0.15, 0.5, 0.5), (0.475, 1.0,\n",
    "                                         1), (0.525, 1.0, 1), (0.85, 0.0, 0.0),\n",
    "                      (1.0, 0.0, 0.0)),\n",
    "            'blue': ((0.0, .5, .5),\n",
    "                     (0.15, 1, 1),\n",
    "                     (0.475, 1.0, 1), (0.525, 1.0, 1), (0.85, 0.0, 0.0), (1.0, 0.0, 0.0))\n",
    "        },)\n",
    "    return cmap\n",
    "\n",
    "\n",
    "def _generate_cartoon(self, gs, n_row, colors, bottom_space=0,\n",
    "                      fig_inches=13.91, show_labels=True):\n",
    "    '''Generates cartoon for heatmap'''\n",
    "    # Create subplot\n",
    "    cartoon = plt.subplot(gs[n_row, 0])\n",
    "\n",
    "    # Generate coordinates of labels\n",
    "    labels = list(Counter(self.secondary).keys())\n",
    "    length = list(Counter(self.secondary).values())\n",
    "    cumsum = length[:-1]\n",
    "    cumsum.insert(0, self.start_position)\n",
    "    cumsum = np.cumsum(cumsum)\n",
    "\n",
    "    # Create cartoon\n",
    "    for label, length, cum in zip(labels, length, cumsum):\n",
    "        if 'β' in label:\n",
    "            loopstructure = _loop(cum, length, color=colors[2])\n",
    "            cartoon.add_patch(loopstructure)\n",
    "            sheetstructure = _sheet(cum, length, colors[0])\n",
    "            cartoon.add_patch(sheetstructure)\n",
    "            x_label = cum + length - 3.5\n",
    "            if length > 2 and show_labels:  # If beta sheet is too small, label does not fit\n",
    "                if length == 3:\n",
    "                    cartoon.text((x_label+0.6), -0.25, label, name='Arial',\n",
    "                                 fontweight='normal', size=8.5*fig_inches/13.91, multialignment='right')\n",
    "                else:\n",
    "                    cartoon.text((x_label), -0.25, label, name='Arial', fontweight='normal',\n",
    "                                 size=8.5*fig_inches/13.91, multialignment='right')\n",
    "        elif 'α' in label:\n",
    "            helixstructure = _helix(cum, length, colors[1])\n",
    "            cartoon.add_patch(helixstructure)\n",
    "            x_label = cum + length/2 - 1\n",
    "            if length > 2 and show_labels:\n",
    "                cartoon.text((x_label), -0.3, label, name='Arial', fontweight='normal',\n",
    "                             size=9*fig_inches/14, multialignment='center')\n",
    "        elif 'L' in label:\n",
    "            loopstructure = _loop(cum, length, colors[2])\n",
    "            cartoon.add_patch(loopstructure)\n",
    "\n",
    "    # format of secondary cartoon\n",
    "    cartoon.xaxis.set_ticks_position('none')\n",
    "    cartoon.yaxis.set_ticks_position('none')\n",
    "    cartoon.axis('off')\n",
    "\n",
    "    # size\n",
    "    cartoon.set_xlim(self.start_position-0.1,\n",
    "                     len(self.secondary)+self.start_position+0.2)\n",
    "    cartoon.set_ylim(-2, 2.5)\n",
    "\n",
    "    # adjust proximity to heatmap\n",
    "    box = cartoon.get_position()\n",
    "    box.y0 = box.y0-bottom_space\n",
    "    box.y1 = box.y1-bottom_space\n",
    "    cartoon.set_position(box)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def _sheet(starting_aa, length_aa, color='lightgreen'):\n",
    "    dx = length_aa\n",
    "    sheetstructure = patches.FancyArrow(starting_aa, 0.25, dx, 0, width=2, length_includes_head=True,\n",
    "                                        head_width=4, head_length=3, shape='full', overhang=0, head_starts_at_zero=False, ec='k', fc=color)\n",
    "    return sheetstructure\n",
    "\n",
    "\n",
    "def _helix(starting_aa, length_aa, color='lavender'):\n",
    "    dx = length_aa  # so i can overlap tip\n",
    "    helixstructure = plt.Rectangle(\n",
    "        (starting_aa, -0.85), dx, 2.2, fc=color, ec='k')\n",
    "    return helixstructure\n",
    "\n",
    "\n",
    "def _loop(starting_aa, length_aa, color='k'):\n",
    "    dx = length_aa\n",
    "    loopstructure = plt.Rectangle((starting_aa, 0), dx, 0.5, fc=color)\n",
    "    return loopstructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouped Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.599513Z",
     "start_time": "2020-09-13T01:45:00.574755Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_heatmap_rows(self, selection=['E', 'Q', 'A', 'P', 'V', 'Y'],\n",
    "                           nancolor='lime', **kwargs):\n",
    "    '''\n",
    "    Generate a heatmap plot enrichment scores of selected aminoacids. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    selection : list of aa to show, default ['E','Q','A','P','V','Y']. \n",
    "    \n",
    "    nancolor : str, default 'lime'\n",
    "        Will color np.nan values with the specified color.\n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None.\n",
    "    '''\n",
    "    # load font parameters\n",
    "    _font_parameters()\n",
    "\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "\n",
    "    # load labels\n",
    "    temp_kwargs['color_sequencelabels'] = _labels(self.start_position)[0]\n",
    "    temp_kwargs['number_sequencelabels'] = _labels(self.start_position)[1]\n",
    "\n",
    "    # Add group and pivot df\n",
    "    df = _select_aa(self.dataframe_stopcodons, selection, values='Score_NaN')\n",
    "    dataset = df.to_numpy()\n",
    "\n",
    "    # The size can be changed. I found it empirically\n",
    "    figwidth = 14*len(dataset[0])/165\n",
    "    figheight = 2/21*len(selection)\n",
    "    fig = plt.figure(figsize=(figwidth, figheight))\n",
    "    gs = gridspec.GridSpec(nrows=1, ncols=2, width_ratios=[len(dataset[0]), 1])\n",
    "    ax = plt.subplot(gs[0, 0])\n",
    "    cbar1 = plt.subplot(gs[0, 1])\n",
    "\n",
    "    # Change color of values that are NaN\n",
    "    cmap = temp_kwargs['colormap']\n",
    "    cmap.set_bad(color=nancolor)\n",
    "\n",
    "    # main heatmap\n",
    "    heatmap = ax.pcolormesh(dataset, vmin=temp_kwargs['colorbar_scale'][0], vmax=temp_kwargs['colorbar_scale'][1],\n",
    "                            cmap=cmap, edgecolors='k', linewidths=0.2, antialiased=True, color='darkgrey')\n",
    "\n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_xticks(np.arange(dataset.shape[1]) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(dataset.shape[0]) + 0.5, minor=False)\n",
    "\n",
    "    # position of axis labels\n",
    "    ax.tick_params('x', direction='out', pad=-2.5)\n",
    "    ax.tick_params('y', direction='out', pad=0.4)\n",
    "\n",
    "    # second axis\n",
    "    ax2 = ax.twiny()\n",
    "    ax2.set_xticks(np.arange(dataset.shape[1]) + 0.5, minor=False)\n",
    "    ax2.tick_params(direction='out', pad=4)\n",
    "\n",
    "    # Set the limits of the new axis from the original axis limits\n",
    "    ax2.set_xlim(ax.get_xlim())\n",
    "\n",
    "    # want a more natural, table-like display\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    "\n",
    "    # so labels of x and y do not show up and my labels show up instead\n",
    "    ax.set_xticklabels(list(self.sequence), fontsize=6.5,\n",
    "                       fontname=\"Arial\", color='k', minor=False)\n",
    "    ax.set_yticklabels(list(df.T.columns), fontsize=6,\n",
    "                       fontname=\"Arial\", color='k', minor=False)\n",
    "    ax2.set_xticklabels(temp_kwargs['number_sequencelabels'][0:len(dataset[0])],\n",
    "                        fontsize=10, fontname=\"Arial\", color='k', minor=False)\n",
    "\n",
    "    # align the labels of the y axis\n",
    "    for ylabel in ax.get_yticklabels():\n",
    "        ylabel.set_horizontalalignment('center')\n",
    "\n",
    "    # for coloring the residues that are 10,20...\n",
    "    for xtick, color in zip(ax.get_xticklabels(), temp_kwargs['color_sequencelabels']):\n",
    "        xtick.set_color(color)\n",
    "\n",
    "    # for putting title on graph\n",
    "    plt.title(temp_kwargs['title'], horizontalalignment='center',\n",
    "              fontname=\"Arial\", fontsize=12)\n",
    "\n",
    "    # for color bar format\n",
    "    cbar1.axis('off')\n",
    "    cb = plt.colorbar(heatmap, fraction=1, pad=0, ax=[cbar1], aspect=5, ticks=[temp_kwargs['colorbar_scale'][0], np.mean(\n",
    "        temp_kwargs['colorbar_scale']), temp_kwargs['colorbar_scale'][1]], orientation='vertical')\n",
    "    cb.ax.set_yticklabels(cb.ax.get_yticklabels(),\n",
    "                          fontsize=8, fontname=\"Arial\", color='k')\n",
    "    cb.update_ticks()\n",
    "    gs.update(hspace=0.1, wspace=0.1/len(dataset[0])*50)\n",
    "\n",
    "    # remove ticks\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax2.yaxis.set_ticks_position('none')\n",
    "    ax2.xaxis.set_ticks_position('none')\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "\n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.615706Z",
     "start_time": "2020-09-13T01:45:00.602146Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_heatmap_columns(self, segment, ylabel_color='k', nancolor='lime', **kwargs):\n",
    "    '''\n",
    "    Generate a heatmap plot enrichment scores but only plots a selected segment.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    segment : list\n",
    "        Segment is typed as [20,40] and includes both residues 20 and 40.\n",
    "    \n",
    "    ylabel_color : str, default 'k'\n",
    "        Choose white if you don't want amino acid y axis label.\n",
    "    \n",
    "    nancolor : str, default 'lime'\n",
    "        Will color np.nan values with the specified color.\n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None    \n",
    "    '''\n",
    "\n",
    "    # load font parameters\n",
    "    _font_parameters()\n",
    "\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "\n",
    "    # load labels\n",
    "    temp_kwargs['color_sequencelabels'] = _labels(self.start_position)[0]\n",
    "    temp_kwargs['number_sequencelabels'] = _labels(self.start_position)[1]\n",
    "\n",
    "    # sort data in specified order by user\n",
    "    df_whole = _df_rearrange(self.dataframe_stopcodons,\n",
    "                            temp_kwargs['neworder_aminoacids'], values='Score_NaN')\n",
    "    \n",
    "    # select subset\n",
    "    c0 = segment[0]-self.start_position\n",
    "    c1 = segment[1]-self.start_position+1\n",
    "    df = df_whole.iloc[:,c0:c1]\n",
    "\n",
    "    # the size can be changed\n",
    "    figwidth = 2*len(df.columns)/22\n",
    "    figheight = 2\n",
    "    fig = plt.figure(figsize=(figwidth, figheight))\n",
    "    gs = gridspec.GridSpec(nrows=1, ncols=1)\n",
    "    # needed to set autoscale off to avoid missalignment\n",
    "    ax = plt.subplot(gs[0])\n",
    "\n",
    "    # Change color of values that are NaN\n",
    "    cmap = temp_kwargs['colormap']\n",
    "    cmap.set_bad(color=nancolor)\n",
    "\n",
    "    # main heatmap\n",
    "    heatmap = ax.pcolormesh(df, vmin=temp_kwargs['colorbar_scale'][0], vmax=temp_kwargs['colorbar_scale'][1],\n",
    "                            cmap=cmap, edgecolors='k', linewidths=0.2, antialiased=True, color='darkgrey')\n",
    "\n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_xticks(np.arange(len(df.columns)) + 0.5, minor=False,)\n",
    "    ax.set_yticks(np.arange(len(df)) + 0.5, minor=False)\n",
    "\n",
    "    # position of axis labels\n",
    "    ax.tick_params('x', direction='out', pad=-2.5)\n",
    "    ax.tick_params('y', direction='out', pad=0.4)\n",
    "\n",
    "    # second axis\n",
    "    ax2 = ax.twiny()\n",
    "    ax2.set_xticks(np.arange(len(df.columns)) + 0.5, minor=False)\n",
    "    ax2.tick_params(direction='out', pad=4)\n",
    "\n",
    "    # Set the limits of the new axis from the original axis limits\n",
    "    ax2.set_xlim(ax.get_xlim())\n",
    "\n",
    "    # want a more natural, table-like display\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    "\n",
    "    # so labels of x and y do not show up and my labels show up instead\n",
    "    ax.set_xticklabels(list(self.sequence)[segment[0]-self.start_position:segment[1] -\n",
    "                                           self.start_position+1], fontsize=6.5, fontname=\"Arial\", color='k', minor=False)\n",
    "    ax.set_yticklabels(temp_kwargs['neworder_aminoacids'], fontsize=6,\n",
    "                       fontname=\"Arial\", color=ylabel_color, minor=False)\n",
    "\n",
    "    ax2_label = (segment[1]-segment[0]+1)*['']\n",
    "    ax2_label[0] = segment[0]\n",
    "    ax2_label[-1] = segment[1]\n",
    "    ax2.set_xticklabels(ax2_label, fontsize=7,\n",
    "                        fontname=\"Arial\", color='k', minor=False)\n",
    "\n",
    "    # align the labels of the y axis\n",
    "    for ylabel in ax.get_yticklabels():\n",
    "        ylabel.set_horizontalalignment('center')\n",
    "\n",
    "    # remove ticks\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "    ax2.yaxis.set_ticks_position('none')\n",
    "    ax2.xaxis.set_ticks_position('none')\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "\n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar graph Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.634245Z",
     "start_time": "2020-09-13T01:45:00.617533Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_mean(self, mode='mean', show_cartoon=False, **kwargs):\n",
    "    '''\n",
    "    Plot in a bargraph the mean enrichment for each residue of the protein. Red for gain of function, blue for loss of function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    mode : str, default 'mean'\n",
    "        Specify what enrichment scores to show. If mode = 'mean', it will show the mean of \n",
    "        each position. If mode = 'A', it will show the alanine substitution profile. Can be \n",
    "        used for each amino acid. Use the one-letter code and upper case.\n",
    "        \n",
    "    show_carton : boolean, default False\n",
    "        If true, the plot will display a cartoon with the secondary structure. The user must have added the secondary structure to the object. \n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None.\n",
    "    '''\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    temp_kwargs['figsize'] = kwargs.get('figsize', (3, 2.5))\n",
    "    temp_kwargs['yscale'] = kwargs.get('yscale', (-1, 1))\n",
    "    temp_kwargs['y_label'] = kwargs.get('y_label', r'$∆E^i_x$')\n",
    "\n",
    "    # load parameters\n",
    "    parameters_mean()\n",
    "\n",
    "    # Select grouping\n",
    "    if mode == 'mean':\n",
    "        df = self.dataframe.groupby('Position', as_index=False).mean()\n",
    "    else:\n",
    "        df = self.dataframe.loc[self.dataframe['Aminoacid']==mode].copy()\n",
    "    \n",
    "    df['Color'] = df.apply(color_data, axis=1)\n",
    "\n",
    "    # make figure\n",
    "    if show_cartoon:\n",
    "        fig = plt.figure(figsize=temp_kwargs['figsize'])\n",
    "        gs = gridspec.GridSpec(nrows=2, ncols=1, height_ratios=[5, 1])\n",
    "        ax = plt.subplot(gs[0])\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=temp_kwargs['figsize'])\n",
    "    width = 1.2\n",
    "\n",
    "    # Color based on values\n",
    "    ax.bar(df['Position'], df['Score'], width, color=df['Color'], snap=False)\n",
    "\n",
    "    # axes parameters\n",
    "    ax.set_ylim(temp_kwargs['yscale'])\n",
    "    ax.set_ylabel(temp_kwargs['y_label'], fontsize=10,\n",
    "                  fontname=\"Arial\", color='k', labelpad=10, rotation=0)\n",
    "    ax.set_xticks(np.arange(self.start_position,\n",
    "                            len(df)+self.start_position, 20))\n",
    "    ax.set_xlabel('Residue', fontsize=10,\n",
    "                  fontname=\"Arial\", color='k', labelpad=4)\n",
    "    ax.set_xlim(self.start_position-0.1, len(df)+self.start_position-1+0.1)\n",
    "    plt.title(temp_kwargs['title'], fontsize=12, fontname='Arial', color='k')\n",
    "\n",
    "    # cartoon\n",
    "    if show_cartoon:\n",
    "        _generate_cartoon(self, gs, 1, temp_kwargs['cartoon_colors'],\n",
    "                          bottom_space=-0.78, show_labels=False)\n",
    "    # Put text labels\n",
    "    _inputtext(temp_kwargs['text_labels'])\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def color_data(row):\n",
    "    if row['Score'] > 0:\n",
    "        return 'red'\n",
    "    else:\n",
    "        return 'blue'\n",
    "\n",
    "\n",
    "def parameters_mean():\n",
    "    # normal font\n",
    "    rcParams['font.family'] = 'sans-serif'\n",
    "    rcParams['font.sans-serif'] = ['Arial']\n",
    "\n",
    "    # math font\n",
    "    rcParams['mathtext.fontset'] = 'custom'\n",
    "    rcParams['mathtext.rm'] = 'Arial'\n",
    "    rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "    # Parameters for all graphs\n",
    "    rcParams['xtick.labelsize'] = 9\n",
    "    rcParams['ytick.labelsize'] = 9\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare two proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.649305Z",
     "start_time": "2020-09-13T01:45:00.637129Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_meandifferential (self, obj2, show_cartoon=False,**kwargs):\n",
    "    '''\n",
    "    Plot the mean positional difference between two experiments\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    obj2 : another Screen object to compare with \n",
    "    \n",
    "    show_carton : boolean, default False\n",
    "        If true, the plot will display a cartoon with the secondary structure. The user must have added the secondary structure to the object. \n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None.\n",
    "    '''\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    temp_kwargs['figsize'] = kwargs.get('figsize', (3,2.5))\n",
    "    temp_kwargs['yscale'] = kwargs.get('yscale', (-1,1))\n",
    "    temp_kwargs['y_label'] = kwargs.get('y_label', r'Mean Differential $∆E^i_x$')\n",
    "\n",
    "    # load parameters\n",
    "    parameters_mean()\n",
    "    \n",
    "    # make pandas\n",
    "    df = _process_meanresidue(self,obj2)\n",
    "    \n",
    "    # make cartoon\n",
    "    if show_cartoon:\n",
    "        fig = plt.figure(figsize=temp_kwargs['figsize'])\n",
    "        gs = gridspec.GridSpec(nrows=2, ncols=1, height_ratios=[5, 1])\n",
    "        ax = plt.subplot(gs[0])\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=temp_kwargs['figsize']) \n",
    "\n",
    "    # plot\n",
    "    ax.plot(df['Position'], df['d1 - d2'], color='k')\n",
    "\n",
    "    # axes parameters\n",
    "    ax.set_ylim(temp_kwargs['yscale'])\n",
    "    ax.set_ylabel(temp_kwargs['y_label'], fontsize=10, fontname=\"Arial\", \n",
    "                  color='k', labelpad=-5, rotation=90)\n",
    "    ax.set_xticks(np.arange(self.start_position, len(df)+self.start_position, 20))\n",
    "    ax.set_xlabel('Residue', fontsize=10, fontname=\"Arial\", color='k', labelpad=4)\n",
    "    ax.set_xlim(self.start_position-0.1, len(df)+self.start_position-1+0.1)\n",
    "    ax.set_title(temp_kwargs['title'], fontsize=12, fontname='Arial', color='k')\n",
    "\n",
    "    # cartoon\n",
    "    if show_cartoon:\n",
    "        obj = obj2\n",
    "        if len(self.dataframe) < len(obj2.dataframe):\n",
    "            obj = self\n",
    "        _generate_cartoon(obj,gs,1,temp_kwargs['cartoon_colors'],\n",
    "                            bottom_space=-0.78, show_labels=False)\n",
    "    # save file\n",
    "    _savefile(fig,temp_kwargs)\n",
    "\n",
    "    if temp_kwargs['show']: plt.show()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar graph Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.662557Z",
     "start_time": "2020-09-13T01:45:00.650951Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_meancounts (self, positions, counts, show_cartoon=False, **kwargs):\n",
    "    '''\n",
    "    Plot in a bargraph the mean counts for each residue of the protein.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    positions : list, x coordinates\n",
    "    \n",
    "    counts : list, y coordinates\n",
    "    \n",
    "    show_carton : boolean, default False\n",
    "        If true, the plot will display a cartoon with the secondary structure. The user must have added the secondary structure to the object. \n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None.\n",
    "    '''\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    temp_kwargs['figsize'] = kwargs.get('figsize', (3,2.5))\n",
    "    temp_kwargs['yscale'] = kwargs.get('yscale', (0,5))\n",
    "    temp_kwargs['y_label'] = kwargs.get('y_label', r'$Log_{10}$ mean counts')\n",
    "\n",
    "    # load parameters\n",
    "    parameters_mean()\n",
    "        \n",
    "    # make figure\n",
    "    if show_cartoon:\n",
    "        fig = plt.figure(figsize=temp_kwargs['figsize'])\n",
    "        gs = gridspec.GridSpec(nrows=2, ncols=1, height_ratios=[5, 1])\n",
    "        ax = plt.subplot(gs[0])\n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=temp_kwargs['figsize']) \n",
    "    width = 0.8\n",
    "\n",
    "    # Color based on values\n",
    "    ax.bar(positions, np.log10(counts), width, color='red', snap=False)\n",
    "\n",
    "    # axes parameters\n",
    "    ax.set_ylim(temp_kwargs['yscale'])\n",
    "    ax.set_ylabel(temp_kwargs['y_label'], fontsize=10, fontname=\"Arial\", color='k', labelpad=0, rotation=90)\n",
    "    ax.set_xticks(np.arange(self.start_position, len(self.dataset[0])+self.start_position, 20))\n",
    "    ax.set_xlabel('Residue', fontsize=10, fontname=\"Arial\", color='k', labelpad=4)\n",
    "    ax.set_xlim(self.start_position-0.1, len(self.dataset[0])+self.start_position-1+0.1)\n",
    "    plt.title(temp_kwargs['title'], fontsize=12, fontname='Arial', color='k')\n",
    "    \n",
    "    # cartoon\n",
    "    if show_cartoon:\n",
    "        _generate_cartoon(self,gs,1,temp_kwargs['cartoon_colors'],\n",
    "                            bottom_space=-0.78, show_labels=False)\n",
    "    # Put text labels\n",
    "    _inputtext(temp_kwargs['text_labels'])\n",
    "    \n",
    "    # save file\n",
    "    _savefile(fig,temp_kwargs)\n",
    "    if temp_kwargs['show']: plt.show()\n",
    "    return\n",
    "\n",
    "def _inputtext(text_entries):\n",
    "    '''the user can input text as a variable by manually giving the coordinates'''\n",
    "    if text_entries:\n",
    "        for entry in text_entries:\n",
    "            plt.text(entry[0],entry[1],entry[2])\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.673130Z",
     "start_time": "2020-09-13T01:45:00.665203Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_position(self, position, **kwargs):\n",
    "    '''\n",
    "    Choose a position and plot in a bargraph the enrichment score for each substitution.\n",
    "    Red for gain of function, blue for loss of function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    position : int\n",
    "        number of residue of the protein to display.\n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None.\n",
    "    '''\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    temp_kwargs['figsize'] = kwargs.get('figsize', (3.5, 2))\n",
    "    temp_kwargs['yscale'] = kwargs.get('yscale', (-1, 1))\n",
    "    temp_kwargs['y_label'] = kwargs.get('y_label', r'$∆E^i_x$')\n",
    "\n",
    "    # load parameters\n",
    "    parameters_mean()\n",
    "\n",
    "    # Select position\n",
    "    df = self.dataframe.loc[self.dataframe['Position']==position].copy()\n",
    "    \n",
    "    # Color\n",
    "    df['Color'] = df.apply(color_data, axis=1)\n",
    "\n",
    "    # make figure\n",
    "    fig, ax = plt.subplots(figsize=temp_kwargs['figsize'])\n",
    "    width = 0.5\n",
    "\n",
    "    # Color based on values\n",
    "    ax.bar(df['Aminoacid'], df['Score'], width, color=df['Color'], ec='k')\n",
    "\n",
    "    # axes parameters\n",
    "    ax.set_ylim(temp_kwargs['yscale'])\n",
    "    ax.set_ylabel(temp_kwargs['y_label'], fontsize=10,\n",
    "                  fontname=\"Arial\", color='k', labelpad=10, rotation=0)\n",
    "\n",
    "    ax.set_xlabel('Residue', fontsize=10,\n",
    "                  fontname=\"Arial\", color='k', labelpad=4)\n",
    "    plt.title(temp_kwargs['title'], fontsize=12, fontname='Arial', color='k')\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "    \n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.691616Z",
     "start_time": "2020-09-13T01:45:00.675142Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_scatter(self, obj2, mode='pointmutant', **kwargs):\n",
    "    '''\n",
    "    Generate a scatter plot between object and a second object of the same class.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    obj2 : object from class \"Screen\" to do the scatter with\n",
    "    \n",
    "    mode : str, default 'pointmutant'. \n",
    "        Alternative set to \"mean\" for the mean of each position\n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None.\n",
    "    '''\n",
    "\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    temp_kwargs['figsize'] = kwargs.get('figsize', (2, 2))\n",
    "    temp_kwargs['xscale'] = kwargs.get('xscale', (-2, 2))\n",
    "    temp_kwargs['yscale'] = kwargs.get('yscale', (-2, 2))\n",
    "\n",
    "    # Chose mode:\n",
    "    if mode == 'pointmutant':\n",
    "        df = _process_bypointmutant(self, obj2)\n",
    "    else:\n",
    "        df = _process_meanresidue(self, obj2)\n",
    "\n",
    "    # create figure\n",
    "    fig, ax = plt.subplots(figsize=temp_kwargs['figsize'])\n",
    "\n",
    "    # import parameters\n",
    "    _parameters()\n",
    "\n",
    "    # Scatter data points\n",
    "    plt.scatter(df['dataset_1'], df['dataset_2'], c='k', s=8,\n",
    "                alpha=0.5, rasterized=True, label='_nolegend_')\n",
    "\n",
    "    # Titles\n",
    "    plt.title(temp_kwargs['title'], fontsize=12,\n",
    "              fontname='Arial', color='k', pad=8)\n",
    "    plt.ylabel(temp_kwargs['y_label'], fontsize=10,\n",
    "               fontname=\"Arial\", color='k', labelpad=0)\n",
    "    plt.xlabel(temp_kwargs['x_label'], fontsize=10,\n",
    "               fontname=\"Arial\", color='k')\n",
    "\n",
    "    # correlation and R2\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "        df['dataset_1'], df['dataset_2'])\n",
    "    R2 = str(round(r_value**2, 2))\n",
    "    legend_label = \"$R^2$ = {}\".format(R2)\n",
    "    # fit and graph line\n",
    "    fit = np.polyfit(df['dataset_1'], df['dataset_2'], 1)\n",
    "    plt.plot(np.unique(df['dataset_1']), np.poly1d(fit)(\n",
    "        np.unique(df['dataset_1'])), color='r', linewidth=1, label=legend_label)\n",
    "    plt.grid()\n",
    "\n",
    "    # other graph parameters\n",
    "    plt.xlim(temp_kwargs['xscale'])\n",
    "    plt.ylim(temp_kwargs['yscale'])\n",
    "    ax.xaxis.set_major_locator(\n",
    "        ticker.MultipleLocator(temp_kwargs['tick_spacing']))\n",
    "    ax.yaxis.set_major_locator(\n",
    "        ticker.MultipleLocator(temp_kwargs['tick_spacing']))\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.draw()\n",
    "\n",
    "    # Legend\n",
    "    plt.legend(loc='upper left', handlelength=0,\n",
    "               handletextpad=0, frameon=False, fontsize=10)\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "    \n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "        \n",
    "    return\n",
    "\n",
    "\n",
    "def _process_bypointmutant(self, obj):\n",
    "    # truncate so both datasets have same length and delete stop codons\n",
    "    minlength = min(len(self.dataframe), len(obj.dataframe))\n",
    "    df = pd.DataFrame()\n",
    "    df['dataset_1'] = list(self.dataframe['Score_NaN'])[:minlength]\n",
    "    df['dataset_2'] = list(obj.dataframe['Score_NaN'])[:minlength]\n",
    "\n",
    "    # eliminate Nans\n",
    "    df.dropna(how='any', inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def _process_meanresidue(self, obj):\n",
    "    # truncate so both datasets have same length and delete stop codons\n",
    "    dataset_1 = self.dataframe.groupby(['Position'], as_index=False).mean()\n",
    "    dataset_2 = obj.dataframe.groupby(['Position'], as_index=False).mean()\n",
    "    minlength = min(len(dataset_1), len(dataset_2))\n",
    "\n",
    "    # convert to dataframe and eliminate Nans\n",
    "    df = pd.DataFrame()\n",
    "    df['dataset_1'] = list(dataset_1['Score'])[0:minlength]\n",
    "    df['dataset_2'] = list(dataset_2['Score'])[0:minlength]\n",
    "    df['Position'] = list(dataset_1['Position'])[0:minlength]\n",
    "    df['d1 - d2'] = df['dataset_1'] - df['dataset_2']\n",
    "    df.dropna(how='any', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.703115Z",
     "start_time": "2020-09-13T01:45:00.693803Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_rank(self, mode='pointmutant', outdf=False, **kwargs):\n",
    "    '''\n",
    "    Generate a rank plot so every mutation/residue is sorted based on enrichment score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self : object from class \"Screen\"\n",
    "        \n",
    "    mode : str, default 'pointmutant'. \n",
    "        Alternative set to \"mean\" for the mean of each position\n",
    "    \n",
    "    outdf : boolean, default False\n",
    "        If set to true, will return the df with the rank of mutations\n",
    "        \n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    Pandas dataframe\n",
    "    '''\n",
    "\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    temp_kwargs['figsize'] = kwargs.get('figsize', (4, 2))\n",
    "    temp_kwargs['x_label'] = kwargs.get('x_label', 'Rank')\n",
    "    temp_kwargs['y_label'] = kwargs.get('y_label', r'$∆E^i_x$')\n",
    "    \n",
    "    # Sort by enrichment scores\n",
    "    df = self.dataframe.sort_values(by=['Score']).copy()\n",
    "    \n",
    "    # Chose mode:\n",
    "    if mode == 'mean':\n",
    "        df = df.groupby(by=['Position'],as_index=False).mean()\n",
    "        df.sort_values(by=['Score'], inplace=True)\n",
    "\n",
    "    # create figure\n",
    "    fig, ax = plt.subplots(figsize=temp_kwargs['figsize'])\n",
    "\n",
    "    # import parameters\n",
    "    _parameters()\n",
    "\n",
    "    # Scatter data points\n",
    "    plt.scatter(np.arange(len(df),0,-1), df['Score'], c='k', s=1)\n",
    "\n",
    "    # Titles\n",
    "    plt.title(temp_kwargs['title'], fontsize=12,\n",
    "              fontname='Arial', color='k', pad=8)\n",
    "    # Labels\n",
    "    plt.ylabel(temp_kwargs['y_label'], fontsize=10,\n",
    "               fontname=\"Arial\", color='k', labelpad=0)\n",
    "    plt.xlabel(temp_kwargs['x_label'], fontsize=10,\n",
    "               fontname=\"Arial\", color='k')\n",
    "    \n",
    "    # other graph parameters\n",
    "    plt.xlim(temp_kwargs['xscale'])\n",
    "    plt.ylim(temp_kwargs['yscale'])\n",
    "    \n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "    \n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "    if outdf:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.714180Z",
     "start_time": "2020-09-13T01:45:00.705567Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_hist(self, population='All', loc='upper left', **kwargs):\n",
    "    '''\n",
    "    Generate a histogram plot. Can plot single nucleotide variants (SNVs) or non-SNVs only\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    population : str, default 'All'. \n",
    "        Other options are 'SNV' and 'nonSNV'.\n",
    "    \n",
    "    loc : str, default 'upper left'. \n",
    "        Position of the legend.\n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "        bins : int, default 50. \n",
    "            Number of bins for the histogram.\n",
    "    Returns\n",
    "    ----------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    temp_kwargs['figsize'] = kwargs.get('figsize', (2, 2))\n",
    "    temp_kwargs['yscale'] = kwargs.get('yscale', (0, 2))\n",
    "    temp_kwargs['xscale'] = kwargs.get('xscale', (-2, 2))\n",
    "\n",
    "    # Select case input data\n",
    "    df = self.dataframe['Score_NaN']\n",
    "    if population == 'SNV':\n",
    "        df = self.dataframe_SNV['Score_NaN']\n",
    "    elif population == 'nonSNV':\n",
    "        df = self.dataframe_nonSNV['Score_NaN']\n",
    "\n",
    "    # create figure\n",
    "    fig = plt.figure(figsize=temp_kwargs['figsize'])\n",
    "\n",
    "    # Import parameters\n",
    "    _parameters()\n",
    "\n",
    "    # plot figure\n",
    "    plt.hist(df, density=True, bins=temp_kwargs['bins'], color='k')\n",
    "\n",
    "    # axes labels and title\n",
    "    plt.xlabel(r'$∆E^i_x$' if temp_kwargs['x_label'] == 'x_label' else temp_kwargs['x_label'],\n",
    "               fontsize=10, fontname=\"Arial\", color='k', labelpad=0)\n",
    "    plt.ylabel('Probability density', fontsize=10,\n",
    "               fontname=\"Arial\", color='k', labelpad=3)\n",
    "    plt.title(temp_kwargs['title'], fontsize=10, fontname='Arial', color='k')\n",
    "\n",
    "    # axes limits. spacer will be 1 or the\n",
    "    plt.xlim(temp_kwargs['xscale'])\n",
    "    plt.xticks(np.arange(temp_kwargs['xscale'][0], temp_kwargs['xscale']\n",
    "                         [1]+temp_kwargs['tick_spacing'], temp_kwargs['tick_spacing']))\n",
    "    plt.ylim(temp_kwargs['yscale'])\n",
    "    plt.grid()\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal SNV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.731344Z",
     "start_time": "2020-09-13T01:45:00.716068Z"
    }
   },
   "outputs": [],
   "source": [
    "def _select_nonSNV(df):\n",
    "    '''\n",
    "    Generate a dataframe that contains the non-SNV variants and the enrichment score\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    df : pd.dataframe\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    Dataframe containing a column of variants that are non-SNV, and the Score.\n",
    "    '''\n",
    "    # Dataframe with SNV\n",
    "    SNV = _select_SNV(df)\n",
    "\n",
    "    # Merge and eliminate duplicates. Keep Non-SNV\n",
    "    NonSNV = pd.concat([SNV, df], sort=False)[['Position', 'Variant', 'Score']]\n",
    "    NonSNV.drop_duplicates(subset='Variant', keep=False, inplace=True)\n",
    "\n",
    "    return NonSNV\n",
    "\n",
    "\n",
    "def _select_SNV(df):\n",
    "    '''\n",
    "    Select for SNV variants in DSM dataset\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    df : pandas dataframe containing DSM data\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    Modified dataframe('Variant','Score') where 'SNV?'== True. Returns copy\n",
    "    '''\n",
    "\n",
    "    # Use _add_SNV_boolean funciton\n",
    "    df = _add_SNV_boolean(df.copy())\n",
    "\n",
    "    # Select SNV? == True only\n",
    "    df = df[df['SNV?'] == True].copy()\n",
    "\n",
    "    # Select columns of interest\n",
    "    df = df[['Position', 'Variant', 'Score']].copy()\n",
    "\n",
    "    # Reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def _aminoacids_snv(aa1, aa2, codontable):\n",
    "    '''\n",
    "    Determine if two amino acids are snv (one base difference)\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    aa1 : str\n",
    "    aa2 : str\n",
    "    codontable : dict (did not want to generate each time I run the function)\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    boolean, True/False\n",
    "    '''\n",
    "    # Convert amino acids to codons\n",
    "    codons1 = codontable[aa1]\n",
    "    codons2 = codontable[aa2]\n",
    "\n",
    "    # Generate a list of combination pairs between all codons in aa1 and aa2\n",
    "    codon_combinations = list(itertools.product(codons1, codons2))\n",
    "\n",
    "    # If one pair of combinations is a SNV, then return True\n",
    "    for combination in codon_combinations:\n",
    "        if _codons_pointmutants(combination[0], combination[1]) == True:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def _add_SNV_boolean(df):\n",
    "    '''\n",
    "    Add a column to dataframe indication if the variant is a SNV or not\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    df : pandas dataframe containing DSM data\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    Modified dataframe. Returns copy\n",
    "    '''\n",
    "\n",
    "    # Generate dictionary with aa and codon translation\n",
    "    codontable = _dict_codontoaa()\n",
    "\n",
    "    # Add column with True/False input\n",
    "    df['SNV?'] = df.apply(lambda x: _aminoacids_snv(\n",
    "        x['Sequence'], x['Aminoacid'], codontable), axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def _codons_pointmutants(codon1, codon2):\n",
    "    '''\n",
    "    Determine if two codons are SNV. Returns a boolean\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    codon1 : str\n",
    "    codon2 : str\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    boolean, True/False\n",
    "    '''\n",
    "    counter_occurrences = 0\n",
    "    for index, base1 in enumerate(codon1):\n",
    "        base2 = list(codon2)[index]\n",
    "        if base1 == base2:\n",
    "            counter_occurrences = counter_occurrences+1\n",
    "    if counter_occurrences > 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def _are_pointmutants(aa, seqbase):\n",
    "    '''\n",
    "    converts the amino acid to all possible degenerate codons and then checks if they are point mutants\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    aa: str\n",
    "    seqbase: str    \n",
    "\n",
    "    Returns \n",
    "    --------\n",
    "    Boolean\n",
    "    '''\n",
    "    codontoaadict = _dict_codontoaa()\n",
    "    pointmutants = False\n",
    "    for codon in _codontoaadict[aa]:\n",
    "        if _codons_pointmutants(seqbase, codon):\n",
    "            pointmutants = True\n",
    "    return pointmutants\n",
    "\n",
    "\n",
    "def _are_pointmutants_list(aa, seqbase_list):\n",
    "    '''\n",
    "    converts the amino acid to all possible degenerate codons and then checks if they are point mutants\n",
    "    Same as _are_pointmutants but in list format\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    aa: str\n",
    "    seqbase_list: list of str    \n",
    "\n",
    "    Returns \n",
    "    --------\n",
    "    List of Boolean\n",
    "    '''\n",
    "    pointmutants_list = []\n",
    "\n",
    "    for seqbase in seqbase_list:\n",
    "        pointmutants_list.append(_are_pointmutants(aa, seqbase))\n",
    "    return pointmutants_list\n",
    "\n",
    "\n",
    "def _dict_codontoaa():\n",
    "    '''\n",
    "    Generates a dictionary with all amino acids and all possible codons.\n",
    "    aa is the aminoacid of the mutation and seqbase is the original codon of the wtsequence\n",
    "    '''\n",
    "    bases = ['T', 'C', 'A', 'G']\n",
    "    codons = [a+b+c for a in bases for b in bases for c in bases]\n",
    "    aminoacids = list(\n",
    "        'FFLLSSSSYY**CC*WLLLLPPPPHHQQRRRRIIIMTTTTNNKKSSRRVVVVAAAADDEEGGGG')\n",
    "\n",
    "    # dictionary with more than one value for each key\n",
    "    codontoaadict = defaultdict(list)\n",
    "    for codon, aminoacid in zip(codons, aminoacids):\n",
    "        codontoaadict[aminoacid].append(codon)\n",
    "    return codontoaadict\n",
    "\n",
    "\n",
    "def _aatocodons(aminoacid):\n",
    "    '''\n",
    "    Inputs an aminoacid, returns all codons. Used dict_codontoaa()\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    aminoacid : str\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    List with all the codons that code for that amino acid\n",
    "    '''\n",
    "\n",
    "    # Dictionary with all codons and aa\n",
    "    codontoaadict = _dict_codontoaa()\n",
    "\n",
    "    # Codons for that amino acid\n",
    "    codons = codontoaadict[aminoacid]\n",
    "\n",
    "    return codons\n",
    "\n",
    "\n",
    "def _aatocodons_df(df, namecolumn):\n",
    "    '''\n",
    "    Inputs a dataframe with a column of amino acids, returns all syn for each amino acidcodons. \n",
    "    Used dict_codontoaa() and _aatocodons\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    df : pandas dataframe\n",
    "    namecolumn : str\n",
    "        name of the column containing the amino acids\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    dataframe with a column containing all the codons that code for that amino acid. Returns copy\n",
    "    '''\n",
    "    # Copy df\n",
    "    df = df.copy()\n",
    "\n",
    "    # Calculate each possible codon for every amino acid\n",
    "    df['Codons_' +\n",
    "        namecolumn] = df.apply(lambda x: _aatocodons(x[namecolumn]), axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miniheatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean substitution heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.746203Z",
     "start_time": "2020-09-13T01:45:00.733101Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_miniheatmap(self, offset=0, **kwargs):\n",
    "    '''\n",
    "    Generate a miniheatmap plot enrichment scores of mutagenesis selection assays.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    offset : int, default 0\n",
    "        if you want to study effects of a residue when is behind or in front of another residue.\n",
    "        offset of 1 means that you evaluate the effect of following residue n+1 on n.\n",
    "        offset of -1 means that you look at the previous residue (n-1 on n).\n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    None.\n",
    "    '''\n",
    "\n",
    "    # load font parameters\n",
    "    _font_parameters()\n",
    "\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "\n",
    "    # load labels\n",
    "    temp_kwargs['color_sequencelabels'] = _labels(self.start_position)[0]\n",
    "    temp_kwargs['number_sequencelabels'] = _labels(self.start_position)[1]\n",
    "\n",
    "    # do offset if appropriate\n",
    "    dataframe_stopcodons = _transform_dataset_offset(self, offset)\n",
    "\n",
    "    # calculate condensed heatmap\n",
    "    dataset = _condense_heatmap(\n",
    "        dataframe_stopcodons, temp_kwargs['neworder_aminoacids'])\n",
    "\n",
    "    _plot_miniheatmap(dataset, temp_kwargs)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def _condense_heatmap(df, new_order):\n",
    "    '''\n",
    "    Converts the np.array with stored enrichment scores into the condensed heatmap\n",
    "    '''\n",
    "    # Convert dataset to df\n",
    "    df = df.copy()\n",
    "    df.drop(['Position'], axis=1, inplace=True)\n",
    "\n",
    "    # Group by sequence and aminoacid, and then pivot table\n",
    "    df_grouped = df.groupby(['Sequence', 'Aminoacid'], sort = False).mean()\n",
    "    df_pivoted = df_grouped.pivot_table(values='Score',\n",
    "                                        index='Aminoacid',  columns='Sequence')\n",
    "    df_pivoted.reset_index(drop=False, inplace=True)\n",
    "\n",
    "    # Sort in y axis desired order\n",
    "    df_pivoted['Aminoacid'] = pd.Categorical(\n",
    "        df_pivoted['Aminoacid'], new_order)\n",
    "    df_pivoted = df_pivoted.sort_values(by=['Aminoacid'])\n",
    "\n",
    "    # Sort in x axis desired order\n",
    "    x_order = _common(new_order, list(df_pivoted.columns))\n",
    "\n",
    "    # Drop amino acid column\n",
    "    data_dropped = df_pivoted.drop(['Aminoacid'], axis=1)\n",
    "\n",
    "    return data_dropped[x_order]\n",
    "\n",
    "\n",
    "def _offset_sequence(dataset, sequence, start_position, offset):\n",
    "    '''\n",
    "    Internal function that offsets the input sequence\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    dataset, sequence, start_position, offset\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    string containing trimmed sequence\n",
    "    '''\n",
    "    # Deep copy sequence\n",
    "    sequence = copy.deepcopy(sequence)\n",
    "\n",
    "    # truncate sequence\n",
    "    if offset > 0:\n",
    "        sequence = sequence+'X'*np.absolute(offset)\n",
    "        trimmedsequence = sequence[start_position-1 +\n",
    "                                   offset:len(dataset[0])+start_position-1+offset]\n",
    "    else:\n",
    "        sequence = 'X'*(np.absolute(offset))+sequence\n",
    "        trimmedsequence = sequence[start_position -\n",
    "                                   1:len(dataset[0])+start_position-1]\n",
    "\n",
    "    return trimmedsequence\n",
    "\n",
    "\n",
    "def _transform_dataset_offset(self, offset, stopcodons=True):\n",
    "    '''\n",
    "    Generate a dataframe with the sequence offset. Reutilizes _transform_dataset\n",
    "    '''\n",
    "    # Add offset sequence\n",
    "    offset_sequence = _offset_sequence(self.dataset, self.sequence_raw,\n",
    "                                       self.start_position, offset)\n",
    "    df = self.dataframe_stopcodons.copy() if stopcodons is True else self.dataframe.copy()\n",
    "\n",
    "    # Copy old sequence\n",
    "    df['Sequence_old'] = df['Sequence']\n",
    "    # Count amino acids\n",
    "    aa_number = len(set(df['Aminoacid']))\n",
    "    # Generate new offset sequence\n",
    "    df['Sequence'] = np.ravel([[aa]*aa_number for aa in offset_sequence])\n",
    "\n",
    "    # Drop rows with X\n",
    "    df.drop(df.index[df['Sequence'] == 'X'], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbor residues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.770745Z",
     "start_time": "2020-09-13T01:45:00.749800Z"
    }
   },
   "outputs": [],
   "source": [
    " def plot_neighboreffect (self, offset=1, **kwargs):\n",
    "    '''\n",
    "    Generate a miniheatmap plot telling you the effect of having a residue in front or behind.\n",
    "    It corrects for the effect of that amino acid on the rest of the population.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    offset : int, default 1\n",
    "        if you want to study effects of a residue when is behind or in front of another residue.\n",
    "        offset of 1 means that you evaluate the effect of following residue n+1 on n. On a \"MTEY...\" sequence,\n",
    "        you would look at the effect of T on M, E on T, Y on E, etc.. and then group by residue (n+1).\n",
    "        offset of -1 means that you look at the previous residue (n-1 on n).\n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None.\n",
    "    '''\n",
    "    # load font parameters\n",
    "    _font_parameters()\n",
    "\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    if '*' in temp_kwargs['neworder_aminoacids']: temp_kwargs['neworder_aminoacids'].remove('*')\n",
    "    \n",
    "    # do offset, no stop codons\n",
    "    df = _normalize_neighboreffect(self,offset,temp_kwargs['neworder_aminoacids'])\n",
    "    \n",
    "    # Plot\n",
    "    _plot_miniheatmap(df,temp_kwargs)\n",
    "    \n",
    "    return\n",
    "    \n",
    "def _plot_miniheatmap(df,temp_kwargs):\n",
    "    # declare figure and subplots\n",
    "    coeff = len(df.columns)/19*1.05\n",
    "    fig = plt.figure(figsize=(2.5*coeff, 2.5))\n",
    "    gs = gridspec.GridSpec(nrows=1, ncols=1)\n",
    "    ax = plt.subplot(gs[0])\n",
    "\n",
    "    # main heatmap\n",
    "    heatmap = ax.pcolor(df.to_numpy(), vmin=temp_kwargs['colorbar_scale'][0], vmax=temp_kwargs['colorbar_scale'][1],\n",
    "                        cmap=temp_kwargs['colormap'], edgecolors='k', linewidths=0.2, color='darkgrey')\n",
    "\n",
    "    # ____________axes manipulation____________________________________________\n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_xticks(np.arange(df.shape[1]) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(df.shape[0]) + 0.5, minor=False)\n",
    "\n",
    "    # position of axis labels\n",
    "    ax.tick_params('x', direction='out', pad=-2.5)\n",
    "    ax.tick_params('y', direction='out', pad=0.4)\n",
    "\n",
    "    # want a more natural, table-like display\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    "\n",
    "    # remove ticks\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "\n",
    "    # so labels of x and y do not show up and my labels show up instead\n",
    "    ax.set_xticklabels(list(df.columns), fontsize=6.5,\n",
    "                       fontname=\"Arial\", color='k', minor=False)\n",
    "    ax.set_yticklabels(temp_kwargs['neworder_aminoacids'],\n",
    "                       fontsize=6.5, fontname=\"Arial\", color='k', minor=False)\n",
    "\n",
    "    # align the labels of the y axis\n",
    "    for ylabel in ax.get_yticklabels():\n",
    "        ylabel.set_horizontalalignment('center')\n",
    "\n",
    "    # _____________________________________________________________________________\n",
    "\n",
    "    # for color bar format\n",
    "    cb = plt.colorbar(heatmap, fraction=0.025, pad=0.05, aspect=5, ticks=[temp_kwargs['colorbar_scale'][0], np.mean(\n",
    "        temp_kwargs['colorbar_scale']), temp_kwargs['colorbar_scale'][1]], orientation='vertical')\n",
    "    cb.ax.set_yticklabels(cb.ax.get_yticklabels(), fontsize=7, fontname=\"Arial\", color='k')\n",
    "    cb.update_ticks()\n",
    "    plt.text(len(df.columns)+2, 7.8, r'$\\langle∆E^x_i\\rangle_x$', horizontalalignment='center',\n",
    "             fontsize=7, fontname=\"Arial\", color='k')\n",
    "\n",
    "    # for putting title on graph\n",
    "    plt.title(temp_kwargs['title'], horizontalalignment='center',\n",
    "              fontname=\"Arial\", fontsize=10, pad=10)\n",
    "    plt.ylabel('Amino Acid Substitution', fontsize=10, labelpad=-1)\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig,temp_kwargs)\n",
    "    \n",
    "    if temp_kwargs['show']: plt.show()\n",
    "    return\n",
    "\n",
    "def _normalize_neighboreffect(self,offset,neworder):\n",
    "    '''\n",
    "    For every residue, subtract the average effect of a substitution\n",
    "    Returns a normalized dataframe\n",
    "    '''\n",
    "    aalist = list('ACDEFGHIKLMNPQRSTVWY')\n",
    "    # Add offset sequence to df\n",
    "    df = _transform_dataset_offset(self,offset,False)\n",
    "    \n",
    "    # calculate mean effect using condensed heatmap\n",
    "    mean = _condense_heatmap(self.dataframe, aalist)\n",
    "    \n",
    "    df_normalized = pd.DataFrame()\n",
    "    for aa in aalist:\n",
    "        # Choose the neighbors of an aa\n",
    "        aa_neighbors = df.loc[df['Sequence']==aa]\n",
    "        # Do the mean substitution of amino acids that are repeated\n",
    "        aa_neighbors = aa_neighbors.groupby(['Sequence_old','Aminoacid'],as_index=False).mean()\n",
    "        # Make into table\n",
    "        aa_neighbors_pivoted = aa_neighbors.pivot_table(values='Score', index='Aminoacid',  columns='Sequence_old')\n",
    "        aa_neighbors_pivoted.reset_index(drop=True, inplace=True)\n",
    "        # Get the mean of the amino acids that appear in the aa_neighbors subset\n",
    "        mean_neighbors = mean[list(aa_neighbors_pivoted.columns)]\n",
    "        # Subtract average effect and do mean\n",
    "        df_normalized[aa] = (aa_neighbors_pivoted - mean_neighbors).mean(axis=1)\n",
    "    \n",
    "    # Sort by aa\n",
    "    df_normalized = df_normalized[neworder]\n",
    "    # Sort in y axis desired order\n",
    "    df_normalized = _sort_yaxis_aminoacids(df_normalized,neworder,aalist)\n",
    "    return df_normalized\n",
    "\n",
    "def _sort_yaxis_aminoacids(df,neworder,oldorder=list('ACDEFGHIKLMNPQRSTVWY')):\n",
    "    # Sort in y axis desired order\n",
    "    df['Aminoacid_new'] = oldorder\n",
    "    df['Aminoacid_new'] = pd.Categorical(df['Aminoacid_new'], neworder)\n",
    "    df.sort_values(by=['Aminoacid_new'],inplace=True)\n",
    "    df.drop(['Aminoacid_new'], inplace=True, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.792871Z",
     "start_time": "2020-09-13T01:45:00.776371Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_correlation(self, **kwargs):\n",
    "    '''\n",
    "    Generate a correlation of each amino acid\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None.\n",
    "    '''\n",
    "\n",
    "    # load font parameters\n",
    "    _font_parameters()\n",
    "\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "\n",
    "    # load labels\n",
    "    temp_kwargs['color_sequencelabels'] = _labels(self.start_position)[0]\n",
    "    temp_kwargs['number_sequencelabels'] = _labels(self.start_position)[1]\n",
    "\n",
    "    # calculate correlation heatmap\n",
    "    dataset = _calculate_correlation(\n",
    "        self.dataframe_stopcodons, temp_kwargs['neworder_aminoacids'])\n",
    "\n",
    "    # declare figure and subplots\n",
    "    coeff = len(dataset.columns)/19*1.05\n",
    "    fig = plt.figure(figsize=(2.5*coeff, 2.5))\n",
    "    gs = gridspec.GridSpec(nrows=1, ncols=1)\n",
    "    ax = plt.subplot(gs[0])\n",
    "\n",
    "    # main heatmap\n",
    "    heatmap = ax.pcolor(dataset.corr(), vmin=temp_kwargs['colorbar_scale'][0], vmax=temp_kwargs['colorbar_scale'][1],\n",
    "                        cmap='Greys', edgecolors='k', linewidths=0.2, color='darkgrey')\n",
    "\n",
    "    # ____________axes manipulation____________________________________________\n",
    "    # put the major ticks at the middle of each cell\n",
    "    ax.set_xticks(np.arange(dataset.shape[1]) + 0.5, minor=False)\n",
    "    ax.set_yticks(np.arange(dataset.shape[0]) + 0.5, minor=False)\n",
    "\n",
    "    # position of axis labels\n",
    "    ax.tick_params('x', direction='out', pad=-2.5)\n",
    "    ax.tick_params('y', direction='out', pad=0.4)\n",
    "\n",
    "    # want a more natural, table-like display\n",
    "    ax.invert_yaxis()\n",
    "    ax.xaxis.tick_top()\n",
    "\n",
    "    # remove ticks\n",
    "    ax.xaxis.set_ticks_position('none')\n",
    "    ax.yaxis.set_ticks_position('none')\n",
    "\n",
    "    # so labels of x and y do not show up and my labels show up instead\n",
    "    ax.set_xticklabels(list(dataset.columns), fontsize=6.5,\n",
    "                       fontname=\"Arial\", color='k', minor=False)\n",
    "    ax.set_yticklabels(temp_kwargs['neworder_aminoacids'],\n",
    "                       fontsize=6.5, fontname=\"Arial\", color='k', minor=False)\n",
    "\n",
    "    # align the labels of the y axis\n",
    "    for ylabel in ax.get_yticklabels():\n",
    "        ylabel.set_horizontalalignment('center')\n",
    "\n",
    "    # _____________________________________________________________________________\n",
    "\n",
    "    # for color bar format\n",
    "    cb = plt.colorbar(heatmap, fraction=0.025, pad=0.05, aspect=5, ticks=[temp_kwargs['colorbar_scale'][0], temp_kwargs['colorbar_scale'][1]],\n",
    "                      orientation='vertical')\n",
    "    cb.ax.set_yticklabels(cb.ax.get_yticklabels(),\n",
    "                          fontsize=7, fontname=\"Arial\", color='k')\n",
    "    cb.update_ticks()\n",
    "    plt.text(len(dataset.columns)+1.2*coeff, len(dataset.columns)/2.5, 'R',\n",
    "             horizontalalignment='center', fontsize=7, fontname=\"Arial\", color='k')\n",
    "\n",
    "    # for putting title on graph\n",
    "    plt.title(temp_kwargs['title'], horizontalalignment='center',\n",
    "              fontname=\"Arial\", fontsize=10, pad=10)\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "\n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def _calculate_correlation(df, order_aminoacids):\n",
    "\n",
    "    dataset = df.copy()\n",
    "    dataset = dataset.pivot_table(\n",
    "        values='Score', index='Position',  columns='Aminoacid')\n",
    "    dataset = dataset.corr()\n",
    "    dataset = dataset.reindex(index=order_aminoacids)[order_aminoacids]\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def _calculate_correlation_byresidue(df):\n",
    "\n",
    "    dataset = df.copy()\n",
    "    dataset = dataset.pivot_table(\n",
    "        values='Score', index='Position',  columns='Aminoacid')\n",
    "    dataset = dataset.T.corr()\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.806690Z",
     "start_time": "2020-09-13T01:45:00.798464Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_individual_correlation(self, **kwargs):\n",
    "    '''\n",
    "    Genereates a bar plot of the correlation of each amino acid mutational \n",
    "    profile (row of the heatmap) with the rest of amino acids (rows)\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    # Load parameters\n",
    "    _parameters()\n",
    "\n",
    "    # Update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    temp_kwargs['figsize'] = kwargs.get('figsize', (3.5, 2))\n",
    "    temp_kwargs['yscale'] = kwargs.get('yscale', (0, 1))\n",
    "\n",
    "    # Get data\n",
    "    if '*' in temp_kwargs['neworder_aminoacids']:\n",
    "        temp_kwargs['neworder_aminoacids'].remove('*')\n",
    "    df = _calculate_correlation(\n",
    "        self.dataframe, temp_kwargs['neworder_aminoacids']).mean()**2\n",
    "\n",
    "    # Make figure\n",
    "    fig, ax = plt.subplots(figsize=temp_kwargs['figsize'])\n",
    "    ticks = np.arange(0, len(df))  # label locations\n",
    "    width = 0.5\n",
    "    labels = temp_kwargs['neworder_aminoacids']\n",
    "    # Plot figure\n",
    "    ax.bar(ticks, df, width, color='blue', ec='k',)\n",
    "\n",
    "    # graph parameters\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels(labels, fontsize=9, fontname=\"Arial\",\n",
    "                       color='k', minor=False, rotation=0)\n",
    "    ax.set_ylabel(r'$R^2$', fontsize=10, fontname=\"Arial\",\n",
    "                  color='k', labelpad=12, rotation=0)\n",
    "    ax.set_ylim(temp_kwargs['yscale'])\n",
    "    plt.title(temp_kwargs['title'], horizontalalignment='center',\n",
    "              fontname=\"Arial\", fontsize=10, pad=5)\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.821827Z",
     "start_time": "2020-09-13T01:45:00.808400Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_group_correlation(self, r2, groups=['DEHKR', 'QN', 'CASTG', 'ILMV', 'WYF'],\n",
    "                        output=False, **kwargs):\n",
    "    '''\n",
    "    Determines which amino acids better represent the heatmap. Requires logomaker package.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    r2 : float\n",
    "        cutoff of the r**2 correlation value. Only values above that will be plot at the sequence logo\n",
    "    \n",
    "    groups : list, default ['DEHKR','QN','CASTG','ILMV','WYF']\n",
    "        groups of aa to combine together\n",
    "    \n",
    "    output : boolean, default False\n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    Use logomaker to plot the most frequent residues. \n",
    "    Optional gives back the different combinations of groups and the R**2 values\n",
    "    '''\n",
    "\n",
    "    # Update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "\n",
    "    # Apply parameters\n",
    "    _parameters()\n",
    "\n",
    "    # If there is a stop codon, delete it\n",
    "    if '*' in temp_kwargs['neworder_aminoacids']:\n",
    "        temp_kwargs['neworder_aminoacids'].remove('*')\n",
    "        \n",
    "    # Get R2 of each combination of amino acid substitutions\n",
    "    df = _calculate_substitution_correlations(self, temp_kwargs['neworder_aminoacids'], groups)\n",
    "\n",
    "    # Filter according the the R2 correlation value\n",
    "    filtered = df.loc[df['R2'] > r2]\n",
    "    logoplot = logomaker.alignment_to_matrix(list(filtered['Combinations']))\n",
    "\n",
    "    # create Logo object\n",
    "    fig = logomaker.Logo(logoplot, font_name='Arial', color_scheme='chemistry', vpad=.1,\n",
    "                         width=.8, figsize=((len(logoplot)+1)/2.5, 1))\n",
    "\n",
    "    # style using Logo methods\n",
    "    fig.style_xticks(anchor=0, spacing=1, rotation=0)\n",
    "\n",
    "    # No yticks and no xticks (but keep labels)\n",
    "    plt.yticks([], [])\n",
    "    fig.ax.tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "    # style using Axes methods\n",
    "    fig.ax.set_ylabel('Bits')\n",
    "    fig.ax.set_xlim([-0.5, len(logoplot)-0.5])\n",
    "\n",
    "    # for putting title on graph\n",
    "    plt.title(temp_kwargs['title'], horizontalalignment='center',\n",
    "              fontname=\"Arial\", fontsize=10, pad=10)\n",
    "\n",
    "    # save file, cannot save logo file for now\n",
    "    #_savefile(fig.ax, temp_kwargs)\n",
    "\n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "        \n",
    "    if output:\n",
    "        return df\n",
    "\n",
    "\n",
    "def _calculate_substitution_correlations(self, aminoacids, groups):\n",
    "    '''if a set of residues was chosen, how well would they represent the entire population'''\n",
    "    \n",
    "    # Get correlation values\n",
    "    corr_values = _calculate_correlation(self.dataframe, aminoacids)**2\n",
    "    corr_values.reset_index(inplace=True)\n",
    "\n",
    "    # Get combinations\n",
    "    replacement_combinations = list(itertools.product(*groups))\n",
    "\n",
    "    # Retrieve Correlation values\n",
    "    df = pd.DataFrame()\n",
    "    df['Aminoacids'] = list(itertools.chain.from_iterable(groups))\n",
    "    for combination in replacement_combinations:  # Iterate over a combination\n",
    "        temp_list = []\n",
    "        \n",
    "        # Iterate over a group of the combination\n",
    "        for group, aa_selected in zip(groups, combination):\n",
    "            for aa_nonselected in group:  # Find correlation values from correlation plot\n",
    "                if aa_nonselected == aa_selected:\n",
    "                    temp_list.append(1)\n",
    "                else:\n",
    "                    temp_list.append(_find_correlation(\n",
    "                        aa_selected, aa_nonselected, corr_values))\n",
    "        df[combination] = temp_list  # Store in df\n",
    "    return _polishdf(df)\n",
    "\n",
    "\n",
    "def _polishdf(df):\n",
    "    df_mean = df.copy()\n",
    "    df_mean = df.mean().to_frame()\n",
    "    df_mean.reset_index(drop=False, inplace=True)\n",
    "    df_mean.rename(columns={0: 'R2'}, inplace=True)\n",
    "    df_mean['Combinations'] = list(df_mean['index'].apply(lambda x: ''.join(x)))\n",
    "    df_mean.drop(columns=['index'], inplace=True)\n",
    "    return df_mean\n",
    "\n",
    "\n",
    "def _find_correlation(aa1, aa2, corr_values):\n",
    "    return float(corr_values[aa1].loc[corr_values['Aminoacid'] == aa2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.839143Z",
     "start_time": "2020-09-13T01:45:00.823616Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_pca(self, mode='aminoacid', dimensions=[0, 1], adjustlabels = False, **kwargs):\n",
    "    '''\n",
    "    Genereates a plot of two PCA dimensions\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    mode : list, default 'aminoacid'\n",
    "        Can also do PCA by secondary structure element if set to \"secondary\" or \n",
    "        by individual residue if set to \"individual\".\n",
    "    \n",
    "    dimensions : list, default [0,1]\n",
    "        Specify which two PCA dimensions to plot. By default PCA1 vs PCA2.\n",
    "        Max dimension is 5.\n",
    "    \n",
    "    adjustlabels : boolean, default False\n",
    "        If set to true, it will adjust the text labels so there is no overlap. It is convenient to increase\n",
    "        the size of the figure, otherwise the algorithm will not find a solution. Requires to install adjustText package.\n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "        random_state : int, default 554\n",
    "    Returns\n",
    "    ----------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "\n",
    "    # load parameters\n",
    "    _parameters()\n",
    "\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    temp_kwargs['figsize'] = kwargs.get('figsize', (2, 2))\n",
    "\n",
    "    # calculate correlation heatmap. Choose mode\n",
    "    dataset = self.dataframe.copy()\n",
    "    if mode == 'aminoacid':\n",
    "        if '*' in temp_kwargs['neworder_aminoacids']:\n",
    "            temp_kwargs['neworder_aminoacids'].remove('*')\n",
    "        dataset = _calculate_correlation(\n",
    "            dataset, temp_kwargs['neworder_aminoacids'])\n",
    "        textlabels = temp_kwargs['neworder_aminoacids']\n",
    "    elif mode == 'secondary':\n",
    "        dataset = _calculate_correlation_bysecondary(\n",
    "            dataset, self.secondary_dup)\n",
    "        textlabels = list(dataset.columns)\n",
    "    elif mode == 'individual':\n",
    "        dataset = _calculate_correlation_byresidue(dataset)\n",
    "        textlabels = list(dataset.columns)\n",
    "    \n",
    "    # plot using plot_clusters\n",
    "    dimensionstoplot, variance = _calculate_clusters(dataset, dimensions, temp_kwargs['random_state'])\n",
    "\n",
    "    # x and y\n",
    "    x = dimensionstoplot.iloc[:, 0]\n",
    "    y = dimensionstoplot.iloc[:, 1]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=temp_kwargs['figsize'])\n",
    "    ax.scatter(x, y, s=4, c='k')\n",
    "\n",
    "    # labels\n",
    "    plt.xlabel('PCA ' + str(dimensions[0]+1) + ': ' + str(int(variance[dimensions[0]]*100))+'%',\n",
    "               fontsize=10, labelpad=5, fontweight='normal')\n",
    "    plt.ylabel('PCA ' + str(dimensions[1]+1) + ': ' + str(int(variance[dimensions[1]]*100))+'%',\n",
    "               fontsize=10, labelpad=-2, fontweight='normal')\n",
    "\n",
    "    # label of data points\n",
    "    texts = _auto_text(x, y, textlabels)\n",
    "    if adjustlabels is True:\n",
    "        adjust_text(texts, autoalign='xy')\n",
    "    \n",
    "    # set title\n",
    "    plt.title(temp_kwargs['title'], horizontalalignment='center',\n",
    "              fontname=\"Arial\", fontsize=10, pad=5)\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "\n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def _auto_text(x, y, textlabels):\n",
    "    '''auto anotates text labels'''\n",
    "    texts = [plt.annotate(textlabels[i],  # this is the text\n",
    "                          (x[i], y[i]),  # this is the point to label\n",
    "                          textcoords=\"offset points\",  # how to position the text\n",
    "                          xytext=(2, 2),  # distance from text to points (x,y)\n",
    "                          fontsize=8,\n",
    "                          ha='center')  # horizontal alignment can be left, right or center\n",
    "             for i in range(len(textlabels))]\n",
    "    return texts\n",
    "\n",
    "\n",
    "def _calculate_clusters(dataset, dimensions, random_state):\n",
    "    '''input the dataframe that needs to be correlated, the dimensions, and will calculate PCA descomposition. '''\n",
    "\n",
    "    # call pca model\n",
    "    pca = PCA(n_components=6, random_state = random_state)\n",
    "\n",
    "    # fit model to df. use aux function correlation_aminoacids\n",
    "    model = pca.fit(dataset)\n",
    "\n",
    "    # create df with PCA data\n",
    "    df_aa = pd.DataFrame((model.components_).T, columns=[\n",
    "                         'PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6'])\n",
    "\n",
    "    # use kmeans to cluster the two dimensions and color\n",
    "    dimensionstoplot = df_aa.iloc[:, np.r_[dimensions[0], dimensions[1]]]\n",
    "\n",
    "    return dimensionstoplot, pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "def _grouby_secondary(df, secondary):\n",
    "    '''\n",
    "    Groups each secondary motif and makes the mean.\n",
    "\n",
    "    Returns dataframe. Returns copy\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df.insert(4, 'Secondary', secondary)\n",
    "    df = df.groupby(['Secondary', 'Aminoacid'], as_index=False).mean()\n",
    "    df = df.loc[df['Secondary'].str.startswith(('β', 'α'))]\n",
    "    return df\n",
    "\n",
    "\n",
    "def _calculate_correlation_bysecondary(df, secondary):\n",
    "    dataset = _grouby_secondary(df, secondary)\n",
    "    dataset = dataset.pivot_table(\n",
    "        values='Score', index='Secondary',  columns='Aminoacid')\n",
    "    dataset = dataset.T.corr()\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.853483Z",
     "start_time": "2020-09-13T01:45:00.841983Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_secondary(self, **kwargs):\n",
    "    '''\n",
    "    Genereates a bar plot of data sorted by secondary elements (alpha helices and beta sheets).\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    # Load parameters\n",
    "    _parameters()\n",
    "\n",
    "    # Update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    temp_kwargs['figsize'] = kwargs.get('figsize', (2.5, 2))\n",
    "    temp_kwargs['yscale'] = kwargs.get('yscale', (-2, 1))\n",
    "\n",
    "    # Get data\n",
    "    df = _calculate_secondary(self.dataframe, self.secondary_dup)\n",
    "\n",
    "    # Color\n",
    "    df['Color'] = df.apply(color_data, axis=1)\n",
    "\n",
    "    # Make figure\n",
    "    fig, ax = plt.subplots(figsize=temp_kwargs['figsize'])\n",
    "    ticks = np.arange(0, len(df))  # label locations\n",
    "    width = 0.5\n",
    "    labels = df['Secondary']\n",
    "    \n",
    "    # Plot figure\n",
    "    ax.bar(ticks, df['Score'], width, color=df['Color'], ec='k',)\n",
    "\n",
    "    # graph parameters\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_xticklabels(labels, fontsize=9, fontname=\"Arial\",\n",
    "                       color='k', minor=False, rotation=0)\n",
    "    ax.set_ylabel(r'$∆E^i_x$', fontsize=10, fontname=\"Arial\",\n",
    "                  color='k', labelpad=12, rotation=0)\n",
    "    ax.set_ylim(temp_kwargs['yscale'])\n",
    "    plt.title(temp_kwargs['title'], horizontalalignment='center',\n",
    "              fontname=\"Arial\", fontsize=10, pad=5)\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "    \n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def _calculate_secondary(df, secondary):\n",
    "    '''\n",
    "    Returns copy\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df.insert(4, 'Secondary', secondary)\n",
    "    df = df.groupby(['Secondary'], as_index=False, sort=False).mean()\n",
    "    df = df[df['Secondary'].str.startswith(('β', 'α'))]\n",
    "    df = df.drop(['Position'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.870342Z",
     "start_time": "2020-09-13T01:45:00.856472Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_roc(self, df_class=None, **kwargs):\n",
    "    '''\n",
    "    Generates ROC AUC plot. It compares enrichment scores to some labels that the user has specified.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    df_class: Pandas dataframe\n",
    "        A dataframe that contains a column of variants labeled 'Variant' with a column labeled 'Class'\n",
    "        containing the true class of that mutation. The true class can also be an input when creating the object.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    None.\n",
    "    '''\n",
    "    # Use default class\n",
    "    if df_class is None:\n",
    "        df_class = self.roc_df\n",
    "\n",
    "    # Merge dataframe with classes\n",
    "    df = _mergeclassvariants(df_class, self.dataframe)\n",
    "\n",
    "    # Calculate ROC parameters\n",
    "    fpr, tpr, auc, _ = _rocauc(df)\n",
    "\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    temp_kwargs['figsize'] = kwargs.get('figsize', (2.5, 2.5))\n",
    "\n",
    "    # import parameters\n",
    "    _parameters()\n",
    "\n",
    "    # create figure\n",
    "    fig, ax = plt.subplots(figsize=temp_kwargs['figsize'])\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='k', lw=lw, label='AUC = %0.2f' % auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "    # Graph limits\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    tick_spacing = 0.2\n",
    "    ax.xaxis.set_major_locator(\n",
    "        ticker.MultipleLocator(tick_spacing))  # Plt ticks\n",
    "    ax.yaxis.set_major_locator(\n",
    "        ticker.MultipleLocator(tick_spacing))  # Plt ticks\n",
    "\n",
    "    # Axis labels\n",
    "    plt.title(temp_kwargs['title'], fontsize=12, fontname='Arial', color='k')\n",
    "    plt.ylabel('True Positive Rate', fontsize=12,\n",
    "               fontname=\"Arial\", color='k', labelpad=0)\n",
    "    plt.xlabel('False Positive Rate', fontsize=12, fontname=\"Arial\", color='k')\n",
    "\n",
    "    # Legend\n",
    "    plt.legend(loc='lower right', handlelength=0,\n",
    "               handletextpad=0, frameon=False)\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def _rocauc(df):\n",
    "    '''\n",
    "    Calculate roc rates and auc.\n",
    "\n",
    "    The input is a dataframe that contains [Variants,Class,Score]\n",
    "    '''\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(\n",
    "        df['Class'], df['Score'], drop_intermediate=True)\n",
    "    auc = metrics.roc_auc_score(df['Class'], df['Score'])\n",
    "    return fpr, tpr, auc, thresholds\n",
    "\n",
    "\n",
    "def _mergeclassvariants(df_score, df_class):\n",
    "    '''\n",
    "    Merge the input dataframe containing the class (true score) for variants and the enrichment scores\n",
    "    '''\n",
    "    # Merge DMS with true score dataset\n",
    "    df_merged = pd.merge(df_class, df_score, on=['Variant'], how='left')\n",
    "\n",
    "    # Drop rows with Nan values\n",
    "    df_merged.dropna(inplace=True)\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "def _concattrueposneg(df_tp, df_tn, subset='Variant', keep='first'):\n",
    "    '''\n",
    "    Concat a df containing the true positive variants and the true negative variants\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    df_tp : Dataframe with the true positives\n",
    "    df_tn : Dataframe with the true negatives\n",
    "    subset : str, default Variant\n",
    "    keep : {‘first’, ‘last’, False} \n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    None.\n",
    "    '''\n",
    "    # Concatenate tp and tn datasets\n",
    "    df_true = pd.concat([df_tp, df_tn], sort=False)\n",
    "\n",
    "    # Will keep a variant as true positive if found in both datasets (because could be a mistake in gnomAD)\n",
    "    df_true.drop_duplicates(subset=subset, keep=keep, inplace=True)\n",
    "\n",
    "    return df_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.883030Z",
     "start_time": "2020-09-13T01:45:00.872398Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_cumulative(self, mode='all', **kwargs):\n",
    "    '''\n",
    "    Generates a cumulative plot of the enrichment scores by position. \n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    self : object from class \"Screen\"\n",
    "    \n",
    "    mode : str, default 'all' \n",
    "        Options are 'all','SNV' and 'nonSNV'.\n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    None.\n",
    "    '''\n",
    "\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    temp_kwargs['figsize'] = kwargs.get('figsize', (3, 2))\n",
    "    temp_kwargs['tick_spacing'] = kwargs.get('tick_spacing', 20)\n",
    "\n",
    "    # import parameters\n",
    "    _parameters()\n",
    "\n",
    "    # create figure\n",
    "    fig, ax = plt.subplots(figsize=temp_kwargs['figsize'])\n",
    "\n",
    "    # Get data filtered\n",
    "    df = _filter(self, mode)\n",
    "    cumsum = df.cumsum(skipna=False)['Score']\n",
    "    plt.plot(df['Position'], cumsum/list(cumsum)[-1], color='red', lw=2)\n",
    "\n",
    "    # y label\n",
    "    y_label = 'Cumulative LoF'\n",
    "    if list(cumsum)[-1] > 0:\n",
    "        y_label = 'Cumulative GoF'\n",
    "\n",
    "    # Graph limits\n",
    "    plt.xlim(self.dataframe['Position'].min(),\n",
    "             self.dataframe['Position'].max()+1)\n",
    "    plt.ylim(0, 1.1)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(\n",
    "        temp_kwargs['tick_spacing']))  # Plt ticks\n",
    "\n",
    "    # Axis labels\n",
    "    plt.title(temp_kwargs['title'], fontsize=12, fontname='Arial', color='k')\n",
    "    plt.ylabel(y_label, fontsize=12, fontname=\"Arial\", color='k', labelpad=5)\n",
    "    plt.xlabel('Position', fontsize=12,\n",
    "               fontname=\"Arial\", color='k', labelpad=0)\n",
    "\n",
    "    # x=y line\n",
    "    plt.plot([0, df['Position'].max()], [0, 1],\n",
    "             color='silver', lw=2, linestyle='--')\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "def _filter(self, mode):\n",
    "\n",
    "    # Select all, SNV, nonSNV\n",
    "    if mode == 'all':\n",
    "        df = self.dataframe\n",
    "    elif mode == 'SNV':\n",
    "        df = self.dataframe_SNV\n",
    "    elif mode == 'nonSNV':\n",
    "        df = self.dataframe_nonSNV\n",
    "    df = df.groupby(by='Position', as_index=False).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.899116Z",
     "start_time": "2020-09-13T01:45:00.891120Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_box(binned_x, y, **kwargs):\n",
    "    '''\n",
    "    Genereates a boxplot. Data needs to be binned prior before using this function. \n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    x, binned_y : arrays\n",
    "        Contain the data is going to plot\n",
    "        \n",
    "    **kwargs : other keyword arguments\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None.\n",
    "\n",
    "    '''\n",
    "    # Load parameters\n",
    "    _parameters()\n",
    "\n",
    "    # Update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    temp_kwargs['figsize'] = kwargs.get('figsize', (2.5, 2))\n",
    "\n",
    "    # Make figure\n",
    "    fig, ax = plt.subplots(figsize=temp_kwargs['figsize'])\n",
    "    \n",
    "    # Plot data\n",
    "    ax = sns.boxplot(binned_x, y, color='white', fliersize=2)\n",
    "\n",
    "    plt.setp(ax.artists, edgecolor='k', facecolor='w')\n",
    "    plt.setp(ax.lines, color='k')\n",
    "\n",
    "    # graph parameters\n",
    "    plt.title(temp_kwargs['title'], fontsize=10,\n",
    "              fontname='Arial', color='k', pad=8)\n",
    "    plt.ylabel(temp_kwargs['y_label'], fontsize=10,\n",
    "               fontname=\"Arial\", color='k', labelpad=0)\n",
    "    plt.xlabel(temp_kwargs['x_label'], fontsize=10,\n",
    "               fontname=\"Arial\", color='k')\n",
    "\n",
    "    # axes limits\n",
    "    plt.xlim(temp_kwargs['xscale'])\n",
    "    plt.ylim(temp_kwargs['yscale'])\n",
    "    plt.grid()\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "    \n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T03:35:01.077953Z",
     "start_time": "2020-09-14T03:35:01.056454Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_scatter_3D(self, mode='mean', pdb_path=None, df_coordinates=None,\n",
    "                    df_color=None,  position_correction=0, chain='A',\n",
    "                    squared=False, rotate=False, **kwargs):\n",
    "    '''\n",
    "    Generates a 3-D scatter plot of the x,y,z coordinates of the C-alpha atoms of the residues, \n",
    "    color coded by the enrichment scores. PDBs may have atoms missing, \n",
    "    you should fix the PDB before using this method. Use matplotlib for interactive plot.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    self : object from class \"Screen\"\n",
    "        **kwargs : other keyword arguments.\n",
    "\n",
    "    mode : str, default 'mean'\n",
    "        Specify what enrichment scores to use. If mode = 'mean', it will use the mean of \n",
    "        each position to classify the residues. If mode = 'A', it will use the Alanine substitution profile. \n",
    "        Can be used for each amino acid. Use the one-letter code and upper case.\n",
    "\n",
    "    pdb : str, default None\n",
    "        User should specify the path PDB chain.\n",
    "\n",
    "    df_coordinates: pandas dataframe, default None\n",
    "        If no pdb is included, the user must pass the 3-D coordinates of the residues to plot. \n",
    "        In here you have more flexibility and you can select other atoms besides the C-alpha.\n",
    "\n",
    "    df_color : pandas dataframe, default None     \n",
    "        The color of each residue can also be included. You must label that label column.\n",
    "\n",
    "    position_correction : int, default 0\n",
    "        If the pdb structure has a different numbering of positions than you dataset,\n",
    "        you can correct for that. If your start_position = 2, but in the PDB that same residue\n",
    "        is at position 20, position_correction needs to be set at 18.\n",
    "\n",
    "    chain : str, default 'A'\n",
    "        Chain of the PDB file to get the coordinates and SASA from.\n",
    "\n",
    "    squared : booleand, False\n",
    "        If this parameter is True, the algorithm will center the data, and plot the square value of the \n",
    "        distance.\n",
    "\n",
    "    rotate : boolean, False\n",
    "        If you are using an interactive matplotlib, set up rotate = True so the graph spins.\n",
    "\n",
    "    **kwargs : other keyword arguments\n",
    "        gof : int, default is 1\n",
    "                 cutoff for determining gain of function mutations based on mutagenesis data.\n",
    "        lof : int, default is -1\n",
    "            cutoff for determining loss of function mutations based on mutagenesis data.\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    None\n",
    "    '''\n",
    "\n",
    "    # Load parameters\n",
    "    _parameters()\n",
    "\n",
    "    # Update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "\n",
    "    # Get Scores and colors\n",
    "    if df_color is None:\n",
    "        df = _color_3D_scatter(self.dataframe, mode, temp_kwargs['lof'],\n",
    "                               temp_kwargs['gof'])\n",
    "\n",
    "    # If coordinates is not an input, get it from the pdb\n",
    "    if df_coordinates is None:\n",
    "        df_coordinates = _parse_pdbcoordinates(\n",
    "            self, pdb_path, position_correction, chain)\n",
    "\n",
    "    # Plot figure\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    if squared is False:\n",
    "        ax.scatter(df_coordinates['x'], df_coordinates['y'],\n",
    "                   df_coordinates['z'], c=df['Color'])\n",
    "    else:\n",
    "        ax.scatter(df_coordinates['x_cent'], df_coordinates['y_cent'],\n",
    "                   df_coordinates['z_cent'], c=df['Color'])\n",
    "        \n",
    "\n",
    "    ax.set_xlabel('X axis')\n",
    "    ax.set_ylabel('Y axis')\n",
    "    ax.set_zlabel('Z axis')\n",
    "\n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "\n",
    "    # rotate if you are using interactive plot\n",
    "    if rotate is True:\n",
    "        for angle in range(0, 360):\n",
    "            ax.view_init(30, angle)\n",
    "            plt.draw()\n",
    "            plt.pause(.001)\n",
    "\n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def _color_3D_scatter(df, mode, lof, gof):\n",
    "    '''Color the data points by enrichment scores'''\n",
    "    # Copy df\n",
    "    df_grouped = df.copy()\n",
    "\n",
    "    # Select grouping\n",
    "    if mode == 'mean':\n",
    "        df_grouped = df_grouped.groupby(['Position'], as_index=False).mean()\n",
    "    else:\n",
    "        df_grouped = df_grouped.loc[df_grouped['Aminoacid'] == mode]\n",
    "\n",
    "    # Select colors\n",
    "    df_grouped['Color'] = 'green'\n",
    "    df_grouped.loc[df_grouped['Score'] < lof, 'Color'] = 'blue'\n",
    "    df_grouped.loc[df_grouped['Score'] > gof, 'Color'] = 'red'\n",
    "\n",
    "    return df_grouped\n",
    "\n",
    "\n",
    "def centeroidnp(df):\n",
    "    '''find center of x,y,z'''\n",
    "    return df['x'].sum()/len(df['x']), df['y'].sum()/len(df['y']), df['z'].sum()/len(df['z'])\n",
    "\n",
    "\n",
    "def _parse_pdbcoordinates(self, pdb_path, position_correction, chain, sasa=False):\n",
    "    '''parse coordinate of CA atoms. Will also return the bfactor and SASA using freesasa.\n",
    "    If PDB is missing atoms, it can handle it.'''\n",
    "    \n",
    "    # Get structure from PDB\n",
    "    structure = PDBParser().get_structure('pdb', pdb_path)\n",
    "\n",
    "    coordinates = []\n",
    "    commands = []\n",
    "    bfactors = []\n",
    "    positions_worked =[] # positions present in pdb\n",
    "    \n",
    "    # Iterate over each CA atom and geet coordinates\n",
    "    for i in np.arange(self.start_position+position_correction, self.end_position+position_correction):\n",
    "        # first check if atom exists\n",
    "        try:\n",
    "            structure[0][chain][int(i)].has_id(\"CA\")\n",
    "            # Get atom from pdb and geet coordinates\n",
    "            atom = list(structure[0][chain][int(i)][\"CA\"].get_vector())+[i]\n",
    "            coordinates.append(atom)\n",
    "            # Get SASA command for each residue and bfactor\n",
    "            residue = \"s{}, chain {} and resi {}\".format(str(i), chain, str(i))\n",
    "            commands.append(residue)\n",
    "            bfactor = (structure[0][chain][int(i)][\"CA\"].get_bfactor())\n",
    "            bfactors.append(bfactor)\n",
    "            positions_worked.append(i)\n",
    "        except:\n",
    "            print (\"residue {} not found\".format(str(i)))\n",
    "            coordinates.append([np.nan, np.nan, np.nan, i])\n",
    "            \n",
    "    # Convert to df\n",
    "    df_coordinates = pd.DataFrame(\n",
    "        columns=['x', 'y', 'z', 'Position'], data=coordinates)\n",
    "\n",
    "    # Center data\n",
    "    x, y, z = centeroidnp(df_coordinates)\n",
    "    df_coordinates['x_cent'] = (df_coordinates['x']-x).abs()**2\n",
    "    df_coordinates['y_cent'] = (df_coordinates['y']-y).abs()**2\n",
    "    df_coordinates['z_cent'] = (df_coordinates['z']-z).abs()**2\n",
    "    df_coordinates['Distance'] = df_coordinates['x_cent'] + \\\n",
    "        df_coordinates['y_cent']+df_coordinates['z_cent']\n",
    "\n",
    "    # Add sasa values\n",
    "    if sasa:\n",
    "        # Get structure for SASA\n",
    "        structure_sasa = freesasa.Structure(pdb_path)\n",
    "        result = freesasa.calc(structure_sasa)\n",
    "        # Calculate sasa\n",
    "        sasa = freesasa.selectArea(commands, structure_sasa, result)\n",
    "        df_sasa = pd.DataFrame(columns=['SASA'], data=sasa.values())\n",
    "        df_sasa['B-factor'] = bfactors\n",
    "        df_sasa['Position'] = positions_worked\n",
    "\n",
    "        # Merge\n",
    "        df_coordinates = df_coordinates.merge(df_sasa,how='outer', on='Position')\n",
    "\n",
    "    return df_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Scatter Second version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-14T03:50:08.603954Z",
     "start_time": "2020-09-14T03:50:08.591491Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_scatter_3D_pdbprop(self, plot=['Distance', 'SASA', 'B-factor'],\n",
    "                            mode='mean', pdb_path=None, custom=None, \n",
    "                            axis_scale = [\"linear\", \"linear\", \"linear\"],\n",
    "                            df_color=None,  color_by_score=True,\n",
    "                            position_correction=0, chain='A',\n",
    "                            rotate=False, output_df= False, **kwargs):\n",
    "    '''\n",
    "    Generates a 3-D scatter plot of different properties obtained from the PDB. \n",
    "    PDBs may have atoms missing, you should fix the PDB before using this\n",
    "    method. We recommend you use matplotlib for interactive plot. \n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    self : object from class \"Screen\"\n",
    "        **kwargs : other keyword arguments.\n",
    "\n",
    "    plot : list, default ['Distance', 'SASA', 'B-factor']\n",
    "        List of 3 elements to plot. Other options are 'Score' and Custom. If custom, add the \n",
    "        label to the third element of the list ie ['Distance', 'SASA', 'Conservation']. \n",
    "\n",
    "    mode : str, default 'mean'\n",
    "        Specify what enrichment scores to use. If mode = 'mean', it will use the mean of \n",
    "        each position to classify the residues. If mode = 'A', it will use the Alanine substitution profile. Can be \n",
    "        used for each amino acid. Use the one-letter code and upper case.\n",
    "\n",
    "    pdb_path : str, default None\n",
    "        User should specify the path PDB.\n",
    "    \n",
    "    custom : list or dataframe or np.array, default None\n",
    "        If you want to add a custom dataset to plot, use custom. On the parameter\n",
    "        plot, the 3rd item of the list will be the label for your custom dataset.\n",
    "    \n",
    "    axis_scale : list, default [\"linear\", \"linear\", \"linear\"]\n",
    "        Check matplotlib.axes.Axes.set_xscale documentation for more information.\n",
    "        The axis scale type to apply. Some options are {\"linear\", \"log\", \"symlog\", \"logit\", ...}.\n",
    "        \n",
    "    df_color : pandas dataframe, default None     \n",
    "        The color of each residue can also be included. You must label that label column.\n",
    "    \n",
    "    color_by_score : boolean, default True\n",
    "        If set to False, the points in the scatter will not be colored based on the enrichment score.\n",
    "\n",
    "    position_correction : int, default 0\n",
    "        If the pdb structure has a different numbering of positions than you dataset,\n",
    "        you can correct for that. If your start_position = 2, but in the PDB that same residue\n",
    "        is at position 20, position_correction needs to be set at 18.\n",
    "\n",
    "    chain : str, default 'A'\n",
    "        Chain of the PDB file to get the coordinates and SASA from.\n",
    "\n",
    "    rotate : boolean, False\n",
    "        If you are using an interactive matplotlib, set up rotate = True so the graph spins.\n",
    "    \n",
    "    output_df : boolean, default False\n",
    "        If true, this method will return the dataframe with the data.\n",
    "        \n",
    "    **kwargs : other keyword arguments\n",
    "        gof : int, default is 1\n",
    "                 cutoff for determining gain of function mutations based on mutagenesis data.\n",
    "        lof : int, default is -1\n",
    "            cutoff for determining loss of function mutations based on mutagenesis data.\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    df_items : pandas dataframe\n",
    "        Contains the plotted data. Needs to have output_df set to true.\n",
    "    '''\n",
    "\n",
    "    # Load parameters\n",
    "    _parameters()\n",
    "\n",
    "    # Update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "    temp_kwargs['x_label'] = kwargs.get('x_label', plot[0])\n",
    "    temp_kwargs['y_label'] = kwargs.get('y_label', plot[1])\n",
    "    temp_kwargs['z_label'] = kwargs.get('z_label', plot[2])\n",
    "    \n",
    "    # Get Scores and colors\n",
    "    df_scores = _color_3D_scatter(self.dataframe, mode, temp_kwargs['lof'],\n",
    "                           temp_kwargs['gof'])\n",
    "    \n",
    "    # If coordinates is not an input, get it from the pdb\n",
    "    df_items = _parse_pdbcoordinates(self, pdb_path, position_correction,\n",
    "                                     chain, sasa=True)\n",
    "    \n",
    "    # Add scores\n",
    "    df_items['Score'] = list(df_scores['Score'])\n",
    "    \n",
    "    \n",
    "    # Custom data\n",
    "    if custom is not None:\n",
    "        df_items[plot[2]] = custom\n",
    "        \n",
    "    # Plot figure\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    if df_color is None and color_by_score is True:\n",
    "        c = df_scores['Color']\n",
    "    elif df_color is None and color_by_score is False:\n",
    "        c = 'k'\n",
    "    else:\n",
    "        c = df_scores['Color']\n",
    "    \n",
    "    ax.scatter(df_items[plot[0]], df_items[plot[1]], df_items[plot[2]], c=c)\n",
    "\n",
    "    # axis labels\n",
    "    ax.set_xlabel(temp_kwargs['x_label'])\n",
    "    ax.set_ylabel(temp_kwargs['y_label'])\n",
    "    ax.set_zlabel(temp_kwargs['z_label'])\n",
    "    \n",
    "    # axis scales\n",
    "    ax.set_xscale(axis_scale[0])\n",
    "    ax.set_yscale(axis_scale[1])\n",
    "    ax.set_zscale(axis_scale[2])\n",
    "    \n",
    "    # save file\n",
    "    _savefile(fig, temp_kwargs)\n",
    "\n",
    "    # rotate if you are using interactive plot\n",
    "    if rotate is True:\n",
    "        for angle in range(0, 360):\n",
    "            ax.view_init(30, angle)\n",
    "            plt.draw()\n",
    "            plt.pause(.001)\n",
    "\n",
    "    if temp_kwargs['show']:\n",
    "        plt.show()\n",
    "    \n",
    "    if output_df:\n",
    "        return df_items, df_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map into Pymol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:00.996068Z",
     "start_time": "2020-09-13T01:45:00.932079Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_pymol(self, pdb, mode = 'mean', residues=None, position_correction = 0,\n",
    "               quit=False, **kwargs):\n",
    "    '''\n",
    "    Color pymol structure residues. User can specify the residues to color, or can use the mutagenesis data.\n",
    "    Activating mutations will be colored red and loss of function blue. Neutral mutations in green.\n",
    "    Only works if pymol is your $PATH as pymol or you can start PyMOL in server mode.\n",
    "    Uses the ipymol package, which needs to be installed from Github $pip install git+https://github.com/cxhernandez/ipymol , not from pypi (not updated there).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pdb : str\n",
    "        User should specify the PDB chain in the following format 4G0N_A.\n",
    "        If you have internet connection, Pymol will download the pdb. Otherwise,\n",
    "        include the path were your PDB is stored locally.\n",
    "        \n",
    "    mode : str, default 'mean'\n",
    "        Specify what enrichment scores to use. If mode = 'mean', it will use the mean of \n",
    "        each position to classify the residues. If mode = 'A', it will use the Alanine substitution profile. Can be \n",
    "        used for each amino acid. Use the one-letter code and upper case.\n",
    "        \n",
    "    residues : list , optional\n",
    "        If user decides to pass custom arguments, use the following format\n",
    "        residues = ['1,2,3,4-10','12-15,23,24,35','48,49,50,52-60'] which are [blue,red,green].\n",
    "    \n",
    "    position_correction : int, default 0\n",
    "        If the pdb structure has a different numbering of positions than you dataset,\n",
    "        you can correct for that. If your start_position = 2, but in the PDB that same residue\n",
    "        is at position 20, position_correction needs to be set at 18.\n",
    "    \n",
    "    quit : boolean, default False\n",
    "        if quit, close pymol after executing code.\n",
    "    \n",
    "    **kwargs : other keyword arguments\n",
    "         gof : int, default is 1\n",
    "             cutoff for determining gain of function mutations based on mutagenesis data.\n",
    "         lof : int, default is -1\n",
    "             cutoff for determining loss of function mutations based on mutagenesis data.\n",
    "    Returns\n",
    "    ----------\n",
    "    Open pymol session with a fetched pdb structure where the residues are colored according to the enrichment scores.\n",
    "    '''\n",
    "    # update kwargs\n",
    "    temp_kwargs = copy.deepcopy(default_kwargs)\n",
    "    temp_kwargs.update(kwargs)\n",
    "\n",
    "    # Calculate residues only if they are not given by the user\n",
    "    if residues is None:\n",
    "        residues = _pymol_fitness(self.dataframe.copy(), temp_kwargs['gof'], \n",
    "                                  temp_kwargs['lof'], mode, position_correction)\n",
    "\n",
    "    # Start Pymol\n",
    "    if not pymol._process_is_running():\n",
    "        pymol.start()\n",
    "\n",
    "    # Fetch structure. If pdb contains a \"/\", it will assume it is stored locally\n",
    "    if '/' in pdb:\n",
    "        pymol.load(pdb)\n",
    "        pdb = (path.basename(pdb)).partition('.')[0] # Extract filename from pdb and then extract pdb code\n",
    "    else:\n",
    "        pymol.fetch(pdb)\n",
    "    \n",
    "    # Hide everything\n",
    "    pymol.do('hide everything')\n",
    "\n",
    "    # Selection names\n",
    "    blue = pdb + '_blue'\n",
    "    red = pdb + '_red'\n",
    "    white = pdb + '_white'\n",
    "\n",
    "    # Do selections\n",
    "    pymol.select(blue, 'resi ' + residues[0])\n",
    "    pymol.select(red, 'resi ' + residues[1])\n",
    "    pymol.select(white, 'resi ' + residues[2])\n",
    "\n",
    "    # Representation parameters\n",
    "    pymol.show_as('cartoon', pdb)\n",
    "    pymol.set('cartoon_color', 'neptunium', blue)\n",
    "    pymol.set('cartoon_color', 'red', red)\n",
    "    pymol.set('cartoon_color', 'chlorine', white)\n",
    "    pymol.bg_color('white')\n",
    "    pymol.remove('solvent')\n",
    "\n",
    "    # light parameters\n",
    "    _light_parameters()\n",
    "    \n",
    "    # deselect everything\n",
    "    pymol.deselect()\n",
    "\n",
    "    if quit:\n",
    "        pymol.quit()\n",
    "    return\n",
    "\n",
    "# Convert fitness scores into pymol residues\n",
    "\n",
    "\n",
    "def _pymol_fitness(df, gof, lof, mode, position_correction):\n",
    "    '''You input the dataframe. Removes stop codons. \n",
    "    Returns the positions that are going to be colored blue,red and white'''\n",
    "    \n",
    "    # Select grouping\n",
    "    if mode == 'mean':\n",
    "        df_grouped = df.groupby(['Position'], as_index=False).mean()\n",
    "    else:\n",
    "        df_grouped = df.loc[df['Aminoacid']==mode]\n",
    "        \n",
    "    # Color of mutations\n",
    "    blue_mutations = df_grouped[df_grouped['Score'] < lof]\n",
    "    red_mutations = df_grouped[df_grouped['Score'] > gof]\n",
    "    white_mutations = df_grouped[df_grouped['Score'].between(\n",
    "        lof, gof, inclusive=True)]\n",
    "\n",
    "    # Pymol Format\n",
    "    blue_pymol = _array_to_pymol(blue_mutations['Position']+position_correction)\n",
    "    red_pymol = _array_to_pymol(red_mutations['Position']+position_correction)\n",
    "    white_pymol = _array_to_pymol(white_mutations['Position']+position_correction)\n",
    "\n",
    "    residues = [blue_pymol, red_pymol, white_pymol]\n",
    "    \n",
    "    # If one group does not have any position, color position 0. Otherwise it gives an error\n",
    "    for i, residue in enumerate(residues):\n",
    "        if residue == '':\n",
    "            residues[i] = '0'\n",
    "\n",
    "    return residues\n",
    "\n",
    "\n",
    "def _array_to_pymol(array):\n",
    "    '''Input an array with positions of aminoacids, return it in pymol format'''\n",
    "    pymol = ''\n",
    "    for aminoacid in array:\n",
    "        pymol += str(aminoacid)+'+'\n",
    "\n",
    "    # delete last '+'\n",
    "    pymol = pymol[:-1]\n",
    "    return pymol\n",
    "\n",
    "\n",
    "def _light_parameters():\n",
    "    '''Group the light and ray parameters for pymol figures'''\n",
    "    # Light parameters\n",
    "    pymol.set('antialias', '3')\n",
    "    pymol.set('ambient', '0.15')\n",
    "    pymol.set('spec_count', '5')\n",
    "    pymol.set('shininess', '50')\n",
    "    pymol.set('specular', '0')\n",
    "    pymol.set('light_count', '4')\n",
    "    pymol.set('direct', '0.45')\n",
    "    pymol.set('reflect', '0.5')\n",
    "    pymol.set('opaque_background', 'off')\n",
    "    pymol.set('dash_gap', 0.5)\n",
    "    pymol.set('dash_radius', 0.1)\n",
    "\n",
    "    # Stick parameters\n",
    "    pymol.set('stick_radius', '0.2')\n",
    "    pymol.set('sphere_scale', '0.2')\n",
    "    pymol.set('sphere_quality', '4')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internal Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:01.019283Z",
     "start_time": "2020-09-13T01:45:00.997864Z"
    }
   },
   "outputs": [],
   "source": [
    "def _transform_dataset(dataset, sequence, aminoacids, start_position, fillna):\n",
    "    '''\n",
    "    Internal function that constructs a dataframe from user inputs\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    dataset, sequence, aminoacids, start_position,fillna\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    Dataframe containing [Position, Sequence, Aminoacid, Variant, Score]\n",
    "    '''\n",
    "\n",
    "    # make a dataframe\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Define Columns\n",
    "    df['Sequence'] = np.ravel([[aa]*len(aminoacids) for aa in sequence])\n",
    "\n",
    "    # Create column with position label\n",
    "    df['Position'] = np.ravel(\n",
    "        [[i]*len(aminoacids) for i in range(start_position, len(dataset[0])+start_position)])\n",
    "    df['Aminoacid'] = aminoacids * len(dataset[0])\n",
    "    df['Variant'] = df['Sequence']+df['Position'].astype(str)+df['Aminoacid']\n",
    "    df['Score'] = np.ravel(dataset.T)\n",
    "    df['Score_NaN'] = np.ravel(dataset.T)\n",
    "\n",
    "    # Eliminate NaNs\n",
    "    df['Score'].fillna(fillna, inplace=True)\n",
    "\n",
    "    # Eliminate stop codons\n",
    "    df_clean = df[df['Aminoacid'] != '*'].copy()\n",
    "\n",
    "    return df, df_clean\n",
    "\n",
    "\n",
    "def _transform_sequence(dataset, sequence, start_position):\n",
    "    '''\n",
    "    Internal function that trims the input sequence\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    dataset, sequence, start_position\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    string containing trimmed sequence\n",
    "    '''\n",
    "\n",
    "    # truncate sequence\n",
    "    trimmedsequence = sequence[start_position -\n",
    "                               1:len(dataset[0])+start_position-1]\n",
    "\n",
    "    return trimmedsequence\n",
    "\n",
    "\n",
    "def _transform_secondary(dataset, secondary, start_position, aminoacids):\n",
    "    '''\n",
    "    Internal function that trims the input secondary structure\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    dataset, sequence, start_position\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    list containing trimmed secondary structure (20 times each element)\n",
    "    '''\n",
    "\n",
    "    # Convert lists of lists to list\n",
    "    secondary_list = list(itertools.chain.from_iterable(secondary))\n",
    "\n",
    "    # Truncate list\n",
    "    trimmedsecondary = secondary_list[start_position -\n",
    "                                      1:len(dataset[0])+start_position-1]\n",
    "\n",
    "    # Multiply each element by number of aminoacids. not use stop codon\n",
    "    aminoacids = list(np.copy(aminoacids))\n",
    "    if '*' in aminoacids:\n",
    "        aminoacids.remove('*')\n",
    "    secondary_dup = [x for item in trimmedsecondary for x in itertools.repeat(\n",
    "        item, len(aminoacids))]\n",
    "\n",
    "    return trimmedsecondary, secondary_dup\n",
    "\n",
    "\n",
    "def _convert_to_df(dataset, sequence, aminoacids, startposition):\n",
    "    '''\n",
    "    Convertds np.array with stored enrichment scores into a dataframe\n",
    "    Makes a copy of data\n",
    "\n",
    "    Returns dataframe\n",
    "\n",
    "    '''\n",
    "    df = pd.DataFrame()\n",
    "    df['Aminoacid'] = list(aminoacids) * len(dataset[0])\n",
    "    df['Position'] = np.ravel(\n",
    "        [[i]*len(aminoacids) for i in range(startposition, len(dataset[0])+startposition)])\n",
    "    df['Sequence'] = np.ravel([[i]*len(aminoacids)\n",
    "                               for i in sequence[:len(dataset[0])]])\n",
    "    df['Score'] = np.copy(dataset.T).ravel()\n",
    "    return df\n",
    "\n",
    "\n",
    "def _df_rearrange(df, new_order, values='Score',show_snv = False):\n",
    "    '''\n",
    "    convert a df into a numpy array for mutagenesis data. \n",
    "    Allows the option of keeping NaN scores\n",
    "\n",
    "    Returns copy\n",
    "    '''\n",
    "    dfcopy = df.copy()\n",
    "    \n",
    "    # If only SNVs, turn rest to NaN\n",
    "    if show_snv is True:\n",
    "        dfcopy.loc[dfcopy['SNV?']==False, values] = np.nan\n",
    "    \n",
    "    df_pivoted = dfcopy.pivot_table(values=values, index='Aminoacid',\n",
    "                                    columns=['Position'], dropna=False)\n",
    "    df_reindexed = df_pivoted.reindex(index=list(new_order))\n",
    "\n",
    "    return df_reindexed\n",
    "\n",
    "\n",
    "def _common(a, b):\n",
    "    '''\n",
    "    return common elements of two lists\n",
    "    '''\n",
    "    c = [value for value in a if value in b]\n",
    "    return c\n",
    "\n",
    "\n",
    "def _transpose(df, values='Score'):\n",
    "    '''\n",
    "    convert a df into a numpy array for mutagenesis data\n",
    "\n",
    "    Returns copy\n",
    "    '''\n",
    "    df = df.pivot_table(values=values, index='Aminoacid',\n",
    "                        columns=['Position']).T\n",
    "    return df\n",
    "\n",
    "\n",
    "def _select_aa(df, selection, values='Score'):\n",
    "    '''returns copy'''\n",
    "    df = _transpose(df.copy(), values)\n",
    "\n",
    "    df = df[selection].T\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def _savefile(fig, temp_kwargs):\n",
    "    '''Save file function'''\n",
    "    if temp_kwargs['savefile'] is True:\n",
    "        filename = temp_kwargs['outputfilepath'] + \\\n",
    "            temp_kwargs['outputfilename']+\".\"+temp_kwargs['outputformat']\n",
    "        fig.savefig(filename, format=temp_kwargs['outputformat'],\n",
    "                    bbox_inches='tight', dpi=temp_kwargs['dpi'], transparent=True)\n",
    "    return\n",
    "\n",
    "def parse_pivot(df_imported, col_variant = 'variant', col_data = 'DMS',\n",
    "               fill_value = np.nan):\n",
    "    '''\n",
    "    Parses a dataframe that contains saturation mutagenesis data in the Variant/Scores format.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    df_imported : pandas dataframe\n",
    "        Dataframe with the data imported with pd.read_excel.\n",
    "    \n",
    "    col_variant : str, default 'variant'\n",
    "        Name of the column that contains the variants (ie T31A).\n",
    "        \n",
    "    col_data : str, default 'DMS'\n",
    "        Name of the column that contains the saturation mutagenesis scores.\n",
    "    \n",
    "    fill_value : float, default np.nan\n",
    "        What number to replace values that are omitted. It is possible that your \n",
    "        dataset does not have a wt value.\n",
    "        \n",
    "    Returns\n",
    "    --------\n",
    "    df_pivoted : pandas dataframe\n",
    "        Dataframe that has been pivoted. Values are the saturation mutagenesis data. Columns are \n",
    "        the amino acid substitutions. Rows are the positions of the protein.\n",
    "    \n",
    "    sequence : list\n",
    "        List of the amino acids that form the protein sequence.\n",
    "    '''\n",
    "    \n",
    "    # Copy\n",
    "    df = df_imported.copy()\n",
    "    \n",
    "    # Extract position and amino acids that are being mutated\n",
    "    df['Position'] = df[col_variant].str.extract('(\\d+)').astype(int)\n",
    "    df['Original'] = df[col_variant].str[0:1]\n",
    "    df['Substitution'] = df[col_variant].str[-1:]\n",
    "    \n",
    "    # Get sequence\n",
    "    sequence = list(df.groupby(by=['Position', 'Original'], as_index=False, group_keys=False).sum() ['Original'])\n",
    "\n",
    "    # Pivot\n",
    "    df_pivoted = df.pivot_table(index='Substitution',columns = 'Position', \n",
    "                                values=col_data, fill_value = fill_value, dropna=False)\n",
    "    \n",
    "    return df_pivoted, sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T02:03:19.790068Z",
     "start_time": "2020-09-13T02:03:19.782375Z"
    }
   },
   "outputs": [],
   "source": [
    "def kwargs():\n",
    "    '''\n",
    "    Kwargs used in the package. Not all of them work on each function.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    colormap : cmap, default custom bluewhitered\n",
    "        Used for heatmaps. You can use your own colormap or the ones provided by \n",
    "        matplotlib. Example colormap = copy.copy((plt.cm.get_cmap('Blues_r')))\n",
    "\n",
    "    colorbar_scale: list, default [-1, 1]\n",
    "        Scale min and max used in heatmaps and correlation heatmaps.\n",
    "    \n",
    "    color: str, default 'k'\n",
    "        Color used for the ...\n",
    "        \n",
    "    title : str, default 'Title'\n",
    "        Title of plot.\n",
    "        \n",
    "    x_label : str, default 'x_label'\n",
    "        Label of x axis.\n",
    "        \n",
    "    y_label : str, default 'y_label'\n",
    "        Label of y axis.\n",
    "    \n",
    "    xscale: tuple, default (None, None)\n",
    "        MinMax of x axis.\n",
    "        \n",
    "    yscale: tuple, default (None, None)\n",
    "        MinMax of y axis.\n",
    "\n",
    "    tick_spacing: int, default 1\n",
    "        Space of axis ticks. Used for scatter and cumulative plots.\n",
    "        \n",
    "    inputfilepath : str, default ''\n",
    "        Path of the input file.\n",
    "        \n",
    "    inputfilename : str, default ''\n",
    "        Name of the input file.\n",
    "        \n",
    "    outputfilepath : str, default ''\n",
    "        Path where file will be exported to.\n",
    "        \n",
    "    outputfilename : str, default ''\n",
    "        Name of the exported file.\n",
    "        \n",
    "    outputformat': str, default 'png'\n",
    "        Fortmat to export matplotlib object.\n",
    "        \n",
    "    dpi : int, default 600\n",
    "        Dots Per Inch in the created image.\n",
    "        \n",
    "    neworder_aminoacids: list, default list('DEKHRGNQASTPCVYMILFW*')\n",
    "        Order of amino acids to display in heatmaps. Used for heatmaps.\n",
    "    \n",
    "    savefile: boolean, default False\n",
    "        If true, will save the matplotlib object into the specified folder.\n",
    "        \n",
    "    gof: int, default 1\n",
    "        Cutoff of the enrichment score to classify a mutation as gain of function.\n",
    "        Used on pymol function.\n",
    "        \n",
    "    lof: int, default -1\n",
    "        Cutoff of the enrichment score to classify a mutation as loss of funtion.\n",
    "        Used on pymol function.\n",
    "    \n",
    "    color_gof : str, default 'red'\n",
    "        Color to color mutations above the gof cutoff.\n",
    "        Used in pymol and mean methods.\n",
    "\n",
    "    color_lof : str, default 'blue'\n",
    "        Color to color mutations below the lof cutoff.\n",
    "        Used in pymol and mean methods.\n",
    "        \n",
    "    cartoon_colors: list, default ['lightgreen', 'lavender', 'k']\n",
    "        Colors used for secondary structure cartoon. Used for heatmap, mean and mean_count plots.\n",
    "        \n",
    "    text_labels: str, default 'None'\n",
    "        Text labels that you can add to mean and mean_count plots. You will need to specify the coordinates.\n",
    "        \n",
    "    show: boolean, default True\n",
    "        Whether to execute plt.show() or not on a matplotlib object.\n",
    "        \n",
    "    random_state : int, default 554\n",
    "        Random state used for PCA function.\n",
    "      \n",
    "    '''\n",
    "    # Do nothing, only so sphinx adds this to the rst file\n",
    "    return\n",
    "\n",
    "default_kwargs = {'colormap': generatecolormap(),\n",
    "                  'colorbar_scale': [-1, 1],\n",
    "                  'color': 'k',\n",
    "                  'title': 'Title',\n",
    "                  'x_label': 'x_label',\n",
    "                  'y_label': 'y_label',\n",
    "                  'z_label': 'y_label',\n",
    "                  'xscale': (None, None),\n",
    "                  'yscale': (None, None),\n",
    "                  'tick_spacing': 1,\n",
    "                  'inputfilepath': '',\n",
    "                  'inputfilename': '',\n",
    "                  'outputfilepath': '',\n",
    "                  'outputfilename': '',\n",
    "                  'outputformat': 'png',\n",
    "                  'dpi': 600,\n",
    "                  'aminoacids': list('ACDEFGHIKLMNPQRSTVWY*'),\n",
    "                  'neworder_aminoacids': list('DEKHRGNQASTPCVYMILFW*'),\n",
    "                  'savefile': False,\n",
    "                  'gof': 1,\n",
    "                  'lof': -1,\n",
    "                  'color_gof' : 'red',\n",
    "                  'color_lof' : 'blue',\n",
    "                  'cartoon_colors': ['lightgreen', 'lavender', 'k'],\n",
    "                  'text_labels': None,\n",
    "                  'show': True,\n",
    "                  'random_state' : 554,\n",
    "                  'bins' : 50,\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:01.040565Z",
     "start_time": "2020-09-13T01:45:01.031364Z"
    }
   },
   "outputs": [],
   "source": [
    "class Screen:\n",
    "    '''\n",
    "    Screen represents a saturation mutagenesis experiment, where every amino acid \n",
    "    in the protein has been mutated to other amino acids. The mutants are scored based\n",
    "    on some custom screen.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    dataset : array\n",
    "        2D matrix containing the enrichment scores of the point mutants. Columns will contain the\n",
    "        amino acid substitutions, rows will contain the enrichment for each residue in the protein sequence.\n",
    "    \n",
    "    sequence : str\n",
    "        Protein sequence (columns) in 1 letter code format.\n",
    "    \n",
    "    aminoacids : list, default list('ACDEFGHIKLMNPQRSTVWY*')\n",
    "        Amino acid substitutions (rows). Submit in the same order that is used for the array.\n",
    "    \n",
    "    start_position : int, default 2\n",
    "        First position in the protein sequence that will be used for the first column of the\n",
    "        array. If a protein has been mutated only from residue 100-150, then if start_position = 100,\n",
    "        the algorithm will trim the first 99 amino acids in the input sequence. The last \n",
    "        residue will be calculated based on the length of the input array. \n",
    "    \n",
    "    secondary : list, optional\n",
    "        This parameter is used to group the data by secondary structure. The format is \n",
    "        the name of the secondary structure multiplied by the residue length of that motif\n",
    "        example : [['β1']*(8),['L1']*(7),['α1']*(9),...,].\n",
    "    \n",
    "    roc_df: Pandas dataframe, optional\n",
    "        A dataframe that contains a column of variants labeled 'Variant' with a column labeled 'Class'\n",
    "        containing the true class of that mutation. This can be used to compare enrichment scores to some label (such as \n",
    "        pathogenicity as found in a Cancer database) using ROC AUC.\n",
    "    \n",
    "    fillna : int, default 0\n",
    "        How to replace NaN values.\n",
    "    \n",
    "    \n",
    "    Attributes\n",
    "    ------------\n",
    "    dataframe : pandas dataframe\n",
    "        Contains the enrichment scores, position, sequence.\n",
    "    \n",
    "    Other attributes are same as input parameters: dataset, aminoacids, start_position, roc_df, secondary\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, dataset, sequence, aminoacids=list('ACDEFGHIKLMNPQRSTVWY*'),\n",
    "                 start_position=2, fillna=0, secondary=None, roc_df=None):\n",
    "        self.dataset = np.array(dataset)\n",
    "        self.aminoacids = aminoacids\n",
    "        self.start_position = start_position\n",
    "        self.end_position = len(self.dataset[0])+start_position\n",
    "        self.sequence_raw = ''.join(sequence)\n",
    "        self.sequence = _transform_sequence(\n",
    "            self.dataset, self.sequence_raw, self.start_position)\n",
    "        self.dataframe_stopcodons, self.dataframe = _transform_dataset(\n",
    "            self.dataset, self.sequence, self.aminoacids, self.start_position, fillna)\n",
    "        self.dataframe_SNV = _select_SNV(self.dataframe)\n",
    "        self.dataframe_nonSNV = _select_nonSNV(self.dataframe)\n",
    "\n",
    "        # Optional parameters\n",
    "        self.roc_df = roc_df\n",
    "        self.secondary = secondary\n",
    "        if self.secondary is not None:\n",
    "            self.secondary, self.secondary_dup = _transform_secondary(\n",
    "                self.dataset, self.secondary, self.start_position, self.aminoacids)\n",
    "\n",
    "    # Methods (Associated functions)\n",
    "    kernel = plot_kernel\n",
    "    heatmap = plot_heatmap\n",
    "    heatmap_rows = plot_heatmap_rows\n",
    "    heatmap_columns = plot_heatmap_columns\n",
    "    mean = plot_mean\n",
    "    meancounts = plot_meancounts\n",
    "    differential = plot_meandifferential\n",
    "    position = plot_position\n",
    "    scatter = plot_scatter\n",
    "    rank = plot_rank\n",
    "    histogram = plot_hist\n",
    "    miniheatmap = plot_miniheatmap\n",
    "    neighboreffect = plot_neighboreffect\n",
    "    correlation = plot_correlation\n",
    "    individual_correlation = plot_individual_correlation\n",
    "    group_correlation = plot_group_correlation\n",
    "    pca = plot_pca\n",
    "    secondary_mean = plot_secondary\n",
    "    roc = plot_roc\n",
    "    cumulative = plot_cumulative\n",
    "    scatter_3D = plot_scatter_3D\n",
    "    scatter_3D_pdbprop = plot_scatter_3D_pdbprop\n",
    "    pymol = plot_pymol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(figure='heatmap'):\n",
    "    \"\"\"\n",
    "    Performs a demonstration of the mutagenesis_visualization software.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    figure : str, default 'heatmap'\n",
    "        There are 5 example plots that can be displayed to test the package is working on your station.\n",
    "        The 5 options are 'heatmap', 'miniheatmap', 'mean', 'kernel' and 'pca'. Check the documentation for more information.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \"\"\"\n",
    "    # Use relative file import to access the data folder\n",
    "    location = os.path.dirname(os.path.realpath(__file__))\n",
    "    my_file = os.path.join(location, 'data', 'HRas166_RBD.csv')\n",
    "\n",
    "    # Load enrichment scores\n",
    "    hras_enrichment_RBD = np.genfromtxt(my_file, delimiter=',')\n",
    "\n",
    "    # Define protein sequence\n",
    "    hras_sequence = 'MTEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVIDGETCLLDILDTAGQEEYSAMRDQYMRTGEGFLCVFAINNTKSFEDIHQYREQIKRVKDSDDVPMVLVGNKCDLAARTVESRQAQDLARSYGIPYIETSAKTRQGVEDAFYTLVREIRQHKLRKLNPPDESGPG'\n",
    "\n",
    "    # Define secondary structure\n",
    "    secondary = [['L0'], ['β1']*(9-1), ['L1']*(15-9), ['α1']*(25-15), ['L2']*(36-25), ['β2']*(46-36), ['L3']*(48-46), \n",
    "                 ['β3']*(58-48), ['L4'] * (64-58),['α2']*(74-64), ['L5']*(76-74), ['β4']*(83-76), \n",
    "                 ['L6']*(86-83), ['α3']*(103-86), ['L7']*(110-103), ['β5']*(116-110), ['L8']*(126-116), ['α4']*(137-126),\n",
    "                 ['L9']*(140-137), ['β6']*(143-140), ['L10']*(151-143), ['α5']*(172-151), ['L11']*(190-172)]\n",
    "\n",
    "    # Create object\n",
    "    hras_RBD = Screen(dataset=hras_enrichment_RBD,\n",
    "                      sequence=hras_sequence, secondary=secondary)\n",
    "\n",
    "    if figure == 'heatmap':\n",
    "        # Create heatmap plot\n",
    "        hras_RBD.heatmap(title='H-Ras 2-166', show_cartoon=True)\n",
    "    elif figure == 'miniheatmap':\n",
    "        # Condensed heatmap\n",
    "        hras_RBD.miniheatmap(title='Wt residue H-Ras')\n",
    "    elif figure == 'mean':\n",
    "        # Mean enrichment by position\n",
    "        hras_RBD.mean(figsize=[6, 2.5], mode='mean',show_cartoon=True, yscale=[-2, 0.5], title = '')\n",
    "    elif figure == 'kernel':\n",
    "        # Plot kernel dist using sns.distplot.\n",
    "        hras_RBD.kernel(histogram=True, title='H-Ras 2-166', xscale=[-2, 1])\n",
    "    elif figure == 'pca':\n",
    "        # PCA by amino acid substitution\n",
    "        hras_RBD.pca(dimensions=[0, 1], figsize=(2, 2), adjustlabels=True, title = '')\n",
    "    return\n",
    "    \n",
    "def demo_datasets():\n",
    "    '''\n",
    "    Loads example datasets so the user can play with it.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    None\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    data_dict : dictionary\n",
    "        Dictionary that contains the datasets used to create the plots on the documentation.\n",
    "    '''\n",
    "    \n",
    "    # Use relative file import to access the data folder\n",
    "    location = os.path.dirname(os.path.realpath(__file__))\n",
    "    \n",
    "    # Create dictionary where to store data\n",
    "    data_dict = {}\n",
    "    \n",
    "    # Retrieve H-Ras dataset and store in dict\n",
    "    my_file = os.path.join(location, 'data', 'HRas166_RBD.csv')\n",
    "    hras_enrichment_RBD = np.genfromtxt(my_file, delimiter=',')\n",
    "    data_dict['array_hras'] = hras_enrichment_RBD\n",
    "    \n",
    "    # Beta lactamase data\n",
    "    my_file = os.path.join(location, 'data', 'df_bla_raw.pkl')\n",
    "    df_bla_raw = pd.read_pickle(my_file)\n",
    "    data_dict['df_bla'], sequence_bla = parse_pivot(df_bla_raw, col_data = 'DMS_amp_625_(b)')\n",
    "\n",
    "    # Sumo\n",
    "    my_file = os.path.join(location, 'data', 'df_sumo1_raw.pkl')\n",
    "    df_sumo1_raw = pd.read_pickle(my_file)\n",
    "    data_dict['df_sumo1'], sequence_sumo1 = parse_pivot(df_sumo1_raw, col_data = 'DMS')\n",
    "   \n",
    "    # MAPK1\n",
    "    my_file = os.path.join(location, 'data', 'df_mapk1_raw.pkl')\n",
    "    df_mapk1_raw = pd.read_pickle(my_file)\n",
    "    data_dict['df_mapk1'], sequence_mapk1 = parse_pivot(df_mapk1_raw, col_data = 'DMS_DOX')\n",
    "    \n",
    "    #UBE2I\n",
    "    my_file = os.path.join(location, 'data', 'df_ube2i_raw.pkl')\n",
    "    df_ube2i_raw = pd.read_pickle(my_file)\n",
    "    data_dict['df_ube2i'], sequence_ube2i = parse_pivot(df_ube2i_raw, col_data = 'DMS')\n",
    "\n",
    "    #TAT\n",
    "    my_file = os.path.join(location, 'data', 'df_tat.pkl')\n",
    "    data_dict['df_tat'] = pd.read_pickle(my_file)\n",
    "\n",
    "    #REV\n",
    "    my_file = os.path.join(location, 'data', 'df_rev.pkl')\n",
    "    data_dict['df_rev'] = pd.read_pickle(my_file)\n",
    "    \n",
    "    # asynuclein\n",
    "    my_file = os.path.join(location, 'data', 'df_asynuclein.pkl')\n",
    "    data_dict['df_asynuclein'] = pd.read_pickle(my_file)\n",
    "    \n",
    "    # APH\n",
    "    my_file = os.path.join(location, 'data', 'df_aph.pkl')\n",
    "    data_dict['df_aph'] = pd.read_pickle(my_file)\n",
    "\n",
    "    # b11L5\n",
    "    my_file = os.path.join(location, 'data', 'df_b11L5F_raw.pkl')\n",
    "    df_b11L5F_raw = pd.read_pickle(my_file)\n",
    "    data_dict['df_b11L5F'], sequence_b11L5F = parse_pivot(df_b11L5F_raw, col_data = 'relative_tryp_stability_score')\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ras Trouble Shooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:14.674478Z",
     "start_time": "2020-09-13T01:45:14.361051Z"
    }
   },
   "outputs": [],
   "source": [
    "'''# Load enrichment scores into a np.array\n",
    "hras_enrichment = np.genfromtxt('../data/HRas166_RBD.csv', delimiter=',')\n",
    "\n",
    "# Define protein sequence\n",
    "hras_sequence = 'MTEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVIDGETCLLDILDTAGQEEYSAMRDQYMRTGEGFLCVFAINNTKSFEDIHQYREQIKRVKDSDDVPMVLVGNKCDLAARTVESRQAQDLARSYGIPYIETSAKTRQGVEDAFYTLVREIRQHKLRKLNPPDESGPG'\n",
    "\n",
    "# Order of amino acid substitutions in the hras_enrichment dataset\n",
    "aminoacids = list('ACDEFGHIKLMNPQRSTVWY*')\n",
    "\n",
    "# First residue of the hras_enrichment dataset. Because 1-Met was not mutated, the dataset starts at residue 2\n",
    "start_position = 2\n",
    "\n",
    "# Define secondary structure\n",
    "secondary = [['L0'], ['β1']*(9-1), ['L1']*(15-9), ['α1']*(25-15), ['L2']*(36-25), ['β2']*(46-36),['L3']*(48-46), ['β3']*(58-48), ['L4'] *(64-58), ['α2']*(74-64), ['L5']*(76-74), ['β4']*(83-76), ['L6']*(86-83), ['α3']*(103-86), ['L7']*(110-103), ['β5']*(116-110), ['L8']*(126-116), ['α4']*(137-126), ['L9']*(140-137), ['β6']*(143-140), ['L10']*(151-143), ['α5']*(172-151), ['L11']*(190-172)]\n",
    "\n",
    "# Create object\n",
    "hras_object = Screen(hras_enrichment,hras_sequence,aminoacids,start_position,0,secondary)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:01.091040Z",
     "start_time": "2020-09-13T01:45:01.086476Z"
    }
   },
   "outputs": [],
   "source": [
    "'''path = '../Data/DMS_others.xlsx'\n",
    "sheet_name='env'\n",
    "usecols='A:B'\n",
    "\n",
    "# Read excel file\n",
    "df = pd.read_excel(path, sheet_name, usecols=usecols)\n",
    "\n",
    "# Parse\n",
    "df_env, sequence_env = parse_pivot(df)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-13T01:45:01.101128Z",
     "start_time": "2020-09-13T01:45:01.095091Z"
    }
   },
   "outputs": [],
   "source": [
    "'''# Order of amino acid substitutions in the hras_enrichment dataset\n",
    "aminoacids = list(df_env.index)\n",
    "neworder_aminoacids = list('DEKHRGNQASTPCVYMILFW')\n",
    "\n",
    "# First residue of the hras_enrichment dataset. Because 1-Met was not mutated, the dataset starts at residue 2\n",
    "start_position = df_env.columns[0]\n",
    "\n",
    "sequence = ['X']*start_position+sequence_env\n",
    "# Create objects\n",
    "env_obj = Screen(df_env, sequence,\n",
    "                         aminoacids, start_position)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "100px",
    "left": "21px",
    "top": "69.2px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.4,
   "position": {
    "height": "423.4px",
    "left": "944.6px",
    "right": "20px",
    "top": "119px",
    "width": "315.4px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
