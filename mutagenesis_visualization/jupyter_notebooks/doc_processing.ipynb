{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing DNA reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will teach you how to use the built-in data processing functions. If you already have your own processing pipeline built, you can skip this section and go to the plotting examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T23:16:50.246919Z",
     "start_time": "2020-10-12T23:16:49.957532Z"
    },
    "execution": {
     "iopub.execute_input": "2020-10-27T05:11:03.183904Z",
     "iopub.status.busy": "2020-10-27T05:11:03.183592Z",
     "iopub.status.idle": "2020-10-27T05:11:04.707245Z",
     "shell.execute_reply": "2020-10-27T05:11:04.706074Z",
     "shell.execute_reply.started": "2020-10-27T05:11:03.183870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from code_process_data.ipynb\n",
      "importing Jupyter notebook from code_demo.ipynb\n",
      "importing Jupyter notebook from code_class.ipynb\n",
      "importing Jupyter notebook from code_3D.ipynb\n",
      "importing Jupyter notebook from code_kwargs.ipynb\n",
      "importing Jupyter notebook from code_utils.ipynb\n",
      "importing Jupyter notebook from code_bar.ipynb\n",
      "importing Jupyter notebook from code_heatmaps.ipynb\n",
      "importing Jupyter notebook from code_kernel.ipynb\n",
      "importing Jupyter notebook from code_scatter.ipynb\n",
      "importing Jupyter notebook from code_PCA.ipynb\n",
      "importing Jupyter notebook from code_other.ipynb\n",
      "importing Jupyter notebook from code_plotly.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Run only if you are using the code from jupyter notebooks instead of pypi\n",
    "import import_notebook\n",
    "import code_process_data as process\n",
    "import code_demo as demo\n",
    "import code_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-12T23:16:52.063712Z",
     "start_time": "2020-10-12T23:16:50.753820Z"
    }
   },
   "outputs": [],
   "source": [
    "import mutagenesis_visualization as mut\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count DNA reads from fastq file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T05:16:16.097807Z",
     "iopub.status.busy": "2020-10-27T05:16:16.097583Z",
     "iopub.status.idle": "2020-10-27T05:16:16.101489Z",
     "shell.execute_reply": "2020-10-27T05:16:16.100610Z",
     "shell.execute_reply.started": "2020-10-27T05:16:16.097786Z"
    }
   },
   "source": [
    "### Site saturation mutagenesis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Methods and functions reviewed in this section:\n",
    "    - :meth:`mutagenesis_visualization.Screen.meancounts`\n",
    "    - :func:`mutagenesis_visualization.count_reads`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After sequencing your DNA library, using other packages you will assemble the forward and reverse reads and trim the flanking bases. That will produce a trimmed fastq file that contains the DNA reads. This is where ``mutagenesis_visualization`` kicks in. The following function ``count_reads`` will read your trimmed fastq file and count the number of times a DNA sequence is present. You will have to pass as inputs a ``dna_sequence`` and a ``codon_list`` with the codons that were used to make the point mutant library. If ``savefile=True`` , it will export the results to txt files. Below there is a prettified example of the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T17:58:49.554291Z",
     "start_time": "2020-10-01T17:58:49.522994Z"
    },
    "execution": {
     "iopub.execute_input": "2020-10-27T05:11:07.149573Z",
     "iopub.status.busy": "2020-10-27T05:11:07.149364Z",
     "iopub.status.idle": "2020-10-27T05:11:11.406630Z",
     "shell.execute_reply": "2020-10-27T05:11:11.405826Z",
     "shell.execute_reply.started": "2020-10-27T05:11:07.149551Z"
    }
   },
   "outputs": [],
   "source": [
    "# H-Ras dna sequence\n",
    "hras_dnasequence = 'acggaatataagctggtggtggtgggcgccggcggtgtgggcaagagtgcgctgaccat'\\\n",
    "    + 'ccagctgatccagaaccattttgtggacgaatacgaccccactatagaggattcctaccggaagcaggtgg'\\\n",
    "    + 'tcattgatggggagacgtgcctgttggacatcctg'\n",
    "\n",
    "# Codons used to make the NNS library. I could also have used 'NNS' and the package will use the NNS codons\n",
    "codon_list = [\"GCC\", \"GCG\", \"TGC\", \"GAC\", \"GAG\", \"TTC\", \"GGC\", \"GGG\", \"CAC\", \"ATC\", \"AAG\",\n",
    "              \"CTC\", \"CTG\", \"TTG\", \"ATG\", \"AAC\", \"CCC\", \"CCG\", \"CAG\", \"CGC\", \"CGG\", \"AGG\",\n",
    "              \"TCC\", \"TCG\", \"AGC\", \"ACC\", \"ACG\", \"GTC\", \"GTG\", \"TGG\", \"TAC\", \"TAG\"]\n",
    "\n",
    "# Input and output files\n",
    "input_file = '../data/hras.trimmed.fastq'\n",
    "output_file = 'hras_counts.xlsx'\n",
    "counts_wt = False\n",
    "start_position = 2\n",
    "\n",
    "# Execute count reads\n",
    "df_counts_pre, wt_counts_pre = process.count_reads(hras_dnasequence, input_file,\n",
    "                                                   codon_list, counts_wt, start_position, \n",
    "                                                   output_file)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T20:09:38.460580Z",
     "start_time": "2020-09-03T20:09:38.455250Z"
    }
   },
   "source": [
    ".. image:: ../example/exported_images/hras_tablecounts.png\n",
    "   :width: 450px\n",
    "   :align: center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create object of class ``Counts``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T05:11:15.667896Z",
     "iopub.status.busy": "2020-10-27T05:11:15.667461Z",
     "iopub.status.idle": "2020-10-27T05:11:15.674070Z",
     "shell.execute_reply": "2020-10-27T05:11:15.672433Z",
     "shell.execute_reply.started": "2020-10-27T05:11:15.667859Z"
    }
   },
   "outputs": [],
   "source": [
    "hras_obj = code_class.Counts(df_counts_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the reads have been counted, the method ``mean_counts`` can be used to evaluate the coverage by position. The method ``library_representation`` will tell you the percentage coverage of each amino acid per position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hras_obj.mean_counts(title = 'H-Ras mean counts per position')\n",
    "\n",
    "hras_obj.library_representation(title = 'H-Ras amino acid coverage')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. image:: ../example/exported_images/hras_countspre.png\n",
    "   :width: 500px\n",
    "   :align: center\n",
    "        \n",
    ".. image:: ../example/exported_images/hras_countspre_aacoverage.png\n",
    "   :width: 500px\n",
    "   :align: center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom DNA list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a custom input DNA list. That way it does not matter if you are using NNS or you have second order mutations. Create a list of variants on your own, and the software will count the frequency of each of those variants on the fastq file you provide as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your list of variants\n",
    "list_variants = ['acggaatataagctggtggtggtgggcgccggcggtgtgggcaagagtgcgctgaccat'\n",
    "                 + 'ccagctgatccagaaccattttgtggacgaatacgaccccactatagaggattcctaccggaagcaggtgg'\n",
    "                 + 'tcattgatggggagacgtgcctgttggacatcctg', 'aaaaaatataagctggtggtggtgggcgccggcggtgtgggcaagagtgcgctgaccat'\n",
    "                 + 'ccagctgatccagaaccattttgtggacgaatacgaccccactatagaggattcctaccggaagcaggtgg'\n",
    "                 + 'tcattgatggggagacgtgcctgttggacatcctg', 'tttttttataagctggtggtggtgggcgccggcggtgtgggcaagagtgcgctgaccat'\n",
    "                 + 'ccagctgatccagaaccattttgtggacgaatacgaccccactatagaggattcctaccggaagcaggtgg'\n",
    "                 + 'tcattgatggggagacgtgcctgttggacatcctg']\n",
    "\n",
    "# Convert list of variants to ordered dictionary with values set to 0\n",
    "variants = process._initialize_ordereddict(list_variants)\n",
    "\n",
    "# Count DNA variants in the fastq file\n",
    "input_file = '../data/hras.trimmed.fastq'\n",
    "\n",
    "variants, totalreads, usefulreads = process.count_fastq(variants, input_file)\n",
    "\n",
    "# Evaluate how many variants in the fastq file were useful\n",
    "print('{}/{} useful reads ({}%)'.format(str(usefulreads),\n",
    "                                        str(totalreads), str(int(usefulreads/totalreads*100))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate enrichment scores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Methods and functions reviewed in this section:\n",
    "    - :class:`mutagenesis_visualization.Screen`\n",
    "    - :meth:`mutagenesis_visualization.Screen.heatmap`\n",
    "    - :func:`mutagenesis_visualization.calculate_enrichment`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are performing a selection experiment, where you sequence your library before and after selection, you will need to calculate the enrichment score of each mutant. The function to do so is ``calculate_enrichment``. This function allows for different parameters to tune how the data is processed and normalized."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this example, we show two different ways of using ``calculate_enrichment``. Note that the parameters of choice will have a say on the final result. In the example, the tonality of red of the two heatmaps is slightly different. A more detailed explanation of the parameters can be found in :ref:`Normalizing datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T17:53:45.991044Z",
     "start_time": "2020-10-01T17:53:45.751331Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read counts from file (could be txt, csv, xlsx, etc...)\n",
    "df_counts_pre = pd.read_excel('../data/hrasGAPGEF_counts.xlsx',\n",
    "                              'R1_before', skiprows=1, index_col='Codons',\n",
    "                              usecols='E:FN', nrows=32)\n",
    "\n",
    "df_counts_sel = pd.read_excel('../data/hrasGAPGEF_counts.xlsx',\n",
    "                              'R1_after', skiprows=1, index_col='Codons',\n",
    "                              usecols='E:FN', nrows=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T18:01:51.229736Z",
     "start_time": "2020-10-01T18:01:51.222245Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ras parameters to create an object\n",
    "\n",
    "# Define protein sequence\n",
    "hras_sequence = 'MTEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVIDGETCLLDILDTAGQEEY'\\\n",
    "                + 'SAMRDQYMRTGEGFLCVFAINNTKSFEDIHQYREQIKRVKDSDDVPMVLVGNKCDLAARTVES'\\\n",
    "                + 'RQAQDLARSYGIPYIETSAKTRQGVEDAFYTLVREIRQHKLRKLNPPDESGPG'\n",
    "\n",
    "# Order of amino acid substitutions in the hras_enrichment dataset\n",
    "aminoacids = list('ACDEFGHIKLMNPQRSTVWY*')\n",
    "\n",
    "# First residue of the hras_enrichment dataset. Because 1-Met was not mutated, the dataset starts at residue 2\n",
    "start_position = 2\n",
    "\n",
    "# Define secondary structure\n",
    "secondary = [['L0'], ['β1']*(9-1), ['L1']*(15-9), ['α1']*(25-15), ['L2']*(36-25),\n",
    "             ['β2']*(46-36), ['L3']*(48-46), ['β3']*(58-48), ['L4'] * (64-58),\n",
    "             ['α2']*(74-64), ['L5']*(76-74), ['β4']*(83-76), ['L6']*(86-83),\n",
    "             ['α3']*(103-86), ['L7']*(110-103), ['β5'] *\n",
    "             (116-110), ['L8']*(126-116),\n",
    "             ['α4']*(137-126), ['L9']*(140-137), ['β6'] *\n",
    "             (143-140), ['L10']*(151-143),\n",
    "             ['α5']*(172-151), ['L11']*(190-172)]\n",
    "\n",
    "# Substitute Nan values with 0\n",
    "fillna = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T18:18:09.541241Z",
     "start_time": "2020-10-01T18:17:51.526918Z"
    }
   },
   "outputs": [],
   "source": [
    "# Order of amino acids (from count_reads)\n",
    "aminoacids_NNS = list('AACDEFGGHIKLLLMNPPQRRRSSSTTVVWY*')\n",
    "\n",
    "# Different parameters can be used to calculate the enrichment scores. They are described in the implementation section\n",
    "\n",
    "# Zeroing using the median of the population, and not using stop codons to correct.\n",
    "frequencies = process.calculate_enrichment(df_counts_pre.iloc[:, :54], df_counts_sel.iloc[:, :54],\n",
    "                                       aminoacids=aminoacids_NNS,\n",
    "                                       zeroing='population', how='median', norm_std=True,\n",
    "                                       stopcodon=True, min_counts=25, min_countswt=100,\n",
    "                                       mpop=2, mwt=2, infinite=3, std_scale=0.3)\n",
    "\n",
    "hras_example1 = mut.Screen(np.array(frequencies), hras_sequence,\n",
    "                           aminoacids, start_position, fillna, secondary)\n",
    "\n",
    "hras_example1.heatmap(title='Normal distribution zeroing', output_file=None)\n",
    "\n",
    "# Zeroing using the median of the population, and not using stop codons to correct.\n",
    "frequencies = process.calculate_enrichment(df_counts_pre.iloc[:, :54], df_counts_sel.iloc[:, :54],\n",
    "                                       aminoacids=aminoacids_NNS,\n",
    "                                       zeroing='kernel', how='median', norm_std=True,\n",
    "                                       stopcodon=True, min_counts=25, min_countswt=100,\n",
    "                                       mpop=2, mwt=2, infinite=3, std_scale=0.15)\n",
    "\n",
    "hras_example2 = mut.Screen(np.array(frequencies), hras_sequence,\n",
    "                           aminoacids, start_position, fillna, secondary)\n",
    "\n",
    "hras_example2.heatmap(title='KDE zeroing', output_file=None)\n",
    "\n",
    "# Note that the two heatmaps look quite similar but the red tonality is slighly different. That is caused by\n",
    "# small differences in zeroing the data."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. image:: ../example/exported_images/hras_tableenrichment.png\n",
    "   :width: 450px\n",
    "   :align: center\n",
    "\n",
    ".. image:: ../example/exported_images/hras_zeronormal.png\n",
    "   :width: 300px\n",
    "   :align: center\n",
    "\n",
    ".. image:: ../example/exported_images/hras_zerokernel.png\n",
    "   :width: 300px\n",
    "   :align: center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble multiple sublibraries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Function reviewed in this section:\n",
    "    - :func:`mutagenesis_visualization.assemble_avengers`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If you split your library into multiple pools, you can use ``assemble_avengers`` to use ``calculate_enrichment`` in an automated loop and return the assembled dataframe. To use this function, you need to import the data in an excel file in the same format as the provided in Example/hrasGAPGEF_counts.xlsx. Note that the parameters for normalization used in ``calculate_enrichment`` also apply here. See :ref:`Normalizing datasets` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T18:03:27.019127Z",
     "start_time": "2020-10-01T18:03:25.783154Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sheet that stores input/preselected counts within the Excel file\n",
    "sheet_pre = 'R1_before'\n",
    "# Sheet that stores output/selected counts within the Excel file\n",
    "sheet_post = 'R1_after'\n",
    "# Columns of each sublibrary. In this example, there are three pools.\n",
    "columns = ['F:BG', 'BH:DK', 'DL:FN']\n",
    "# Columns of the wt pools (optional)\n",
    "columns_wt = ['A', 'B', 'C']\n",
    "# Path were the excel file is stored.\n",
    "excel_path = '../data/hrasGAPGEF_counts.xlsx'\n",
    "# Parameter for pd.read_excel function\n",
    "nrows_pop = 32  # For nrows of the sublibrary\n",
    "nrows_wt = [50, 37, 57]  # For nrows of each of the three wild-type columns\n",
    "skiprows = 1  # Skip one row when reading the columns specified in the list `columns`\n",
    "\n",
    "# Normalization parameters also need to be specified. In here we\n",
    "# are using the default ones.\n",
    "\n",
    "# Call the function and return a df\n",
    "df = process.assemble_avengers(excel_path, sheet_pre, sheet_post, columns,\n",
    "                           nrows_pop, nrows_wt, columns_wt, output_file=None)\n",
    "\n",
    "# The output looks like calculate_enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine MSA with enrichment scores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Function and class reviewed in this section:\n",
    "    - :class:`mutagenesis_visualization.Screen`\n",
    "    - :func:`mutagenesis_visualization.msa_enrichment`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Function ``msa_enrichment`` will calculate the frequency of each substitution in an input MSA. The frequency of each substitution will be merged into the enrichment score dataframe. The function also calculates the Shannon entropy for each position in the protein. This function has been used to generate the data that is plotted in box plot and the ROC AUC charts :ref:`Correlation, PCA and ROC AUC`. We will first need to create the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T18:03:52.325809Z",
     "start_time": "2020-10-01T18:03:52.139240Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load enrichment scores\n",
    "hras_enrichment_RBD = np.genfromtxt('../data/HRas166_RBD.csv', delimiter=',')\n",
    "\n",
    "# Define protein sequence\n",
    "hras_sequence = 'MTEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVIDGETCLLDILDTAGQEEYSAMRDQYMRTGEGFLCVFAINNTKSFEDIHQYREQIKRVKDSDDVPMVLVGNKCDLAARTVESRQAQDLARSYGIPYIETSAKTRQGVEDAFYTLVREIRQHKLRKLNPPDESGPG'\n",
    "\n",
    "# Create object (more detail about this in plotting examples)\n",
    "hras_RBD = mut.Screen(hras_enrichment_RBD, hras_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get the frequency of each substituion in the MSA and the Shannon entropy. You can use the example fasta file by loading ``fasta_dict = demo_fasta()`` and then ``path = fasta_dict['ras']``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T18:04:12.673422Z",
     "start_time": "2020-10-01T18:04:12.557239Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate conservation score from MSA\n",
    "path = '../data/Ras_family_trimmed.fasta'  # local file\n",
    "\n",
    "# Load example file (only if you are trying to reproduce the plots)\n",
    "fasta_dict = demo.demo_fasta()\n",
    "#path = fasta_dict['ras']\n",
    "\n",
    "# Calculate msa scores\n",
    "df_shannon, df_freq = process.msa_enrichment(hras_RBD, path,\n",
    "                                         start_position=1, threshold=0.1)\n",
    "\n",
    "# In the example, for position 2, in 3.63% of the cases there was an Ala.\n",
    "df_freq.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. image:: ../example/exported_images/hras_table_msa.png\n",
    "   :width: 300px\n",
    "   :align: center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The Shannon entropy is calculated using a script created by Joe R. J. Healey from Warwick University. Could not find the script on Github or Pypi so I included it in the package (shannon.py)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "215px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
