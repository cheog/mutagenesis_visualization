{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing DNA reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will teach you how to use the built-in data processing functions. If you already have your own processing pipeline built, you can skip this section and go to the plotting examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T17:38:38.816954Z",
     "start_time": "2020-09-07T17:38:37.556847Z"
    }
   },
   "outputs": [],
   "source": [
    "import Import_notebook\n",
    "import mutagenesis_visualization as mut\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count DNA reads from fastq file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Methods and functions reviewed in this section:\n",
    "    - :meth:`mutagenesis_visualization.Screen.meancounts`\n",
    "    - :func:`mutagenesis_visualization.count_reads`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After sequencing your DNA library, using other packages you will assemble the forward and reverse reads and trim the flanking bases. That will produce a trimmed fastq file that contains the DNA reads. This is where ``mutagenesis_visualization`` kicks in. The following function ``count_reads`` will read your trimmed fastq file and count the number of times a DNA sequence is present. You will have to pass as inputs a ``dna_sequence`` and a ``codon_list`` with the codons that were used to make the point mutant library. If ``savefile=True`` , it will export the results to txt files. Below there is a prettified example of the output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and filenames\n",
    "inputfilepath = 'Trimmed/'\n",
    "inputfilename_pre = 'hras.fastq'\n",
    "outputfilepath = 'codonCounts/'\n",
    "outputfilename_pre = 'hras_counts'\n",
    "\n",
    "# H-Ras dna sequence\n",
    "hras_dnasequence = 'acggaatataagctggtggtggtgggcgccggcggtgtgggcaagagtgcgctgaccat'\\\n",
    "    + 'ccagctgatccagaaccattttgtggacgaatacgaccccactatagaggattcctaccggaagcaggtgg'\\\n",
    "    + 'tcattgatggggagacgtgcctgttggacatcctg'\n",
    "\n",
    "# Codons used to make the NNS library. I could also have used 'NNS' and the package will use the NNS codons\n",
    "codon_list = [\"GCC\", \"GCG\", \"TGC\", \"GAC\", \"GAG\", \"TTC\", \"GGC\", \"GGG\", \"CAC\", \"ATC\", \"AAG\",\n",
    "              \"CTC\", \"CTG\", \"TTG\", \"ATG\", \"AAC\", \"CCC\", \"CCG\", \"CAG\", \"CGC\", \"CGG\", \"AGG\",\n",
    "              \"TCC\", \"TCG\", \"AGC\", \"ACC\", \"ACG\", \"GTC\", \"GTG\", \"TGG\", \"TAC\", \"TAG\"]\n",
    "\n",
    "df_counts_pre, wt_counts_pre = mut.count_reads(hras_dnasequence, codon_list, inputfilepath,\n",
    "                                               inputfilename_pre, outputfilepath,\n",
    "                                               outputfilename_pre, savefile=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T20:09:38.460580Z",
     "start_time": "2020-09-03T20:09:38.455250Z"
    }
   },
   "source": [
    ".. image:: ../example/exported_images/hras_tablecounts.png\n",
    "   :width: 450px\n",
    "   :align: center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-06T22:55:32.815742Z",
     "start_time": "2020-09-06T22:55:32.492795Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read counts from file (could be txt, csv, xlsx, etc...)\n",
    "df_counts_pre = pd.read_excel('mv_repo/example/hrasGAPGEF_counts.xlsx',\n",
    "                              'R1_before', skiprows=1, index_col='Codons',\n",
    "                              usecols='E:FN', nrows=32)\n",
    "\n",
    "df_counts_sel = pd.read_excel('mv_repo/example/hrasGAPGEF_counts.xlsx',\n",
    "                              'R1_after', skiprows=1, index_col='Codons',\n",
    "                              usecols='E:FN', nrows=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the reads have been counted, the object ``meancounts`` can be used to evaluate the coverage by position. You can also manually inspect the exported files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T23:59:34.974842Z",
     "start_time": "2020-08-31T23:59:33.250136Z"
    }
   },
   "outputs": [],
   "source": [
    "# Determine the positions (x axis)\n",
    "positions = np.arange(2, 167, 1)\n",
    "\n",
    "# Plot mean counts\n",
    "hras_RBD.meancounts(positions, df_counts_pre.mean(), show_cartoon=False,\n",
    "                    yscale=(0, 5.5), figsize=(6, 2.5),\n",
    "                    title='Positional coverage pre-selected',\n",
    "                    outputfilename='hras_countspre',\n",
    "                    outputfilepath=outputfilepath, savefile=savefile)\n",
    "\n",
    "hras_RBD.meancounts(positions, df_counts_sel.mean(), show_cartoon=False,\n",
    "                    yscale=(0, 5.5), figsize=(6, 2.5), \n",
    "                    title='Positional coverage selected',\n",
    "                    outputfilename='hras_countssel', \n",
    "                    outputfilepath=outputfilepath, savefile=savefile)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. image:: ../example/exported_images/hras_countspre.png\n",
    "   :width: 400px\n",
    "   :align: center\n",
    "        \n",
    ".. image:: ../example/exported_images/hras_countssel.png\n",
    "   :width: 400px\n",
    "   :align: center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate enrichment scores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Methods and functions reviewed in this section:\n",
    "    - :class:`mutagenesis_visualization.Screen`\n",
    "    - :meth:`mutagenesis_visualization.Screen.heatmap`\n",
    "    - :func:`mutagenesis_visualization.calculate_enrichment`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are performing a selection experiment, where you sequence your library before and after selection, you will need to calculate the enrichment score of each mutant. The function to do so is ``calculate_enrichment``. This function allows for different parameters to tune how the data is processed and normalized."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this example, we show two different ways of using ``calculate_enrichment``. Note that the parameters of choice will have a say on the final result. In the example, the tonality of red of the two heatmaps is slightly different. A more detailed explanation of the parameters can be found in :ref:`Normalizing datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-31T23:54:55.896786Z",
     "start_time": "2020-08-31T23:54:38.147551Z"
    }
   },
   "outputs": [],
   "source": [
    "# Order of amino acids (from count_reads)\n",
    "aminoacids_NNS = list('AACDEFGGHIKLLLMNPPQRRRSSSTTVVWY*')\n",
    "\n",
    "# Parameters to save output images, will be the same for each plot\n",
    "outputfilepath = 'mv_repo/example/exported_images/'\n",
    "savefile = True\n",
    "\n",
    "# Different parameters can be used to calculate the enrichment scores. They are described in the implementation section\n",
    "\n",
    "# Zeroing using the median of the population, and not using stop codons to correct.\n",
    "frequencies = mut.calculate_enrichment(df_counts_pre, df_counts_sel, aminoacids=aminoacids_NNS,\n",
    "                                       zeroing='population', how='median', norm_std=True,\n",
    "                                       stopcodon=True, min_counts=25, min_countswt=100,\n",
    "                                       mpop=2, mwt=2, infinite=3, std_scale=0.3)\n",
    "\n",
    "hras_example1 = mut.Screen(np.array(frequencies), hras_sequence,\n",
    "                           aminoacids, start_position, fillna, secondary)\n",
    "\n",
    "hras_example1.heatmap(title='Normal distribution zeroing', outputfilename='hras_zeronormal',\n",
    "                      outputfilepath=outputfilepath, outputformat=outputformat, savefile=savefile)\n",
    "\n",
    "# Zeroing using the median of the population, and not using stop codons to correct.\n",
    "frequencies = mut.calculate_enrichment(df_counts_pre, df_counts_sel, aminoacids=aminoacids_NNS,\n",
    "                                       zeroing='kernel', how='median', norm_std=True,\n",
    "                                       stopcodon=True, min_counts=25, min_countswt=100,\n",
    "                                       mpop=2, mwt=2, infinite=3, std_scale=0.15)\n",
    "\n",
    "hras_example2 = mut.Screen(np.array(frequencies), hras_sequence,\n",
    "                           aminoacids, start_position, fillna, secondary)\n",
    "\n",
    "hras_example2.heatmap(title='KDE zeroing', outputfilename='hras_zerokernel',\n",
    "                      outputfilepath=outputfilepath, outputformat=outputformat, savefile=savefile)\n",
    "\n",
    "# Note that the two heatmaps look quite similar but the red tonality is slighly different. That is caused by\n",
    "# small differences in zeroing the data."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. image:: ../example/exported_images/hras_tableenrichment.png\n",
    "   :width: 450px\n",
    "   :align: center\n",
    "\n",
    ".. image:: ../example/exported_images/hras_zeronormal.png\n",
    "   :width: 300px\n",
    "   :align: center\n",
    "\n",
    ".. image:: ../example/exported_images/hras_zerokernel.png\n",
    "   :width: 300px\n",
    "   :align: center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble multiple sublibraries"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Function reviewed in this section:\n",
    "    - :func:`mutagenesis_visualization.assemble_avengers`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If you split your library into multiple pools, you can use ``assemble_avengers`` to use ``calculate_enrichment`` in an automated loop and return the assembled dataframe. To use this function, you need to import the data in an excel file in the same format as the provided in Example/hrasGAPGEF_counts.xlsx. Note that the parameters for normalization used in ``calculate_enrichment`` also apply here. See :ref:`Normalizing datasets` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-07T17:39:29.662140Z",
     "start_time": "2020-09-07T17:39:29.658612Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sheet that stores input/preselected counts within the Excel file\n",
    "sheet_pre = 'R1_before'\n",
    "# Sheet that stores output/selected counts within the Excel file\n",
    "sheet_post = 'R1_after'\n",
    "# Columns of each sublibrary. In this example, there are three pools.\n",
    "columns = ['F:BG', 'BH:DK', 'DL:FN']\n",
    "# Columns of the wt pools (optional)\n",
    "columns_wt = ['A', 'B', 'C']\n",
    "# Path were the excel file is stored.\n",
    "excel_path = 'mv_repo/example/hrasGAPGEF_counts.xlsx'\n",
    "# Parameter for pd.read_excel function\n",
    "nrows_pop=32 # For nrows of the sublibrary\n",
    "nrows_wt = [50,37,57] # For nrows of each of the three wild-type columns\n",
    "skiprows = 1 # Skip one row when reading the columns specified in the list `columns`\n",
    "\n",
    "# Normalization parameters also need to be specified. In here we\n",
    "# are using the default ones.\n",
    "\n",
    "# Call the function and return a df\n",
    "df = mut.assemble_avengers(path, sheet_pre, sheet_post, columns,\n",
    "                           nrows_pop, nrows_wt, columns_wt, savefile=False)\n",
    "\n",
    "# The output looks like calculate_enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine MSA with enrichment scores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Function and class reviewed in this section:\n",
    "    - :class:`mutagenesis_visualization.Screen`\n",
    "    - :func:`mutagenesis_visualization.msa_enrichment`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Function ``msa_enrichment`` will calculate the frequency of each substitution in an input MSA. The frequency of each substitution will be merged into the enrichment score dataframe. The function also calculates the Shannon entropy for each position in the protein. This function has been used to generate the data that is plotted in box plot and the ROC AUC charts :ref:`Correlation, PCA and ROC AUC`. We will first need to create the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T20:35:30.612975Z",
     "start_time": "2020-09-03T20:35:30.411945Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load enrichment scores\n",
    "hras_enrichment_RBD = np.genfromtxt('Exported/HRas166_RBD.csv', delimiter=',')\n",
    "\n",
    "# Define protein sequence\n",
    "hras_sequence = 'MTEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVIDGETCLLDILDTAGQEEYSAMRDQYMRTGEGFLCVFAINNTKSFEDIHQYREQIKRVKDSDDVPMVLVGNKCDLAARTVESRQAQDLARSYGIPYIETSAKTRQGVEDAFYTLVREIRQHKLRKLNPPDESGPG'\n",
    "\n",
    "# Create object (more detail about this in plotting examples)\n",
    "hras_RBD = mut.Screen(hras_enrichment_RBD, hras_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get the frequency of each substituion in the MSA and the Shannon entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-03T20:35:31.161656Z",
     "start_time": "2020-09-03T20:35:30.998477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate conservation score from MSA\n",
    "path = 'Other/2020_pfam/Ras_family_trimmed.fasta'\n",
    "df_shannon, df_freq = mut.msa_enrichment(hras_RBD, path, \n",
    "                                         start_position=1, threshold=0.1)\n",
    "\n",
    "# In the example, for position 2, in 3.63% of the cases there was an Ala.\n",
    "df_freq.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".. image:: ../example/exported_images/hras_table_msa.png\n",
    "   :width: 300px\n",
    "   :align: center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The Shannon entropy is calculated using a script created by Joe R. J. Healey from Warwick University. Could not find the script on Github or Pypi so I included it in the package (shannon.py)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "215.012px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
