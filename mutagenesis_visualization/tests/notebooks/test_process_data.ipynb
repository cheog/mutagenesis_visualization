{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from code_process_data.ipynb\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'assemble_sublibraries' from 'code_process_data' (code_process_data.ipynb)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-995a50ad6e2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     from mutagenesis_visualization.main.scripts.code_process_data import (\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mcount_reads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_enrichment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massemble_sublibraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mutagenesis_visualization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-995a50ad6e2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mnew_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tests'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'main'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mcode_process_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcount_reads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalculate_enrichment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massemble_sublibraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'assemble_sublibraries' from 'code_process_data' (code_process_data.ipynb)"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pandas.testing import assert_frame_equal\n",
    "import os\n",
    "from itertools import product\n",
    "from random import randint, random\n",
    "import logging\n",
    "\n",
    "log: logging.Logger = logging.getLogger('test_process_data')\n",
    "\n",
    "\n",
    "try:\n",
    "    from mutagenesis_visualization.main.scripts.code_process_data import (\n",
    "        count_reads, calculate_enrichment, assemble_sublibraries\n",
    "    )\n",
    "except ModuleNotFoundError:\n",
    "    import import_notebook\n",
    "    import os\n",
    "    directory = os.getcwd()\n",
    "    new_directory = directory.replace('tests', 'main')\n",
    "    os.chdir(new_directory)\n",
    "    from code_process_data import count_reads, calculate_enrichment, assemble_sublibraries\n",
    "    os.chdir(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To run these tests run pytest from the root directory. \"Test CCT\" is the one\n",
    "that fails.\n",
    "\n",
    "Other bits and bobs:\n",
    "    In _enumerate_variants you don't use firstwtseq so you can remove that. And\n",
    "    if that goes you can also not pass dna_sequence.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def test_count_reads():\n",
    "    # Need to remove firstwtseq from _enumerate_variants\n",
    "\n",
    "    def mut_assert_df_equal(left: pd.DataFrame, right: pd.DataFrame):\n",
    "        assert_frame_equal(\n",
    "            left,\n",
    "            right,\n",
    "            check_dtype=False,\n",
    "            check_index_type=False,\n",
    "            check_column_type=False,\n",
    "            check_frame_type=False,\n",
    "            check_names=False,\n",
    "            check_like=True,\n",
    "        )\n",
    "\n",
    "    # File location\n",
    "    # Use relative file import to access the data folder\n",
    "    try:\n",
    "        location = os.path.dirname(os.path.realpath(__file__))\n",
    "        my_file = os.path.join(location, '../../data/for_tests', \"short.fastq\")\n",
    "    except NameError:\n",
    "        my_file = os.path.join('../../data/for_tests', \"short.fastq\")\n",
    "\n",
    "    # Create dataframe\n",
    "    codon_list = [\n",
    "        'AAA', 'AAC', 'AAG', 'AAT', 'ACA', 'ACC', 'ACG', 'ACT', 'AGA', 'AGC',\n",
    "        'AGG', 'AGT', 'ATA', 'ATC', 'ATG', 'ATT', 'CAA', 'CAC', 'CAG', 'CAT',\n",
    "        'CCA', 'CCC', 'CCG', 'CCT', 'CGA', 'CGC', 'CGG', 'CGT', 'CTA', 'CTC',\n",
    "        'CTG', 'CTT', 'GAA', 'GAC', 'GAG', 'GAT', 'GCA', 'GCC', 'GCG', 'GCT',\n",
    "        'GGA', 'GGC', 'GGG', 'GGT', 'GTA', 'GTC', 'GTG', 'GTT', 'TAA', 'TAC',\n",
    "        'TAG', 'TAT', 'TCA', 'TCC', 'TCG', 'TCT', 'TGA', 'TGC', 'TGG', 'TGT',\n",
    "        'TTA', 'TTC', 'TTG', 'TTT'\n",
    "    ]\n",
    "    index = pd.Index(codon_list)\n",
    "    column_counts = pd.Index([2])\n",
    "    column_wt = pd.Index([\"Position\", \"Codon\", \"Aminoacid\", \"Counts\"])\n",
    "    values_cct = values_atc = [0] * 23 + [1] + [0] * 40\n",
    "\n",
    "    # Test ATG\n",
    "    expected_atc_counts = pd.DataFrame(\n",
    "        values_atc, index=index, columns=column_counts\n",
    "    )\n",
    "    expected_atc_wt = pd.DataFrame([], columns=column_wt)\n",
    "    atg_counts, atg_wt = count_reads(\"atg\", my_file, codon_list)\n",
    "    # return atg_counts\n",
    "    mut_assert_df_equal(atg_counts, expected_atc_counts)\n",
    "    mut_assert_df_equal(atg_wt, expected_atc_wt)\n",
    "\n",
    "    # Test CCT\n",
    "    expected_cct_counts = pd.DataFrame(\n",
    "        values_cct, index=index, columns=column_counts\n",
    "    )\n",
    "    expected_cct_wt = pd.DataFrame([[2, 'CCA', 'P', 0], [2, 'CCC', 'P', 0],\n",
    "                                    [2, 'CCG', 'P', 0]],\n",
    "                                   index=[20, 21, 22],\n",
    "                                   columns=column_wt)\n",
    "    cct_counts, cct_wt = count_reads(\"cCt\", my_file, codon_list)\n",
    "    mut_assert_df_equal(cct_counts, expected_cct_counts)\n",
    "    mut_assert_df_equal(cct_wt, expected_cct_wt)\n",
    "\n",
    "    # Test CCT when not in codon list\n",
    "    index = pd.Index([\n",
    "        \"GCC\", \"GCG\", \"TGC\", \"GAC\", \"GAG\", \"TTC\", \"GGC\", \"GGG\", \"CAC\",\n",
    "        \"ATC\", \"AAG\", \"CTC\", \"CTG\", \"TTG\", \"ATG\", \"AAC\", \"CCC\", \"CCG\",\n",
    "        \"CAG\", \"CGC\", \"CGG\", \"AGG\", \"TCC\", \"TCG\", \"AGC\", \"ACC\", \"ACG\",\n",
    "        \"GTC\", \"GTG\", \"TGG\", \"TAC\", \"TAG\",\n",
    "    ])\n",
    "    values_cct = [0] * 32\n",
    "    expected_cct_counts = pd.DataFrame(\n",
    "        values_cct, index=index, columns=column_counts\n",
    "    )\n",
    "    expected_cct_wt = pd.DataFrame([[2, 'CCC', 'P', 0], [2, 'CCG', 'P', 0]],\n",
    "                                   index=[16, 17],\n",
    "                                   columns=column_wt)\n",
    "    cct_counts, cct_wt = count_reads(\"cCt\", my_file, 'NNS')\n",
    "    mut_assert_df_equal(cct_counts, expected_cct_counts)\n",
    "    mut_assert_df_equal(cct_wt, expected_cct_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_calculate_enrichment():\n",
    "    # Read counts from file (could be txt, csv, xlsx, etc...)\n",
    "    prefix = \"mutagenesis_visualization/\"\n",
    "    # prefix = \"../../\"\n",
    "    df_counts_pre = pd.read_excel(\n",
    "        prefix + 'data/hrasGAPGEF_counts.xlsx',\n",
    "        'R1_before',\n",
    "        skiprows=1,\n",
    "        index_col='Codons',\n",
    "        usecols='E:FN',\n",
    "        nrows=32\n",
    "    )\n",
    "\n",
    "    df_counts_sel = pd.read_excel(\n",
    "        prefix + 'data/hrasGAPGEF_counts.xlsx',\n",
    "        'R1_after',\n",
    "        skiprows=1,\n",
    "        index_col='Codons',\n",
    "        usecols='E:FN',\n",
    "        nrows=32\n",
    "    )\n",
    "\n",
    "    # Ras parameters to create an object\n",
    "\n",
    "    # Order of amino acids (from count_reads)\n",
    "    aminoacids_NNS = list('AACDEFGGHIKLLLMNPPQRRRSSSTTVVWY*')\n",
    "\n",
    "    # TODO: do 0 and then a random number from 100 - 1000\n",
    "    stopcodon = [\"True\", \"False\"]\n",
    "    min_counts = [0, randint(100, 1000)]\n",
    "    mpop = [0.01, (random() + 0.01) * 10]  # mpop 0 causes an error\n",
    "    common_args = [stopcodon, min_counts, mpop]\n",
    "\n",
    "    # \"wt\" requires pre_wt\n",
    "    zeroing_compatible = [\"population\"]\n",
    "    # \"zscore\" zeroing broken at \"elif zeroing == \"zscore\"\"\n",
    "    zeroing_other = [\"kernel\", \"counts\"]\n",
    "    how = [\"median\", \"mean\", \"mode\"]\n",
    "    std_scale = [0.1, randint(0, 100)]\n",
    "\n",
    "    log.info(f\"{min_counts=}\")\n",
    "    log.info(f\"{mpop=}\")\n",
    "    log.info(f\"{std_scale=}\")\n",
    "\n",
    "    args_how_scale = product(\n",
    "        zeroing_compatible, how, [True], std_scale, *common_args\n",
    "    )\n",
    "    args_how_no_scale = product(\n",
    "        zeroing_compatible, how, [False], *common_args\n",
    "    )\n",
    "    args_no_how_scale = product(\n",
    "        zeroing_other, [True], std_scale, *common_args\n",
    "    )\n",
    "    args_no_how_no_scale = product(\n",
    "        zeroing_other, [False], *common_args\n",
    "    )\n",
    "\n",
    "    for args in args_how_scale:\n",
    "        print(args)\n",
    "        zeroing, how, norm_std, std_scale, *common_args = args\n",
    "        stopcodon, min_counts, mpop = common_args\n",
    "        frequencies = calculate_enrichment(\n",
    "            df_counts_pre.iloc[:, :54],\n",
    "            df_counts_sel.iloc[:, :54],\n",
    "\n",
    "            zeroing=zeroing,\n",
    "            how=how,\n",
    "            norm_std=norm_std,\n",
    "            std_scale=std_scale,\n",
    "\n",
    "            aminoacids=aminoacids_NNS,\n",
    "            stopcodon=stopcodon,\n",
    "            min_counts=min_counts,\n",
    "            min_countswt=100,\n",
    "            mpop=mpop,\n",
    "            mwt=2,\n",
    "            infinite=3\n",
    "        )\n",
    "    for args in args_no_how_scale:\n",
    "        print(args)\n",
    "        zeroing, how, norm_std, *common_args = args\n",
    "        stopcodon, min_counts, mpop = common_args\n",
    "        frequencies = calculate_enrichment(\n",
    "            df_counts_pre.iloc[:, :54],\n",
    "            df_counts_sel.iloc[:, :54],\n",
    "\n",
    "            zeroing=zeroing,\n",
    "            how=how,\n",
    "            norm_std=norm_std,\n",
    "\n",
    "            aminoacids=aminoacids_NNS,\n",
    "            stopcodon=stopcodon,\n",
    "            min_counts=min_counts,\n",
    "            min_countswt=100,\n",
    "            mpop=mpop,\n",
    "            mwt=2,\n",
    "            infinite=3\n",
    "        )\n",
    "    for args in args_how_no_scale:\n",
    "        print(args)\n",
    "        zeroing, norm_std, std_scale, *common_args = args\n",
    "        stopcodon, min_counts, mpop = common_args\n",
    "        frequencies = calculate_enrichment(\n",
    "            df_counts_pre.iloc[:, :54],\n",
    "            df_counts_sel.iloc[:, :54],\n",
    "\n",
    "            zeroing=zeroing,\n",
    "            norm_std=norm_std,\n",
    "            std_scale=std_scale,\n",
    "\n",
    "            aminoacids=aminoacids_NNS,\n",
    "            stopcodon=stopcodon,\n",
    "            min_counts=min_counts,\n",
    "            min_countswt=100,\n",
    "            mpop=mpop,\n",
    "            mwt=2,\n",
    "            infinite=3\n",
    "        )\n",
    "    for args in args_how_scale:\n",
    "        print(args)\n",
    "        zeroing, norm_std, *common_args = args\n",
    "        stopcodon, min_counts, mpop = common_args\n",
    "        frequencies = calculate_enrichment(\n",
    "            df_counts_pre.iloc[:, :54],\n",
    "            df_counts_sel.iloc[:, :54],\n",
    "\n",
    "            zeroing=zeroing,\n",
    "            norm_std=norm_std,\n",
    "\n",
    "            aminoacids=aminoacids_NNS,\n",
    "            stopcodon=stopcodon,\n",
    "            min_counts=min_counts,\n",
    "            min_countswt=100,\n",
    "            mpop=mpop,\n",
    "            mwt=2,\n",
    "            infinite=3\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_assemble_sublibraries():\n",
    "    # There aren't actually very many arguments to test here.  Once you remove\n",
    "    # - all arguments that are just forwarded to calculate_enrichment\n",
    "    # - the filename and excel sheet arguments\n",
    "    # - treat the columns_wt arguments as either there or not\n",
    "    # You're left with testing columns, nrows_pop, and columns_wt as a bool\n",
    "\n",
    "    alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "    pairs = [a + b for a, b in product(alphabet, alphabet)]\n",
    "    all_columns = list(alphabet[5:]) + pairs[:144]\n",
    "    col_lists = [partition_list(all_columns, i) for i in range(2, 6)]\n",
    "\n",
    "    nrows_list = [randint(1, 31) for _ in range(3)] + [32]\n",
    "    aminos = list(reversed(\"AACDEFGGHIKLLLMNPPQRRRSSSTTVVWY*\"))\n",
    "    amino_list = [list(reversed(aminos[:rows])) for rows in nrows_list]\n",
    "\n",
    "    col_wt_list = [['A', 'B', 'C']]\n",
    "\n",
    "    args = product(col_lists, col_wt_list, zip(nrows_list, amino_list))\n",
    "\n",
    "    filename = \"mutagenesis_visualization/data/hrasGAPGEF_counts.xlsx\"\n",
    "    # filename = \"../../data/hrasGAPGEF_counts.xlsx\"\n",
    "    sheet_pre = \"R1_before\"\n",
    "    sheet_post = \"R1_after\"\n",
    "    columns_wt = ['A', 'B', 'C']\n",
    "    nrows_pop = 32\n",
    "    nrows_wt = [50, 37, 57]\n",
    "\n",
    "    for columns, columns_wt, nrows_aminos in args:\n",
    "        nrows_pop, aminos = nrows_aminos\n",
    "        print(f\"{columns=}\\t{columns_wt=}\\t{nrows_pop=}\")\n",
    "        df = assemble_sublibraries(\n",
    "            excel_path=filename,\n",
    "            sheet_pre=sheet_pre,\n",
    "            sheet_post=sheet_post,\n",
    "            columns=columns,\n",
    "            nrows_pop=nrows_pop,\n",
    "            nrows_wt=nrows_wt,\n",
    "            columns_wt=columns_wt,\n",
    "            aminoacids=aminos,\n",
    "            output_file=None\n",
    "        )\n",
    "\n",
    "        \n",
    "def partition_list(array, num_partitions):\n",
    "    \"\"\"Partition array randomly where each partition has at least one item.\"\"\"\n",
    "    if num_partitions < 2:\n",
    "        return [f\"{array[0]}:{array[-1]}\"]\n",
    "    partition_idxs = []\n",
    "    while len(partition_idxs) < num_partitions - 1:\n",
    "        num = randint(0, len(array) - 1)\n",
    "        if num not in partition_idxs:\n",
    "            tmp_parts = partition_idxs.copy()\n",
    "            tmp_parts.append(num)\n",
    "            tmp_parts.sort()\n",
    "            idx = tmp_parts.index(num)\n",
    "            if idx != 0:\n",
    "                if tmp_parts[idx] - tmp_parts[idx - 1] < 1:\n",
    "                    continue\n",
    "            if idx != len(tmp_parts) - 1:\n",
    "                if tmp_parts[idx + 1] - tmp_parts[idx] < 1:\n",
    "                    continue\n",
    "            partition_idxs.append(num)\n",
    "    partition_idxs.sort()\n",
    "    parts = [f\"{array[0]}:{array[partition_idxs[0] - 1]}\"]\n",
    "    for start, end in zip(partition_idxs, partition_idxs[1:]):\n",
    "        parts.append(f\"{array[start]}:{array[end - 1]}\")\n",
    "    parts.append(f\"{array[partition_idxs[-1]]}:{array[-1]}\")\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
